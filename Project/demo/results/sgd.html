<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean_fit_time</th>
      <th>std_fit_time</th>
      <th>mean_score_time</th>
      <th>std_score_time</th>
      <th>param_clf__alpha</th>
      <th>param_clf__class_weight</th>
      <th>param_clf__eta0</th>
      <th>param_clf__fit_intercept</th>
      <th>param_clf__learning_rate</th>
      <th>param_clf__loss</th>
      <th>param_clf__penalty</th>
      <th>param_clf__shuffle</th>
      <th>param_vec__analyzer</th>
      <th>param_vec__lowercase</th>
      <th>param_vec__ngram_range</th>
      <th>param_vec__norm</th>
      <th>param_vec__strip_accents</th>
      <th>params</th>
      <th>split0_test_F1</th>
      <th>split1_test_F1</th>
      <th>split2_test_F1</th>
      <th>mean_test_F1</th>
      <th>std_test_F1</th>
      <th>rank_test_F1</th>
      <th>split0_test_Accuracy</th>
      <th>split1_test_Accuracy</th>
      <th>split2_test_Accuracy</th>
      <th>mean_test_Accuracy</th>
      <th>std_test_Accuracy</th>
      <th>rank_test_Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>97</th>
      <td>1.472335</td>
      <td>0.020170</td>
      <td>0.358997</td>
      <td>0.009415</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775390</td>
      <td>0.790103</td>
      <td>0.777927</td>
      <td>0.781140</td>
      <td>0.006422</td>
      <td>1</td>
      <td>0.800709</td>
      <td>0.814468</td>
      <td>0.804681</td>
      <td>0.806619</td>
      <td>0.005782</td>
      <td>57</td>
    </tr>
    <tr>
      <th>463</th>
      <td>1.235041</td>
      <td>0.023391</td>
      <td>0.310250</td>
      <td>0.006294</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775302</td>
      <td>0.790005</td>
      <td>0.777654</td>
      <td>0.780987</td>
      <td>0.006448</td>
      <td>2</td>
      <td>0.801844</td>
      <td>0.815035</td>
      <td>0.805390</td>
      <td>0.807423</td>
      <td>0.005574</td>
      <td>46</td>
    </tr>
    <tr>
      <th>571</th>
      <td>1.237667</td>
      <td>0.010341</td>
      <td>0.356663</td>
      <td>0.046189</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775302</td>
      <td>0.790005</td>
      <td>0.777654</td>
      <td>0.780987</td>
      <td>0.006448</td>
      <td>2</td>
      <td>0.801844</td>
      <td>0.815035</td>
      <td>0.805390</td>
      <td>0.807423</td>
      <td>0.005574</td>
      <td>46</td>
    </tr>
    <tr>
      <th>625</th>
      <td>1.252005</td>
      <td>0.011575</td>
      <td>0.372328</td>
      <td>0.044975</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775302</td>
      <td>0.790005</td>
      <td>0.777654</td>
      <td>0.780987</td>
      <td>0.006448</td>
      <td>2</td>
      <td>0.801844</td>
      <td>0.815035</td>
      <td>0.805390</td>
      <td>0.807423</td>
      <td>0.005574</td>
      <td>46</td>
    </tr>
    <tr>
      <th>517</th>
      <td>1.241996</td>
      <td>0.014169</td>
      <td>0.365670</td>
      <td>0.049032</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775302</td>
      <td>0.790005</td>
      <td>0.777654</td>
      <td>0.780987</td>
      <td>0.006448</td>
      <td>2</td>
      <td>0.801844</td>
      <td>0.815035</td>
      <td>0.805390</td>
      <td>0.807423</td>
      <td>0.005574</td>
      <td>46</td>
    </tr>
    <tr>
      <th>472</th>
      <td>1.976073</td>
      <td>0.172834</td>
      <td>0.363335</td>
      <td>0.035122</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775894</td>
      <td>0.790743</td>
      <td>0.774731</td>
      <td>0.780456</td>
      <td>0.007290</td>
      <td>6</td>
      <td>0.800142</td>
      <td>0.814752</td>
      <td>0.800426</td>
      <td>0.805106</td>
      <td>0.006821</td>
      <td>89</td>
    </tr>
    <tr>
      <th>634</th>
      <td>1.433065</td>
      <td>0.060313</td>
      <td>0.353953</td>
      <td>0.018779</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.774751</td>
      <td>0.788908</td>
      <td>0.777319</td>
      <td>0.780326</td>
      <td>0.006159</td>
      <td>7</td>
      <td>0.800142</td>
      <td>0.813617</td>
      <td>0.803688</td>
      <td>0.805816</td>
      <td>0.005703</td>
      <td>78</td>
    </tr>
    <tr>
      <th>572</th>
      <td>1.868336</td>
      <td>0.016580</td>
      <td>0.472998</td>
      <td>0.015253</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775078</td>
      <td>0.788804</td>
      <td>0.776986</td>
      <td>0.780290</td>
      <td>0.006071</td>
      <td>8</td>
      <td>0.802553</td>
      <td>0.815319</td>
      <td>0.805390</td>
      <td>0.807754</td>
      <td>0.005473</td>
      <td>32</td>
    </tr>
    <tr>
      <th>464</th>
      <td>1.960662</td>
      <td>0.062724</td>
      <td>0.405413</td>
      <td>0.028330</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775078</td>
      <td>0.788804</td>
      <td>0.776986</td>
      <td>0.780290</td>
      <td>0.006071</td>
      <td>8</td>
      <td>0.802553</td>
      <td>0.815319</td>
      <td>0.805390</td>
      <td>0.807754</td>
      <td>0.005473</td>
      <td>32</td>
    </tr>
    <tr>
      <th>626</th>
      <td>1.932999</td>
      <td>0.040405</td>
      <td>0.418333</td>
      <td>0.031596</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775078</td>
      <td>0.788804</td>
      <td>0.776986</td>
      <td>0.780290</td>
      <td>0.006071</td>
      <td>8</td>
      <td>0.802553</td>
      <td>0.815319</td>
      <td>0.805390</td>
      <td>0.807754</td>
      <td>0.005473</td>
      <td>32</td>
    </tr>
    <tr>
      <th>518</th>
      <td>1.954190</td>
      <td>0.030403</td>
      <td>0.425668</td>
      <td>0.044791</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775078</td>
      <td>0.788804</td>
      <td>0.776986</td>
      <td>0.780290</td>
      <td>0.006071</td>
      <td>8</td>
      <td>0.802553</td>
      <td>0.815319</td>
      <td>0.805390</td>
      <td>0.807754</td>
      <td>0.005473</td>
      <td>32</td>
    </tr>
    <tr>
      <th>43</th>
      <td>1.298042</td>
      <td>0.040462</td>
      <td>0.363997</td>
      <td>0.017964</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.776895</td>
      <td>0.788984</td>
      <td>0.774252</td>
      <td>0.780044</td>
      <td>0.006413</td>
      <td>12</td>
      <td>0.803972</td>
      <td>0.814468</td>
      <td>0.803972</td>
      <td>0.807470</td>
      <td>0.004948</td>
      <td>45</td>
    </tr>
    <tr>
      <th>206</th>
      <td>1.927671</td>
      <td>0.035190</td>
      <td>0.407330</td>
      <td>0.024005</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.778304</td>
      <td>0.789819</td>
      <td>0.771522</td>
      <td>0.779882</td>
      <td>0.007552</td>
      <td>13</td>
      <td>0.806383</td>
      <td>0.816312</td>
      <td>0.804539</td>
      <td>0.809078</td>
      <td>0.005170</td>
      <td>10</td>
    </tr>
    <tr>
      <th>142</th>
      <td>1.218999</td>
      <td>0.016873</td>
      <td>0.373333</td>
      <td>0.018735</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.776459</td>
      <td>0.789748</td>
      <td>0.773437</td>
      <td>0.779882</td>
      <td>0.007085</td>
      <td>14</td>
      <td>0.804255</td>
      <td>0.815745</td>
      <td>0.803404</td>
      <td>0.807801</td>
      <td>0.005627</td>
      <td>28</td>
    </tr>
    <tr>
      <th>34</th>
      <td>1.269070</td>
      <td>0.025362</td>
      <td>0.332332</td>
      <td>0.027525</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.776459</td>
      <td>0.789748</td>
      <td>0.773437</td>
      <td>0.779882</td>
      <td>0.007085</td>
      <td>14</td>
      <td>0.804255</td>
      <td>0.815745</td>
      <td>0.803404</td>
      <td>0.807801</td>
      <td>0.005627</td>
      <td>28</td>
    </tr>
    <tr>
      <th>88</th>
      <td>1.224002</td>
      <td>0.017908</td>
      <td>0.333332</td>
      <td>0.031513</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.776459</td>
      <td>0.789748</td>
      <td>0.773437</td>
      <td>0.779882</td>
      <td>0.007085</td>
      <td>14</td>
      <td>0.804255</td>
      <td>0.815745</td>
      <td>0.803404</td>
      <td>0.807801</td>
      <td>0.005627</td>
      <td>28</td>
    </tr>
    <tr>
      <th>196</th>
      <td>1.242089</td>
      <td>0.046972</td>
      <td>0.346064</td>
      <td>0.012334</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.776459</td>
      <td>0.789748</td>
      <td>0.773437</td>
      <td>0.779882</td>
      <td>0.007085</td>
      <td>14</td>
      <td>0.804255</td>
      <td>0.815745</td>
      <td>0.803404</td>
      <td>0.807801</td>
      <td>0.005627</td>
      <td>28</td>
    </tr>
    <tr>
      <th>497</th>
      <td>2.477427</td>
      <td>0.063960</td>
      <td>0.396413</td>
      <td>0.017352</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.777103</td>
      <td>0.787506</td>
      <td>0.774207</td>
      <td>0.779605</td>
      <td>0.005710</td>
      <td>18</td>
      <td>0.804397</td>
      <td>0.814894</td>
      <td>0.803262</td>
      <td>0.807518</td>
      <td>0.005236</td>
      <td>38</td>
    </tr>
    <tr>
      <th>70</th>
      <td>1.485334</td>
      <td>0.030070</td>
      <td>0.337001</td>
      <td>0.009092</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775070</td>
      <td>0.787989</td>
      <td>0.775533</td>
      <td>0.779531</td>
      <td>0.005984</td>
      <td>19</td>
      <td>0.800426</td>
      <td>0.812908</td>
      <td>0.802553</td>
      <td>0.805296</td>
      <td>0.005452</td>
      <td>88</td>
    </tr>
    <tr>
      <th>635</th>
      <td>2.091886</td>
      <td>0.035211</td>
      <td>0.418613</td>
      <td>0.014554</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.774845</td>
      <td>0.787688</td>
      <td>0.775981</td>
      <td>0.779505</td>
      <td>0.005805</td>
      <td>20</td>
      <td>0.800851</td>
      <td>0.813475</td>
      <td>0.803546</td>
      <td>0.805957</td>
      <td>0.005429</td>
      <td>75</td>
    </tr>
    <tr>
      <th>503</th>
      <td>2.367949</td>
      <td>0.020297</td>
      <td>0.445667</td>
      <td>0.027392</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.774875</td>
      <td>0.788296</td>
      <td>0.775299</td>
      <td>0.779490</td>
      <td>0.006229</td>
      <td>21</td>
      <td>0.802553</td>
      <td>0.815603</td>
      <td>0.804397</td>
      <td>0.807518</td>
      <td>0.005766</td>
      <td>38</td>
    </tr>
    <tr>
      <th>44</th>
      <td>1.921669</td>
      <td>0.021700</td>
      <td>0.463664</td>
      <td>0.038767</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775445</td>
      <td>0.787902</td>
      <td>0.774781</td>
      <td>0.779376</td>
      <td>0.006035</td>
      <td>22</td>
      <td>0.804113</td>
      <td>0.814894</td>
      <td>0.805248</td>
      <td>0.808085</td>
      <td>0.004837</td>
      <td>23</td>
    </tr>
    <tr>
      <th>607</th>
      <td>1.454002</td>
      <td>0.035528</td>
      <td>0.356329</td>
      <td>0.024224</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.774720</td>
      <td>0.787831</td>
      <td>0.775556</td>
      <td>0.779369</td>
      <td>0.005993</td>
      <td>23</td>
      <td>0.800567</td>
      <td>0.813475</td>
      <td>0.803262</td>
      <td>0.805768</td>
      <td>0.005560</td>
      <td>79</td>
    </tr>
    <tr>
      <th>71</th>
      <td>2.374841</td>
      <td>0.122215</td>
      <td>0.464507</td>
      <td>0.021793</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.774674</td>
      <td>0.789873</td>
      <td>0.773204</td>
      <td>0.779251</td>
      <td>0.007535</td>
      <td>24</td>
      <td>0.798865</td>
      <td>0.814326</td>
      <td>0.799291</td>
      <td>0.804161</td>
      <td>0.007190</td>
      <td>91</td>
    </tr>
    <tr>
      <th>197</th>
      <td>1.917411</td>
      <td>0.032206</td>
      <td>0.432922</td>
      <td>0.033598</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775960</td>
      <td>0.786943</td>
      <td>0.774618</td>
      <td>0.779174</td>
      <td>0.005521</td>
      <td>25</td>
      <td>0.805248</td>
      <td>0.814468</td>
      <td>0.805248</td>
      <td>0.808322</td>
      <td>0.004346</td>
      <td>17</td>
    </tr>
    <tr>
      <th>143</th>
      <td>1.941332</td>
      <td>0.016503</td>
      <td>0.474328</td>
      <td>0.003093</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775960</td>
      <td>0.786943</td>
      <td>0.774618</td>
      <td>0.779174</td>
      <td>0.005521</td>
      <td>25</td>
      <td>0.805248</td>
      <td>0.814468</td>
      <td>0.805248</td>
      <td>0.808322</td>
      <td>0.004346</td>
      <td>17</td>
    </tr>
    <tr>
      <th>35</th>
      <td>1.877998</td>
      <td>0.026090</td>
      <td>0.432667</td>
      <td>0.033318</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775960</td>
      <td>0.786943</td>
      <td>0.774618</td>
      <td>0.779174</td>
      <td>0.005521</td>
      <td>25</td>
      <td>0.805248</td>
      <td>0.814468</td>
      <td>0.805248</td>
      <td>0.808322</td>
      <td>0.004346</td>
      <td>17</td>
    </tr>
    <tr>
      <th>89</th>
      <td>1.902332</td>
      <td>0.025421</td>
      <td>0.441001</td>
      <td>0.038112</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775960</td>
      <td>0.786943</td>
      <td>0.774618</td>
      <td>0.779174</td>
      <td>0.005521</td>
      <td>25</td>
      <td>0.805248</td>
      <td>0.814468</td>
      <td>0.805248</td>
      <td>0.808322</td>
      <td>0.004346</td>
      <td>17</td>
    </tr>
    <tr>
      <th>440</th>
      <td>2.021316</td>
      <td>0.060388</td>
      <td>0.448837</td>
      <td>0.048083</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775497</td>
      <td>0.789368</td>
      <td>0.772498</td>
      <td>0.779121</td>
      <td>0.007348</td>
      <td>29</td>
      <td>0.801277</td>
      <td>0.813191</td>
      <td>0.804255</td>
      <td>0.806241</td>
      <td>0.005063</td>
      <td>64</td>
    </tr>
    <tr>
      <th>602</th>
      <td>2.289994</td>
      <td>0.213531</td>
      <td>0.422689</td>
      <td>0.041969</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775497</td>
      <td>0.789368</td>
      <td>0.772498</td>
      <td>0.779121</td>
      <td>0.007348</td>
      <td>29</td>
      <td>0.801277</td>
      <td>0.813191</td>
      <td>0.804255</td>
      <td>0.806241</td>
      <td>0.005063</td>
      <td>64</td>
    </tr>
    <tr>
      <th>494</th>
      <td>1.882018</td>
      <td>0.063056</td>
      <td>0.461271</td>
      <td>0.058795</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775497</td>
      <td>0.789368</td>
      <td>0.772498</td>
      <td>0.779121</td>
      <td>0.007348</td>
      <td>29</td>
      <td>0.801277</td>
      <td>0.813191</td>
      <td>0.804255</td>
      <td>0.806241</td>
      <td>0.005063</td>
      <td>64</td>
    </tr>
    <tr>
      <th>548</th>
      <td>1.909001</td>
      <td>0.009936</td>
      <td>0.417329</td>
      <td>0.030470</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775497</td>
      <td>0.789368</td>
      <td>0.772498</td>
      <td>0.779121</td>
      <td>0.007348</td>
      <td>29</td>
      <td>0.801277</td>
      <td>0.813191</td>
      <td>0.804255</td>
      <td>0.806241</td>
      <td>0.005063</td>
      <td>64</td>
    </tr>
    <tr>
      <th>445</th>
      <td>1.661335</td>
      <td>0.041801</td>
      <td>0.316998</td>
      <td>0.012031</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.776520</td>
      <td>0.786301</td>
      <td>0.773623</td>
      <td>0.778815</td>
      <td>0.005424</td>
      <td>33</td>
      <td>0.800993</td>
      <td>0.810922</td>
      <td>0.799574</td>
      <td>0.803830</td>
      <td>0.005048</td>
      <td>93</td>
    </tr>
    <tr>
      <th>98</th>
      <td>2.294383</td>
      <td>0.082372</td>
      <td>0.460441</td>
      <td>0.016990</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.774001</td>
      <td>0.787985</td>
      <td>0.774249</td>
      <td>0.778745</td>
      <td>0.006534</td>
      <td>34</td>
      <td>0.800851</td>
      <td>0.814326</td>
      <td>0.802979</td>
      <td>0.806052</td>
      <td>0.005915</td>
      <td>74</td>
    </tr>
    <tr>
      <th>17</th>
      <td>1.978667</td>
      <td>0.020136</td>
      <td>0.449662</td>
      <td>0.031648</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.776244</td>
      <td>0.790819</td>
      <td>0.768871</td>
      <td>0.778645</td>
      <td>0.009119</td>
      <td>35</td>
      <td>0.801702</td>
      <td>0.816454</td>
      <td>0.804681</td>
      <td>0.807612</td>
      <td>0.006369</td>
      <td>37</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1.908668</td>
      <td>0.045389</td>
      <td>0.430995</td>
      <td>0.067277</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.777401</td>
      <td>0.789922</td>
      <td>0.768596</td>
      <td>0.778640</td>
      <td>0.008750</td>
      <td>36</td>
      <td>0.803262</td>
      <td>0.816170</td>
      <td>0.804397</td>
      <td>0.807943</td>
      <td>0.005836</td>
      <td>24</td>
    </tr>
    <tr>
      <th>170</th>
      <td>2.150051</td>
      <td>0.035015</td>
      <td>0.518444</td>
      <td>0.097635</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.777401</td>
      <td>0.789922</td>
      <td>0.768596</td>
      <td>0.778640</td>
      <td>0.008750</td>
      <td>36</td>
      <td>0.803262</td>
      <td>0.816170</td>
      <td>0.804397</td>
      <td>0.807943</td>
      <td>0.005836</td>
      <td>24</td>
    </tr>
    <tr>
      <th>62</th>
      <td>1.897333</td>
      <td>0.020139</td>
      <td>0.423668</td>
      <td>0.021642</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.777401</td>
      <td>0.789922</td>
      <td>0.768596</td>
      <td>0.778640</td>
      <td>0.008750</td>
      <td>36</td>
      <td>0.803262</td>
      <td>0.816170</td>
      <td>0.804397</td>
      <td>0.807943</td>
      <td>0.005836</td>
      <td>24</td>
    </tr>
    <tr>
      <th>116</th>
      <td>1.918998</td>
      <td>0.046316</td>
      <td>0.440332</td>
      <td>0.023110</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.777401</td>
      <td>0.789922</td>
      <td>0.768596</td>
      <td>0.778640</td>
      <td>0.008750</td>
      <td>36</td>
      <td>0.803262</td>
      <td>0.816170</td>
      <td>0.804397</td>
      <td>0.807943</td>
      <td>0.005836</td>
      <td>24</td>
    </tr>
    <tr>
      <th>473</th>
      <td>2.428370</td>
      <td>0.033561</td>
      <td>0.425334</td>
      <td>0.049301</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.773269</td>
      <td>0.786831</td>
      <td>0.775253</td>
      <td>0.778451</td>
      <td>0.005981</td>
      <td>40</td>
      <td>0.798440</td>
      <td>0.812199</td>
      <td>0.801844</td>
      <td>0.804161</td>
      <td>0.005851</td>
      <td>92</td>
    </tr>
    <tr>
      <th>461</th>
      <td>1.916013</td>
      <td>0.034084</td>
      <td>0.467206</td>
      <td>0.046442</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.777459</td>
      <td>0.786521</td>
      <td>0.770356</td>
      <td>0.778112</td>
      <td>0.006615</td>
      <td>41</td>
      <td>0.810780</td>
      <td>0.817163</td>
      <td>0.804539</td>
      <td>0.810827</td>
      <td>0.005154</td>
      <td>1</td>
    </tr>
    <tr>
      <th>569</th>
      <td>1.825195</td>
      <td>0.020323</td>
      <td>0.476335</td>
      <td>0.015964</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.777459</td>
      <td>0.786521</td>
      <td>0.770356</td>
      <td>0.778112</td>
      <td>0.006615</td>
      <td>41</td>
      <td>0.810780</td>
      <td>0.817163</td>
      <td>0.804539</td>
      <td>0.810827</td>
      <td>0.005154</td>
      <td>1</td>
    </tr>
    <tr>
      <th>623</th>
      <td>1.897999</td>
      <td>0.020700</td>
      <td>0.443666</td>
      <td>0.006648</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.777459</td>
      <td>0.786521</td>
      <td>0.770356</td>
      <td>0.778112</td>
      <td>0.006615</td>
      <td>41</td>
      <td>0.810780</td>
      <td>0.817163</td>
      <td>0.804539</td>
      <td>0.810827</td>
      <td>0.005154</td>
      <td>1</td>
    </tr>
    <tr>
      <th>515</th>
      <td>1.988335</td>
      <td>0.014051</td>
      <td>0.392331</td>
      <td>0.012360</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.777459</td>
      <td>0.786521</td>
      <td>0.770356</td>
      <td>0.778112</td>
      <td>0.006615</td>
      <td>41</td>
      <td>0.810780</td>
      <td>0.817163</td>
      <td>0.804539</td>
      <td>0.810827</td>
      <td>0.005154</td>
      <td>1</td>
    </tr>
    <tr>
      <th>529</th>
      <td>1.598061</td>
      <td>0.047854</td>
      <td>0.362690</td>
      <td>0.058962</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.776363</td>
      <td>0.784205</td>
      <td>0.772826</td>
      <td>0.777798</td>
      <td>0.004755</td>
      <td>45</td>
      <td>0.806383</td>
      <td>0.813759</td>
      <td>0.805532</td>
      <td>0.808558</td>
      <td>0.003694</td>
      <td>14</td>
    </tr>
    <tr>
      <th>502</th>
      <td>1.527091</td>
      <td>0.027319</td>
      <td>0.304332</td>
      <td>0.009674</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.774008</td>
      <td>0.785482</td>
      <td>0.773441</td>
      <td>0.777644</td>
      <td>0.005547</td>
      <td>46</td>
      <td>0.802837</td>
      <td>0.813901</td>
      <td>0.804255</td>
      <td>0.806998</td>
      <td>0.004915</td>
      <td>50</td>
    </tr>
    <tr>
      <th>205</th>
      <td>1.264999</td>
      <td>0.031874</td>
      <td>0.333335</td>
      <td>0.042034</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.776092</td>
      <td>0.786636</td>
      <td>0.769963</td>
      <td>0.777564</td>
      <td>0.006886</td>
      <td>47</td>
      <td>0.802979</td>
      <td>0.812340</td>
      <td>0.803404</td>
      <td>0.806241</td>
      <td>0.004316</td>
      <td>64</td>
    </tr>
    <tr>
      <th>496</th>
      <td>1.617370</td>
      <td>0.001818</td>
      <td>0.387908</td>
      <td>0.010844</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775317</td>
      <td>0.785025</td>
      <td>0.771990</td>
      <td>0.777444</td>
      <td>0.005530</td>
      <td>48</td>
      <td>0.803121</td>
      <td>0.812908</td>
      <td>0.801844</td>
      <td>0.805957</td>
      <td>0.004942</td>
      <td>76</td>
    </tr>
    <tr>
      <th>608</th>
      <td>2.147669</td>
      <td>0.035593</td>
      <td>0.384332</td>
      <td>0.001249</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.773078</td>
      <td>0.786840</td>
      <td>0.772401</td>
      <td>0.777440</td>
      <td>0.006653</td>
      <td>49</td>
      <td>0.797589</td>
      <td>0.811915</td>
      <td>0.798865</td>
      <td>0.802790</td>
      <td>0.006474</td>
      <td>103</td>
    </tr>
    <tr>
      <th>449</th>
      <td>2.002334</td>
      <td>0.023582</td>
      <td>0.415333</td>
      <td>0.032309</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.777443</td>
      <td>0.783058</td>
      <td>0.771745</td>
      <td>0.777415</td>
      <td>0.004619</td>
      <td>50</td>
      <td>0.808227</td>
      <td>0.813617</td>
      <td>0.805248</td>
      <td>0.809031</td>
      <td>0.003463</td>
      <td>11</td>
    </tr>
    <tr>
      <th>523</th>
      <td>1.701665</td>
      <td>0.059539</td>
      <td>0.305001</td>
      <td>0.015513</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775815</td>
      <td>0.784481</td>
      <td>0.771866</td>
      <td>0.777388</td>
      <td>0.005269</td>
      <td>51</td>
      <td>0.805816</td>
      <td>0.814043</td>
      <td>0.804539</td>
      <td>0.808132</td>
      <td>0.004211</td>
      <td>22</td>
    </tr>
    <tr>
      <th>491</th>
      <td>1.968466</td>
      <td>0.069437</td>
      <td>0.481597</td>
      <td>0.076753</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.773801</td>
      <td>0.787407</td>
      <td>0.770415</td>
      <td>0.777208</td>
      <td>0.007343</td>
      <td>52</td>
      <td>0.799149</td>
      <td>0.813333</td>
      <td>0.804539</td>
      <td>0.805674</td>
      <td>0.005846</td>
      <td>84</td>
    </tr>
    <tr>
      <th>599</th>
      <td>1.929107</td>
      <td>0.053405</td>
      <td>0.475684</td>
      <td>0.025948</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.773801</td>
      <td>0.787407</td>
      <td>0.770415</td>
      <td>0.777208</td>
      <td>0.007343</td>
      <td>52</td>
      <td>0.799149</td>
      <td>0.813333</td>
      <td>0.804539</td>
      <td>0.805674</td>
      <td>0.005846</td>
      <td>84</td>
    </tr>
    <tr>
      <th>545</th>
      <td>1.955334</td>
      <td>0.038309</td>
      <td>0.388334</td>
      <td>0.006654</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.773801</td>
      <td>0.787407</td>
      <td>0.770415</td>
      <td>0.777208</td>
      <td>0.007343</td>
      <td>52</td>
      <td>0.799149</td>
      <td>0.813333</td>
      <td>0.804539</td>
      <td>0.805674</td>
      <td>0.005846</td>
      <td>84</td>
    </tr>
    <tr>
      <th>437</th>
      <td>1.946889</td>
      <td>0.026409</td>
      <td>0.381667</td>
      <td>0.003299</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.773801</td>
      <td>0.787407</td>
      <td>0.770415</td>
      <td>0.777208</td>
      <td>0.007343</td>
      <td>52</td>
      <td>0.799149</td>
      <td>0.813333</td>
      <td>0.804539</td>
      <td>0.805674</td>
      <td>0.005846</td>
      <td>84</td>
    </tr>
    <tr>
      <th>446</th>
      <td>2.333669</td>
      <td>0.016009</td>
      <td>0.390330</td>
      <td>0.013427</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.773437</td>
      <td>0.785205</td>
      <td>0.772880</td>
      <td>0.777174</td>
      <td>0.005683</td>
      <td>56</td>
      <td>0.796596</td>
      <td>0.809787</td>
      <td>0.797730</td>
      <td>0.801371</td>
      <td>0.005969</td>
      <td>104</td>
    </tr>
    <tr>
      <th>530</th>
      <td>2.722912</td>
      <td>0.079522</td>
      <td>0.488311</td>
      <td>0.035633</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775733</td>
      <td>0.784364</td>
      <td>0.770805</td>
      <td>0.776967</td>
      <td>0.005604</td>
      <td>57</td>
      <td>0.807660</td>
      <td>0.815177</td>
      <td>0.805248</td>
      <td>0.809362</td>
      <td>0.004228</td>
      <td>9</td>
    </tr>
    <tr>
      <th>598</th>
      <td>1.261720</td>
      <td>0.027930</td>
      <td>0.352335</td>
      <td>0.022664</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.774001</td>
      <td>0.787701</td>
      <td>0.769093</td>
      <td>0.776932</td>
      <td>0.007874</td>
      <td>58</td>
      <td>0.800851</td>
      <td>0.814184</td>
      <td>0.803972</td>
      <td>0.806336</td>
      <td>0.005694</td>
      <td>60</td>
    </tr>
    <tr>
      <th>490</th>
      <td>1.255667</td>
      <td>0.039617</td>
      <td>0.371000</td>
      <td>0.008832</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.774001</td>
      <td>0.787701</td>
      <td>0.769093</td>
      <td>0.776932</td>
      <td>0.007874</td>
      <td>58</td>
      <td>0.800851</td>
      <td>0.814184</td>
      <td>0.803972</td>
      <td>0.806336</td>
      <td>0.005694</td>
      <td>60</td>
    </tr>
    <tr>
      <th>544</th>
      <td>1.423670</td>
      <td>0.075161</td>
      <td>0.326330</td>
      <td>0.009569</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.774001</td>
      <td>0.787701</td>
      <td>0.769093</td>
      <td>0.776932</td>
      <td>0.007874</td>
      <td>58</td>
      <td>0.800851</td>
      <td>0.814184</td>
      <td>0.803972</td>
      <td>0.806336</td>
      <td>0.005694</td>
      <td>60</td>
    </tr>
    <tr>
      <th>436</th>
      <td>1.237588</td>
      <td>0.018930</td>
      <td>0.309701</td>
      <td>0.011255</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.774001</td>
      <td>0.787701</td>
      <td>0.769093</td>
      <td>0.776932</td>
      <td>0.007874</td>
      <td>58</td>
      <td>0.800851</td>
      <td>0.814184</td>
      <td>0.803972</td>
      <td>0.806336</td>
      <td>0.005694</td>
      <td>60</td>
    </tr>
    <tr>
      <th>605</th>
      <td>1.869342</td>
      <td>0.032290</td>
      <td>0.474658</td>
      <td>0.029598</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.776392</td>
      <td>0.783602</td>
      <td>0.769873</td>
      <td>0.776622</td>
      <td>0.005607</td>
      <td>62</td>
      <td>0.806525</td>
      <td>0.813901</td>
      <td>0.804965</td>
      <td>0.808463</td>
      <td>0.003897</td>
      <td>15</td>
    </tr>
    <tr>
      <th>443</th>
      <td>1.969667</td>
      <td>0.102770</td>
      <td>0.513666</td>
      <td>0.036010</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775384</td>
      <td>0.782043</td>
      <td>0.771786</td>
      <td>0.776404</td>
      <td>0.004249</td>
      <td>63</td>
      <td>0.806667</td>
      <td>0.812908</td>
      <td>0.805532</td>
      <td>0.808369</td>
      <td>0.003243</td>
      <td>16</td>
    </tr>
    <tr>
      <th>575</th>
      <td>1.915331</td>
      <td>0.043224</td>
      <td>0.464333</td>
      <td>0.022216</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.771067</td>
      <td>0.785764</td>
      <td>0.772371</td>
      <td>0.776400</td>
      <td>0.006642</td>
      <td>64</td>
      <td>0.797730</td>
      <td>0.811489</td>
      <td>0.802128</td>
      <td>0.803783</td>
      <td>0.005738</td>
      <td>94</td>
    </tr>
    <tr>
      <th>629</th>
      <td>1.890002</td>
      <td>0.011223</td>
      <td>0.414329</td>
      <td>0.030269</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.771067</td>
      <td>0.785764</td>
      <td>0.772371</td>
      <td>0.776400</td>
      <td>0.006642</td>
      <td>64</td>
      <td>0.797730</td>
      <td>0.811489</td>
      <td>0.802128</td>
      <td>0.803783</td>
      <td>0.005738</td>
      <td>94</td>
    </tr>
    <tr>
      <th>521</th>
      <td>1.927332</td>
      <td>0.063926</td>
      <td>0.476999</td>
      <td>0.029406</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.771067</td>
      <td>0.785764</td>
      <td>0.772371</td>
      <td>0.776400</td>
      <td>0.006642</td>
      <td>64</td>
      <td>0.797730</td>
      <td>0.811489</td>
      <td>0.802128</td>
      <td>0.803783</td>
      <td>0.005738</td>
      <td>94</td>
    </tr>
    <tr>
      <th>467</th>
      <td>1.966001</td>
      <td>0.007273</td>
      <td>0.417737</td>
      <td>0.004999</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.771067</td>
      <td>0.785764</td>
      <td>0.772371</td>
      <td>0.776400</td>
      <td>0.006642</td>
      <td>64</td>
      <td>0.797730</td>
      <td>0.811489</td>
      <td>0.802128</td>
      <td>0.803783</td>
      <td>0.005738</td>
      <td>94</td>
    </tr>
    <tr>
      <th>16</th>
      <td>1.276667</td>
      <td>0.025592</td>
      <td>0.314333</td>
      <td>0.007847</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775883</td>
      <td>0.787125</td>
      <td>0.765348</td>
      <td>0.776119</td>
      <td>0.008892</td>
      <td>68</td>
      <td>0.802553</td>
      <td>0.813191</td>
      <td>0.803830</td>
      <td>0.806525</td>
      <td>0.004743</td>
      <td>58</td>
    </tr>
    <tr>
      <th>137</th>
      <td>2.025478</td>
      <td>0.138022</td>
      <td>0.486801</td>
      <td>0.012149</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.769208</td>
      <td>0.787829</td>
      <td>0.771269</td>
      <td>0.776102</td>
      <td>0.008335</td>
      <td>69</td>
      <td>0.789220</td>
      <td>0.807801</td>
      <td>0.792482</td>
      <td>0.796501</td>
      <td>0.008101</td>
      <td>113</td>
    </tr>
    <tr>
      <th>191</th>
      <td>2.040668</td>
      <td>0.022156</td>
      <td>0.424997</td>
      <td>0.016755</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.769208</td>
      <td>0.787829</td>
      <td>0.771269</td>
      <td>0.776102</td>
      <td>0.008335</td>
      <td>69</td>
      <td>0.789220</td>
      <td>0.807801</td>
      <td>0.792482</td>
      <td>0.796501</td>
      <td>0.008101</td>
      <td>113</td>
    </tr>
    <tr>
      <th>29</th>
      <td>1.905070</td>
      <td>0.059742</td>
      <td>0.409427</td>
      <td>0.037135</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.769208</td>
      <td>0.787829</td>
      <td>0.771269</td>
      <td>0.776102</td>
      <td>0.008335</td>
      <td>69</td>
      <td>0.789220</td>
      <td>0.807801</td>
      <td>0.792482</td>
      <td>0.796501</td>
      <td>0.008101</td>
      <td>113</td>
    </tr>
    <tr>
      <th>83</th>
      <td>2.061115</td>
      <td>0.070856</td>
      <td>0.417667</td>
      <td>0.033493</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.769208</td>
      <td>0.787829</td>
      <td>0.771269</td>
      <td>0.776102</td>
      <td>0.008335</td>
      <td>69</td>
      <td>0.789220</td>
      <td>0.807801</td>
      <td>0.792482</td>
      <td>0.796501</td>
      <td>0.008101</td>
      <td>113</td>
    </tr>
    <tr>
      <th>583</th>
      <td>2.103974</td>
      <td>0.054359</td>
      <td>0.318843</td>
      <td>0.026520</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.768889</td>
      <td>0.785875</td>
      <td>0.772947</td>
      <td>0.775904</td>
      <td>0.007243</td>
      <td>73</td>
      <td>0.789787</td>
      <td>0.807376</td>
      <td>0.795461</td>
      <td>0.797541</td>
      <td>0.007330</td>
      <td>109</td>
    </tr>
    <tr>
      <th>38</th>
      <td>2.088023</td>
      <td>0.038849</td>
      <td>0.441668</td>
      <td>0.042992</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.767422</td>
      <td>0.787609</td>
      <td>0.772163</td>
      <td>0.775732</td>
      <td>0.008619</td>
      <td>74</td>
      <td>0.787376</td>
      <td>0.807234</td>
      <td>0.793333</td>
      <td>0.795981</td>
      <td>0.008320</td>
      <td>119</td>
    </tr>
    <tr>
      <th>611</th>
      <td>2.073130</td>
      <td>0.018569</td>
      <td>0.397380</td>
      <td>0.006938</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.776976</td>
      <td>0.782673</td>
      <td>0.767394</td>
      <td>0.775681</td>
      <td>0.006305</td>
      <td>75</td>
      <td>0.807801</td>
      <td>0.813333</td>
      <td>0.804823</td>
      <td>0.808652</td>
      <td>0.003526</td>
      <td>13</td>
    </tr>
    <tr>
      <th>524</th>
      <td>2.884370</td>
      <td>0.311585</td>
      <td>0.489000</td>
      <td>0.096066</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.774737</td>
      <td>0.783075</td>
      <td>0.769005</td>
      <td>0.775606</td>
      <td>0.005777</td>
      <td>76</td>
      <td>0.807801</td>
      <td>0.815603</td>
      <td>0.805390</td>
      <td>0.809598</td>
      <td>0.004359</td>
      <td>8</td>
    </tr>
    <tr>
      <th>434</th>
      <td>1.916127</td>
      <td>0.062240</td>
      <td>0.471068</td>
      <td>0.066822</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.773106</td>
      <td>0.786780</td>
      <td>0.766461</td>
      <td>0.775449</td>
      <td>0.008459</td>
      <td>77</td>
      <td>0.802837</td>
      <td>0.814610</td>
      <td>0.803404</td>
      <td>0.806950</td>
      <td>0.005421</td>
      <td>51</td>
    </tr>
    <tr>
      <th>596</th>
      <td>1.885728</td>
      <td>0.026554</td>
      <td>0.436996</td>
      <td>0.016515</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.773106</td>
      <td>0.786780</td>
      <td>0.766461</td>
      <td>0.775449</td>
      <td>0.008459</td>
      <td>77</td>
      <td>0.802837</td>
      <td>0.814610</td>
      <td>0.803404</td>
      <td>0.806950</td>
      <td>0.005421</td>
      <td>51</td>
    </tr>
    <tr>
      <th>542</th>
      <td>1.826003</td>
      <td>0.021955</td>
      <td>0.472328</td>
      <td>0.005248</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.773106</td>
      <td>0.786780</td>
      <td>0.766461</td>
      <td>0.775449</td>
      <td>0.008459</td>
      <td>77</td>
      <td>0.802837</td>
      <td>0.814610</td>
      <td>0.803404</td>
      <td>0.806950</td>
      <td>0.005421</td>
      <td>51</td>
    </tr>
    <tr>
      <th>488</th>
      <td>1.931483</td>
      <td>0.054257</td>
      <td>0.423016</td>
      <td>0.034221</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.773106</td>
      <td>0.786780</td>
      <td>0.766461</td>
      <td>0.775449</td>
      <td>0.008459</td>
      <td>77</td>
      <td>0.802837</td>
      <td>0.814610</td>
      <td>0.803404</td>
      <td>0.806950</td>
      <td>0.005421</td>
      <td>51</td>
    </tr>
    <tr>
      <th>110</th>
      <td>1.915001</td>
      <td>0.021775</td>
      <td>0.438332</td>
      <td>0.038587</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.766092</td>
      <td>0.787571</td>
      <td>0.772003</td>
      <td>0.775222</td>
      <td>0.009059</td>
      <td>81</td>
      <td>0.785390</td>
      <td>0.807660</td>
      <td>0.794468</td>
      <td>0.795839</td>
      <td>0.009143</td>
      <td>120</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.958881</td>
      <td>0.028961</td>
      <td>0.403238</td>
      <td>0.033121</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.766092</td>
      <td>0.787571</td>
      <td>0.772003</td>
      <td>0.775222</td>
      <td>0.009059</td>
      <td>81</td>
      <td>0.785390</td>
      <td>0.807660</td>
      <td>0.794468</td>
      <td>0.795839</td>
      <td>0.009143</td>
      <td>120</td>
    </tr>
    <tr>
      <th>56</th>
      <td>1.965738</td>
      <td>0.047320</td>
      <td>0.413964</td>
      <td>0.026036</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.766092</td>
      <td>0.787571</td>
      <td>0.772003</td>
      <td>0.775222</td>
      <td>0.009059</td>
      <td>81</td>
      <td>0.785390</td>
      <td>0.807660</td>
      <td>0.794468</td>
      <td>0.795839</td>
      <td>0.009143</td>
      <td>120</td>
    </tr>
    <tr>
      <th>164</th>
      <td>1.956666</td>
      <td>0.058196</td>
      <td>0.460335</td>
      <td>0.032189</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.766092</td>
      <td>0.787571</td>
      <td>0.772003</td>
      <td>0.775222</td>
      <td>0.009059</td>
      <td>81</td>
      <td>0.785390</td>
      <td>0.807660</td>
      <td>0.794468</td>
      <td>0.795839</td>
      <td>0.009143</td>
      <td>120</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1.277332</td>
      <td>0.056722</td>
      <td>0.369330</td>
      <td>0.042991</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.774245</td>
      <td>0.786600</td>
      <td>0.764039</td>
      <td>0.774961</td>
      <td>0.009224</td>
      <td>85</td>
      <td>0.801844</td>
      <td>0.813050</td>
      <td>0.802411</td>
      <td>0.805768</td>
      <td>0.005154</td>
      <td>80</td>
    </tr>
    <tr>
      <th>115</th>
      <td>1.192335</td>
      <td>0.015285</td>
      <td>0.369999</td>
      <td>0.017666</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.774245</td>
      <td>0.786600</td>
      <td>0.764039</td>
      <td>0.774961</td>
      <td>0.009224</td>
      <td>85</td>
      <td>0.801844</td>
      <td>0.813050</td>
      <td>0.802411</td>
      <td>0.805768</td>
      <td>0.005154</td>
      <td>80</td>
    </tr>
    <tr>
      <th>169</th>
      <td>1.218688</td>
      <td>0.021596</td>
      <td>0.330363</td>
      <td>0.028152</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.774245</td>
      <td>0.786600</td>
      <td>0.764039</td>
      <td>0.774961</td>
      <td>0.009224</td>
      <td>85</td>
      <td>0.801844</td>
      <td>0.813050</td>
      <td>0.802411</td>
      <td>0.805768</td>
      <td>0.005154</td>
      <td>80</td>
    </tr>
    <tr>
      <th>61</th>
      <td>1.257333</td>
      <td>0.025694</td>
      <td>0.321334</td>
      <td>0.003094</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.774245</td>
      <td>0.786600</td>
      <td>0.764039</td>
      <td>0.774961</td>
      <td>0.009224</td>
      <td>85</td>
      <td>0.801844</td>
      <td>0.813050</td>
      <td>0.802411</td>
      <td>0.805768</td>
      <td>0.005154</td>
      <td>80</td>
    </tr>
    <tr>
      <th>199</th>
      <td>1.275546</td>
      <td>0.029553</td>
      <td>0.341146</td>
      <td>0.036487</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.768129</td>
      <td>0.782198</td>
      <td>0.774470</td>
      <td>0.774932</td>
      <td>0.005753</td>
      <td>89</td>
      <td>0.786809</td>
      <td>0.800993</td>
      <td>0.796312</td>
      <td>0.794704</td>
      <td>0.005901</td>
      <td>130</td>
    </tr>
    <tr>
      <th>37</th>
      <td>1.412710</td>
      <td>0.016019</td>
      <td>0.343358</td>
      <td>0.017485</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.767914</td>
      <td>0.782801</td>
      <td>0.774021</td>
      <td>0.774912</td>
      <td>0.006110</td>
      <td>90</td>
      <td>0.786667</td>
      <td>0.802128</td>
      <td>0.794610</td>
      <td>0.794468</td>
      <td>0.006313</td>
      <td>132</td>
    </tr>
    <tr>
      <th>11</th>
      <td>1.981366</td>
      <td>0.022657</td>
      <td>0.522665</td>
      <td>0.024238</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.765582</td>
      <td>0.786727</td>
      <td>0.772236</td>
      <td>0.774848</td>
      <td>0.008828</td>
      <td>91</td>
      <td>0.785248</td>
      <td>0.806525</td>
      <td>0.799007</td>
      <td>0.796927</td>
      <td>0.008810</td>
      <td>111</td>
    </tr>
    <tr>
      <th>10</th>
      <td>1.407448</td>
      <td>0.041570</td>
      <td>0.357264</td>
      <td>0.047097</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.768410</td>
      <td>0.783697</td>
      <td>0.772221</td>
      <td>0.774776</td>
      <td>0.006497</td>
      <td>92</td>
      <td>0.787801</td>
      <td>0.803404</td>
      <td>0.799149</td>
      <td>0.796785</td>
      <td>0.006586</td>
      <td>112</td>
    </tr>
    <tr>
      <th>557</th>
      <td>3.772792</td>
      <td>0.023460</td>
      <td>0.415409</td>
      <td>0.040023</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.768642</td>
      <td>0.784491</td>
      <td>0.771146</td>
      <td>0.774759</td>
      <td>0.006956</td>
      <td>93</td>
      <td>0.788936</td>
      <td>0.806383</td>
      <td>0.792908</td>
      <td>0.796076</td>
      <td>0.007467</td>
      <td>118</td>
    </tr>
    <tr>
      <th>584</th>
      <td>3.304071</td>
      <td>0.057716</td>
      <td>0.385999</td>
      <td>0.003266</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.768368</td>
      <td>0.786728</td>
      <td>0.768976</td>
      <td>0.774691</td>
      <td>0.008515</td>
      <td>94</td>
      <td>0.790071</td>
      <td>0.808936</td>
      <td>0.792340</td>
      <td>0.797116</td>
      <td>0.008409</td>
      <td>110</td>
    </tr>
    <tr>
      <th>200</th>
      <td>1.952724</td>
      <td>0.038646</td>
      <td>0.464522</td>
      <td>0.037852</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.768782</td>
      <td>0.784614</td>
      <td>0.770520</td>
      <td>0.774638</td>
      <td>0.007089</td>
      <td>95</td>
      <td>0.787801</td>
      <td>0.803688</td>
      <td>0.792482</td>
      <td>0.794657</td>
      <td>0.006665</td>
      <td>131</td>
    </tr>
    <tr>
      <th>568</th>
      <td>1.241985</td>
      <td>0.017041</td>
      <td>0.344881</td>
      <td>0.025121</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.772746</td>
      <td>0.782520</td>
      <td>0.768528</td>
      <td>0.774598</td>
      <td>0.005861</td>
      <td>96</td>
      <td>0.805390</td>
      <td>0.813901</td>
      <td>0.803262</td>
      <td>0.807518</td>
      <td>0.004596</td>
      <td>38</td>
    </tr>
    <tr>
      <th>514</th>
      <td>1.314003</td>
      <td>0.015582</td>
      <td>0.350331</td>
      <td>0.046430</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.772746</td>
      <td>0.782520</td>
      <td>0.768528</td>
      <td>0.774598</td>
      <td>0.005861</td>
      <td>96</td>
      <td>0.805390</td>
      <td>0.813901</td>
      <td>0.803262</td>
      <td>0.807518</td>
      <td>0.004596</td>
      <td>38</td>
    </tr>
    <tr>
      <th>622</th>
      <td>1.368998</td>
      <td>0.084147</td>
      <td>0.317333</td>
      <td>0.004112</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.772746</td>
      <td>0.782520</td>
      <td>0.768528</td>
      <td>0.774598</td>
      <td>0.005861</td>
      <td>96</td>
      <td>0.805390</td>
      <td>0.813901</td>
      <td>0.803262</td>
      <td>0.807518</td>
      <td>0.004596</td>
      <td>38</td>
    </tr>
    <tr>
      <th>460</th>
      <td>1.254711</td>
      <td>0.017246</td>
      <td>0.366707</td>
      <td>0.052661</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.772746</td>
      <td>0.782520</td>
      <td>0.768528</td>
      <td>0.774598</td>
      <td>0.005861</td>
      <td>96</td>
      <td>0.805390</td>
      <td>0.813901</td>
      <td>0.803262</td>
      <td>0.807518</td>
      <td>0.004596</td>
      <td>38</td>
    </tr>
    <tr>
      <th>163</th>
      <td>1.280669</td>
      <td>0.062256</td>
      <td>0.332328</td>
      <td>0.019706</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.766082</td>
      <td>0.783841</td>
      <td>0.773307</td>
      <td>0.774410</td>
      <td>0.007292</td>
      <td>100</td>
      <td>0.785957</td>
      <td>0.804113</td>
      <td>0.795887</td>
      <td>0.795319</td>
      <td>0.007423</td>
      <td>126</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.268797</td>
      <td>0.018513</td>
      <td>0.340168</td>
      <td>0.022448</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.766082</td>
      <td>0.783841</td>
      <td>0.773307</td>
      <td>0.774410</td>
      <td>0.007292</td>
      <td>100</td>
      <td>0.785957</td>
      <td>0.804113</td>
      <td>0.795887</td>
      <td>0.795319</td>
      <td>0.007423</td>
      <td>126</td>
    </tr>
    <tr>
      <th>55</th>
      <td>1.364556</td>
      <td>0.032615</td>
      <td>0.407186</td>
      <td>0.051521</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.766082</td>
      <td>0.783841</td>
      <td>0.773307</td>
      <td>0.774410</td>
      <td>0.007292</td>
      <td>100</td>
      <td>0.785957</td>
      <td>0.804113</td>
      <td>0.795887</td>
      <td>0.795319</td>
      <td>0.007423</td>
      <td>126</td>
    </tr>
    <tr>
      <th>109</th>
      <td>1.254670</td>
      <td>0.018375</td>
      <td>0.357329</td>
      <td>0.018837</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.766082</td>
      <td>0.783841</td>
      <td>0.773307</td>
      <td>0.774410</td>
      <td>0.007292</td>
      <td>100</td>
      <td>0.785957</td>
      <td>0.804113</td>
      <td>0.795887</td>
      <td>0.795319</td>
      <td>0.007423</td>
      <td>126</td>
    </tr>
    <tr>
      <th>190</th>
      <td>1.383002</td>
      <td>0.038478</td>
      <td>0.357662</td>
      <td>0.034470</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.767163</td>
      <td>0.782463</td>
      <td>0.773560</td>
      <td>0.774395</td>
      <td>0.006274</td>
      <td>104</td>
      <td>0.785957</td>
      <td>0.801986</td>
      <td>0.793901</td>
      <td>0.793948</td>
      <td>0.006544</td>
      <td>133</td>
    </tr>
    <tr>
      <th>82</th>
      <td>1.435249</td>
      <td>0.034499</td>
      <td>0.330420</td>
      <td>0.011197</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.767163</td>
      <td>0.782463</td>
      <td>0.773560</td>
      <td>0.774395</td>
      <td>0.006274</td>
      <td>104</td>
      <td>0.785957</td>
      <td>0.801986</td>
      <td>0.793901</td>
      <td>0.793948</td>
      <td>0.006544</td>
      <td>133</td>
    </tr>
    <tr>
      <th>28</th>
      <td>1.274454</td>
      <td>0.008623</td>
      <td>0.310006</td>
      <td>0.009781</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.767163</td>
      <td>0.782463</td>
      <td>0.773560</td>
      <td>0.774395</td>
      <td>0.006274</td>
      <td>104</td>
      <td>0.785957</td>
      <td>0.801986</td>
      <td>0.793901</td>
      <td>0.793948</td>
      <td>0.006544</td>
      <td>133</td>
    </tr>
    <tr>
      <th>136</th>
      <td>1.492297</td>
      <td>0.039771</td>
      <td>0.373417</td>
      <td>0.027545</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.767163</td>
      <td>0.782463</td>
      <td>0.773560</td>
      <td>0.774395</td>
      <td>0.006274</td>
      <td>104</td>
      <td>0.785957</td>
      <td>0.801986</td>
      <td>0.793901</td>
      <td>0.793948</td>
      <td>0.006544</td>
      <td>133</td>
    </tr>
    <tr>
      <th>632</th>
      <td>1.869667</td>
      <td>0.051614</td>
      <td>0.454050</td>
      <td>0.048268</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.773929</td>
      <td>0.780401</td>
      <td>0.767881</td>
      <td>0.774070</td>
      <td>0.005112</td>
      <td>108</td>
      <td>0.808652</td>
      <td>0.814326</td>
      <td>0.806241</td>
      <td>0.809740</td>
      <td>0.003389</td>
      <td>6</td>
    </tr>
    <tr>
      <th>556</th>
      <td>2.354670</td>
      <td>0.125236</td>
      <td>0.396333</td>
      <td>0.038352</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.768087</td>
      <td>0.783140</td>
      <td>0.770160</td>
      <td>0.773796</td>
      <td>0.006661</td>
      <td>109</td>
      <td>0.789078</td>
      <td>0.805248</td>
      <td>0.792766</td>
      <td>0.795697</td>
      <td>0.006919</td>
      <td>124</td>
    </tr>
    <tr>
      <th>475</th>
      <td>1.307334</td>
      <td>0.032705</td>
      <td>0.360331</td>
      <td>0.041073</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.772925</td>
      <td>0.782130</td>
      <td>0.765483</td>
      <td>0.773513</td>
      <td>0.006809</td>
      <td>110</td>
      <td>0.806950</td>
      <td>0.814752</td>
      <td>0.802979</td>
      <td>0.808227</td>
      <td>0.004890</td>
      <td>21</td>
    </tr>
    <tr>
      <th>151</th>
      <td>1.938670</td>
      <td>0.022866</td>
      <td>0.342330</td>
      <td>0.028395</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.767844</td>
      <td>0.784496</td>
      <td>0.768170</td>
      <td>0.773503</td>
      <td>0.007774</td>
      <td>111</td>
      <td>0.786809</td>
      <td>0.804539</td>
      <td>0.788936</td>
      <td>0.793428</td>
      <td>0.007905</td>
      <td>150</td>
    </tr>
    <tr>
      <th>448</th>
      <td>1.311002</td>
      <td>0.060072</td>
      <td>0.308332</td>
      <td>0.005735</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.772666</td>
      <td>0.782273</td>
      <td>0.764975</td>
      <td>0.773305</td>
      <td>0.007077</td>
      <td>112</td>
      <td>0.805248</td>
      <td>0.814043</td>
      <td>0.800709</td>
      <td>0.806667</td>
      <td>0.005535</td>
      <td>56</td>
    </tr>
    <tr>
      <th>547</th>
      <td>1.259333</td>
      <td>0.033070</td>
      <td>0.296666</td>
      <td>0.002058</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.772336</td>
      <td>0.783179</td>
      <td>0.763977</td>
      <td>0.773164</td>
      <td>0.007861</td>
      <td>113</td>
      <td>0.801702</td>
      <td>0.808369</td>
      <td>0.798723</td>
      <td>0.802931</td>
      <td>0.004033</td>
      <td>99</td>
    </tr>
    <tr>
      <th>493</th>
      <td>1.246337</td>
      <td>0.022571</td>
      <td>0.353699</td>
      <td>0.042436</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.772336</td>
      <td>0.783179</td>
      <td>0.763977</td>
      <td>0.773164</td>
      <td>0.007861</td>
      <td>113</td>
      <td>0.801702</td>
      <td>0.808369</td>
      <td>0.798723</td>
      <td>0.802931</td>
      <td>0.004033</td>
      <td>99</td>
    </tr>
    <tr>
      <th>439</th>
      <td>1.260923</td>
      <td>0.011519</td>
      <td>0.330373</td>
      <td>0.025195</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.772336</td>
      <td>0.783179</td>
      <td>0.763977</td>
      <td>0.773164</td>
      <td>0.007861</td>
      <td>113</td>
      <td>0.801702</td>
      <td>0.808369</td>
      <td>0.798723</td>
      <td>0.802931</td>
      <td>0.004033</td>
      <td>99</td>
    </tr>
    <tr>
      <th>601</th>
      <td>1.415894</td>
      <td>0.090290</td>
      <td>0.509213</td>
      <td>0.061243</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.772336</td>
      <td>0.783179</td>
      <td>0.763977</td>
      <td>0.773164</td>
      <td>0.007861</td>
      <td>113</td>
      <td>0.801702</td>
      <td>0.808369</td>
      <td>0.798723</td>
      <td>0.802931</td>
      <td>0.004033</td>
      <td>99</td>
    </tr>
    <tr>
      <th>476</th>
      <td>2.068198</td>
      <td>0.042398</td>
      <td>0.397980</td>
      <td>0.018027</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.773709</td>
      <td>0.779027</td>
      <td>0.766010</td>
      <td>0.772915</td>
      <td>0.005344</td>
      <td>117</td>
      <td>0.809787</td>
      <td>0.813759</td>
      <td>0.805248</td>
      <td>0.809598</td>
      <td>0.003477</td>
      <td>7</td>
    </tr>
    <tr>
      <th>487</th>
      <td>1.239009</td>
      <td>0.006299</td>
      <td>0.303995</td>
      <td>0.006167</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.771720</td>
      <td>0.781247</td>
      <td>0.765468</td>
      <td>0.772812</td>
      <td>0.006488</td>
      <td>118</td>
      <td>0.802411</td>
      <td>0.812482</td>
      <td>0.803688</td>
      <td>0.806194</td>
      <td>0.004477</td>
      <td>70</td>
    </tr>
    <tr>
      <th>433</th>
      <td>1.281339</td>
      <td>0.044315</td>
      <td>0.392203</td>
      <td>0.013012</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.771720</td>
      <td>0.781247</td>
      <td>0.765468</td>
      <td>0.772812</td>
      <td>0.006488</td>
      <td>118</td>
      <td>0.802411</td>
      <td>0.812482</td>
      <td>0.803688</td>
      <td>0.806194</td>
      <td>0.004477</td>
      <td>70</td>
    </tr>
    <tr>
      <th>541</th>
      <td>1.253336</td>
      <td>0.008381</td>
      <td>0.330666</td>
      <td>0.023798</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.771720</td>
      <td>0.781247</td>
      <td>0.765468</td>
      <td>0.772812</td>
      <td>0.006488</td>
      <td>118</td>
      <td>0.802411</td>
      <td>0.812482</td>
      <td>0.803688</td>
      <td>0.806194</td>
      <td>0.004477</td>
      <td>70</td>
    </tr>
    <tr>
      <th>595</th>
      <td>1.222779</td>
      <td>0.034110</td>
      <td>0.354002</td>
      <td>0.049603</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.771720</td>
      <td>0.781247</td>
      <td>0.765468</td>
      <td>0.772812</td>
      <td>0.006488</td>
      <td>118</td>
      <td>0.802411</td>
      <td>0.812482</td>
      <td>0.803688</td>
      <td>0.806194</td>
      <td>0.004477</td>
      <td>70</td>
    </tr>
    <tr>
      <th>442</th>
      <td>1.406330</td>
      <td>0.036707</td>
      <td>0.401000</td>
      <td>0.006482</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.771233</td>
      <td>0.781216</td>
      <td>0.765522</td>
      <td>0.772657</td>
      <td>0.006486</td>
      <td>122</td>
      <td>0.804539</td>
      <td>0.813759</td>
      <td>0.801277</td>
      <td>0.806525</td>
      <td>0.005286</td>
      <td>58</td>
    </tr>
    <tr>
      <th>470</th>
      <td>2.114453</td>
      <td>0.044914</td>
      <td>0.581727</td>
      <td>0.086769</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.771989</td>
      <td>0.780162</td>
      <td>0.765484</td>
      <td>0.772545</td>
      <td>0.006005</td>
      <td>123</td>
      <td>0.808652</td>
      <td>0.815461</td>
      <td>0.805248</td>
      <td>0.809787</td>
      <td>0.004246</td>
      <td>5</td>
    </tr>
    <tr>
      <th>152</th>
      <td>3.096001</td>
      <td>0.040355</td>
      <td>0.432000</td>
      <td>0.054718</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.764538</td>
      <td>0.782933</td>
      <td>0.769974</td>
      <td>0.772482</td>
      <td>0.007716</td>
      <td>124</td>
      <td>0.784681</td>
      <td>0.803688</td>
      <td>0.791348</td>
      <td>0.793239</td>
      <td>0.007874</td>
      <td>151</td>
    </tr>
    <tr>
      <th>631</th>
      <td>1.243668</td>
      <td>0.029779</td>
      <td>0.370669</td>
      <td>0.023794</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.770474</td>
      <td>0.782325</td>
      <td>0.764228</td>
      <td>0.772342</td>
      <td>0.007505</td>
      <td>125</td>
      <td>0.804539</td>
      <td>0.814894</td>
      <td>0.801418</td>
      <td>0.806950</td>
      <td>0.005759</td>
      <td>51</td>
    </tr>
    <tr>
      <th>92</th>
      <td>2.531002</td>
      <td>0.038994</td>
      <td>0.409334</td>
      <td>0.025490</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.761832</td>
      <td>0.784704</td>
      <td>0.769872</td>
      <td>0.772136</td>
      <td>0.009474</td>
      <td>126</td>
      <td>0.779149</td>
      <td>0.802837</td>
      <td>0.788652</td>
      <td>0.790213</td>
      <td>0.009733</td>
      <td>167</td>
    </tr>
    <tr>
      <th>469</th>
      <td>1.301791</td>
      <td>0.023439</td>
      <td>0.428664</td>
      <td>0.018660</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.772238</td>
      <td>0.781431</td>
      <td>0.762734</td>
      <td>0.772134</td>
      <td>0.007634</td>
      <td>127</td>
      <td>0.806667</td>
      <td>0.815319</td>
      <td>0.800993</td>
      <td>0.807660</td>
      <td>0.005891</td>
      <td>36</td>
    </tr>
    <tr>
      <th>637</th>
      <td>1.236269</td>
      <td>0.009539</td>
      <td>0.307414</td>
      <td>0.005712</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.772001</td>
      <td>0.781507</td>
      <td>0.762547</td>
      <td>0.772018</td>
      <td>0.007740</td>
      <td>128</td>
      <td>0.806667</td>
      <td>0.814752</td>
      <td>0.801135</td>
      <td>0.807518</td>
      <td>0.005592</td>
      <td>38</td>
    </tr>
    <tr>
      <th>124</th>
      <td>1.996000</td>
      <td>0.043364</td>
      <td>0.377666</td>
      <td>0.051226</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.764709</td>
      <td>0.782577</td>
      <td>0.768499</td>
      <td>0.771928</td>
      <td>0.007687</td>
      <td>129</td>
      <td>0.784681</td>
      <td>0.803404</td>
      <td>0.789929</td>
      <td>0.792671</td>
      <td>0.007886</td>
      <td>153</td>
    </tr>
    <tr>
      <th>173</th>
      <td>1.949000</td>
      <td>0.064687</td>
      <td>0.448330</td>
      <td>0.000941</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.763358</td>
      <td>0.786985</td>
      <td>0.764612</td>
      <td>0.771652</td>
      <td>0.010854</td>
      <td>130</td>
      <td>0.782979</td>
      <td>0.805957</td>
      <td>0.800142</td>
      <td>0.796359</td>
      <td>0.009755</td>
      <td>117</td>
    </tr>
    <tr>
      <th>638</th>
      <td>1.940116</td>
      <td>0.014784</td>
      <td>0.390332</td>
      <td>0.012764</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.771161</td>
      <td>0.778831</td>
      <td>0.764602</td>
      <td>0.771532</td>
      <td>0.005815</td>
      <td>131</td>
      <td>0.807801</td>
      <td>0.814043</td>
      <td>0.804681</td>
      <td>0.808842</td>
      <td>0.003892</td>
      <td>12</td>
    </tr>
    <tr>
      <th>610</th>
      <td>1.238333</td>
      <td>0.021914</td>
      <td>0.324665</td>
      <td>0.017782</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.771456</td>
      <td>0.782246</td>
      <td>0.760748</td>
      <td>0.771483</td>
      <td>0.008776</td>
      <td>132</td>
      <td>0.804113</td>
      <td>0.814184</td>
      <td>0.800426</td>
      <td>0.806241</td>
      <td>0.005815</td>
      <td>64</td>
    </tr>
    <tr>
      <th>604</th>
      <td>1.305668</td>
      <td>0.012257</td>
      <td>0.373665</td>
      <td>0.033480</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.771054</td>
      <td>0.779581</td>
      <td>0.763584</td>
      <td>0.771406</td>
      <td>0.006536</td>
      <td>133</td>
      <td>0.804113</td>
      <td>0.812199</td>
      <td>0.801277</td>
      <td>0.805863</td>
      <td>0.004627</td>
      <td>77</td>
    </tr>
    <tr>
      <th>628</th>
      <td>1.269667</td>
      <td>0.054012</td>
      <td>0.312998</td>
      <td>0.011521</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.765340</td>
      <td>0.780370</td>
      <td>0.768504</td>
      <td>0.771404</td>
      <td>0.006470</td>
      <td>134</td>
      <td>0.793333</td>
      <td>0.805106</td>
      <td>0.799291</td>
      <td>0.799243</td>
      <td>0.004806</td>
      <td>105</td>
    </tr>
    <tr>
      <th>520</th>
      <td>1.259332</td>
      <td>0.027328</td>
      <td>0.299666</td>
      <td>0.015195</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.765340</td>
      <td>0.780370</td>
      <td>0.768504</td>
      <td>0.771404</td>
      <td>0.006470</td>
      <td>134</td>
      <td>0.793333</td>
      <td>0.805106</td>
      <td>0.799291</td>
      <td>0.799243</td>
      <td>0.004806</td>
      <td>105</td>
    </tr>
    <tr>
      <th>466</th>
      <td>1.239880</td>
      <td>0.028804</td>
      <td>0.323795</td>
      <td>0.039440</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.765340</td>
      <td>0.780370</td>
      <td>0.768504</td>
      <td>0.771404</td>
      <td>0.006470</td>
      <td>134</td>
      <td>0.793333</td>
      <td>0.805106</td>
      <td>0.799291</td>
      <td>0.799243</td>
      <td>0.004806</td>
      <td>105</td>
    </tr>
    <tr>
      <th>574</th>
      <td>1.264000</td>
      <td>0.002159</td>
      <td>0.349333</td>
      <td>0.028160</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.765340</td>
      <td>0.780370</td>
      <td>0.768504</td>
      <td>0.771404</td>
      <td>0.006470</td>
      <td>134</td>
      <td>0.793333</td>
      <td>0.805106</td>
      <td>0.799291</td>
      <td>0.799243</td>
      <td>0.004806</td>
      <td>105</td>
    </tr>
    <tr>
      <th>125</th>
      <td>3.151670</td>
      <td>0.078705</td>
      <td>0.406997</td>
      <td>0.047464</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.763351</td>
      <td>0.780009</td>
      <td>0.770583</td>
      <td>0.771314</td>
      <td>0.006820</td>
      <td>138</td>
      <td>0.782837</td>
      <td>0.800851</td>
      <td>0.791348</td>
      <td>0.791678</td>
      <td>0.007358</td>
      <td>158</td>
    </tr>
    <tr>
      <th>65</th>
      <td>2.564911</td>
      <td>0.018678</td>
      <td>0.420075</td>
      <td>0.022736</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.761644</td>
      <td>0.781667</td>
      <td>0.770454</td>
      <td>0.771255</td>
      <td>0.008194</td>
      <td>139</td>
      <td>0.778865</td>
      <td>0.799858</td>
      <td>0.789787</td>
      <td>0.789504</td>
      <td>0.008573</td>
      <td>168</td>
    </tr>
    <tr>
      <th>91</th>
      <td>1.627335</td>
      <td>0.015586</td>
      <td>0.327666</td>
      <td>0.005440</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.762949</td>
      <td>0.781185</td>
      <td>0.768586</td>
      <td>0.770907</td>
      <td>0.007623</td>
      <td>140</td>
      <td>0.779716</td>
      <td>0.798865</td>
      <td>0.786950</td>
      <td>0.788511</td>
      <td>0.007895</td>
      <td>169</td>
    </tr>
    <tr>
      <th>172</th>
      <td>1.392021</td>
      <td>0.028346</td>
      <td>0.335666</td>
      <td>0.041314</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.765958</td>
      <td>0.783072</td>
      <td>0.761832</td>
      <td>0.770287</td>
      <td>0.009196</td>
      <td>141</td>
      <td>0.785248</td>
      <td>0.802411</td>
      <td>0.798865</td>
      <td>0.795508</td>
      <td>0.007398</td>
      <td>125</td>
    </tr>
    <tr>
      <th>179</th>
      <td>1.927334</td>
      <td>0.002621</td>
      <td>0.419996</td>
      <td>0.029936</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775225</td>
      <td>0.791291</td>
      <td>0.744001</td>
      <td>0.770172</td>
      <td>0.019634</td>
      <td>142</td>
      <td>0.800993</td>
      <td>0.816312</td>
      <td>0.797305</td>
      <td>0.804870</td>
      <td>0.008230</td>
      <td>90</td>
    </tr>
    <tr>
      <th>64</th>
      <td>1.646333</td>
      <td>0.019344</td>
      <td>0.307999</td>
      <td>0.010616</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.760342</td>
      <td>0.779635</td>
      <td>0.767314</td>
      <td>0.769097</td>
      <td>0.007977</td>
      <td>143</td>
      <td>0.777730</td>
      <td>0.798014</td>
      <td>0.786950</td>
      <td>0.787565</td>
      <td>0.008292</td>
      <td>173</td>
    </tr>
    <tr>
      <th>471</th>
      <td>0.672999</td>
      <td>0.021403</td>
      <td>0.266690</td>
      <td>0.030926</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.763351</td>
      <td>0.775374</td>
      <td>0.765962</td>
      <td>0.768229</td>
      <td>0.005163</td>
      <td>144</td>
      <td>0.785957</td>
      <td>0.798723</td>
      <td>0.790355</td>
      <td>0.791678</td>
      <td>0.005295</td>
      <td>158</td>
    </tr>
    <tr>
      <th>462</th>
      <td>0.577406</td>
      <td>0.037120</td>
      <td>0.215168</td>
      <td>0.027924</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.763137</td>
      <td>0.775462</td>
      <td>0.765049</td>
      <td>0.767883</td>
      <td>0.005416</td>
      <td>145</td>
      <td>0.788085</td>
      <td>0.800284</td>
      <td>0.792482</td>
      <td>0.793617</td>
      <td>0.005044</td>
      <td>141</td>
    </tr>
    <tr>
      <th>516</th>
      <td>0.531670</td>
      <td>0.028052</td>
      <td>0.207998</td>
      <td>0.000816</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.763137</td>
      <td>0.775462</td>
      <td>0.765049</td>
      <td>0.767883</td>
      <td>0.005416</td>
      <td>145</td>
      <td>0.788085</td>
      <td>0.800284</td>
      <td>0.792482</td>
      <td>0.793617</td>
      <td>0.005044</td>
      <td>141</td>
    </tr>
    <tr>
      <th>624</th>
      <td>0.517004</td>
      <td>0.030242</td>
      <td>0.224995</td>
      <td>0.020314</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.763137</td>
      <td>0.775462</td>
      <td>0.765049</td>
      <td>0.767883</td>
      <td>0.005416</td>
      <td>145</td>
      <td>0.788085</td>
      <td>0.800284</td>
      <td>0.792482</td>
      <td>0.793617</td>
      <td>0.005044</td>
      <td>141</td>
    </tr>
    <tr>
      <th>570</th>
      <td>0.476003</td>
      <td>0.032259</td>
      <td>0.213996</td>
      <td>0.034911</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.763137</td>
      <td>0.775462</td>
      <td>0.765049</td>
      <td>0.767883</td>
      <td>0.005416</td>
      <td>145</td>
      <td>0.788085</td>
      <td>0.800284</td>
      <td>0.792482</td>
      <td>0.793617</td>
      <td>0.005044</td>
      <td>141</td>
    </tr>
    <tr>
      <th>633</th>
      <td>0.569333</td>
      <td>0.011812</td>
      <td>0.227336</td>
      <td>0.035237</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.764147</td>
      <td>0.774621</td>
      <td>0.764711</td>
      <td>0.767827</td>
      <td>0.004810</td>
      <td>149</td>
      <td>0.788085</td>
      <td>0.799007</td>
      <td>0.790213</td>
      <td>0.792435</td>
      <td>0.004728</td>
      <td>154</td>
    </tr>
    <tr>
      <th>527</th>
      <td>3.205918</td>
      <td>0.070578</td>
      <td>0.428516</td>
      <td>0.046472</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.758609</td>
      <td>0.777149</td>
      <td>0.767666</td>
      <td>0.767808</td>
      <td>0.007569</td>
      <td>150</td>
      <td>0.777305</td>
      <td>0.796454</td>
      <td>0.787234</td>
      <td>0.786998</td>
      <td>0.007819</td>
      <td>174</td>
    </tr>
    <tr>
      <th>96</th>
      <td>0.687998</td>
      <td>0.010676</td>
      <td>0.202667</td>
      <td>0.013425</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.762929</td>
      <td>0.773929</td>
      <td>0.765798</td>
      <td>0.767552</td>
      <td>0.004659</td>
      <td>151</td>
      <td>0.786099</td>
      <td>0.797305</td>
      <td>0.790638</td>
      <td>0.791348</td>
      <td>0.004602</td>
      <td>164</td>
    </tr>
    <tr>
      <th>444</th>
      <td>0.644998</td>
      <td>0.016970</td>
      <td>0.205000</td>
      <td>0.005100</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.762160</td>
      <td>0.775143</td>
      <td>0.764484</td>
      <td>0.767262</td>
      <td>0.005653</td>
      <td>152</td>
      <td>0.787518</td>
      <td>0.800000</td>
      <td>0.791348</td>
      <td>0.792955</td>
      <td>0.005221</td>
      <td>152</td>
    </tr>
    <tr>
      <th>178</th>
      <td>1.260334</td>
      <td>0.030379</td>
      <td>0.370666</td>
      <td>0.034983</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.775006</td>
      <td>0.787428</td>
      <td>0.738369</td>
      <td>0.766935</td>
      <td>0.020826</td>
      <td>153</td>
      <td>0.801277</td>
      <td>0.812766</td>
      <td>0.795035</td>
      <td>0.803026</td>
      <td>0.007343</td>
      <td>98</td>
    </tr>
    <tr>
      <th>526</th>
      <td>2.700808</td>
      <td>0.269106</td>
      <td>0.362333</td>
      <td>0.047935</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.759256</td>
      <td>0.775020</td>
      <td>0.766226</td>
      <td>0.766834</td>
      <td>0.006450</td>
      <td>154</td>
      <td>0.777730</td>
      <td>0.794043</td>
      <td>0.785532</td>
      <td>0.785768</td>
      <td>0.006661</td>
      <td>179</td>
    </tr>
    <tr>
      <th>555</th>
      <td>0.882999</td>
      <td>0.027313</td>
      <td>0.198000</td>
      <td>0.010034</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.760368</td>
      <td>0.775340</td>
      <td>0.764389</td>
      <td>0.766699</td>
      <td>0.006327</td>
      <td>155</td>
      <td>0.780709</td>
      <td>0.796312</td>
      <td>0.786383</td>
      <td>0.787801</td>
      <td>0.006448</td>
      <td>172</td>
    </tr>
    <tr>
      <th>582</th>
      <td>0.888332</td>
      <td>0.019938</td>
      <td>0.211004</td>
      <td>0.029136</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.761108</td>
      <td>0.774509</td>
      <td>0.763698</td>
      <td>0.766438</td>
      <td>0.005804</td>
      <td>156</td>
      <td>0.780142</td>
      <td>0.794326</td>
      <td>0.783972</td>
      <td>0.786147</td>
      <td>0.005991</td>
      <td>176</td>
    </tr>
    <tr>
      <th>499</th>
      <td>1.946101</td>
      <td>0.027526</td>
      <td>0.331509</td>
      <td>0.034295</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.757729</td>
      <td>0.774603</td>
      <td>0.766819</td>
      <td>0.766384</td>
      <td>0.006895</td>
      <td>157</td>
      <td>0.777305</td>
      <td>0.795177</td>
      <td>0.787234</td>
      <td>0.786572</td>
      <td>0.007311</td>
      <td>175</td>
    </tr>
    <tr>
      <th>69</th>
      <td>0.667404</td>
      <td>0.027986</td>
      <td>0.196668</td>
      <td>0.013196</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.761784</td>
      <td>0.774561</td>
      <td>0.762749</td>
      <td>0.766364</td>
      <td>0.005809</td>
      <td>158</td>
      <td>0.786809</td>
      <td>0.799291</td>
      <td>0.789787</td>
      <td>0.791962</td>
      <td>0.005323</td>
      <td>157</td>
    </tr>
    <tr>
      <th>606</th>
      <td>0.585673</td>
      <td>0.028166</td>
      <td>0.209661</td>
      <td>0.016774</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.760517</td>
      <td>0.774487</td>
      <td>0.764012</td>
      <td>0.766339</td>
      <td>0.005936</td>
      <td>159</td>
      <td>0.787376</td>
      <td>0.800426</td>
      <td>0.793050</td>
      <td>0.793617</td>
      <td>0.005343</td>
      <td>141</td>
    </tr>
    <tr>
      <th>33</th>
      <td>0.583034</td>
      <td>0.040029</td>
      <td>0.224668</td>
      <td>0.011729</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.758341</td>
      <td>0.774449</td>
      <td>0.763856</td>
      <td>0.765549</td>
      <td>0.006684</td>
      <td>160</td>
      <td>0.783262</td>
      <td>0.799574</td>
      <td>0.791773</td>
      <td>0.791537</td>
      <td>0.006661</td>
      <td>160</td>
    </tr>
    <tr>
      <th>195</th>
      <td>0.492335</td>
      <td>0.013024</td>
      <td>0.200334</td>
      <td>0.010138</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.758341</td>
      <td>0.774449</td>
      <td>0.763856</td>
      <td>0.765549</td>
      <td>0.006684</td>
      <td>160</td>
      <td>0.783262</td>
      <td>0.799574</td>
      <td>0.791773</td>
      <td>0.791537</td>
      <td>0.006661</td>
      <td>160</td>
    </tr>
    <tr>
      <th>141</th>
      <td>0.478995</td>
      <td>0.018404</td>
      <td>0.200336</td>
      <td>0.018189</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.758341</td>
      <td>0.774449</td>
      <td>0.763856</td>
      <td>0.765549</td>
      <td>0.006684</td>
      <td>160</td>
      <td>0.783262</td>
      <td>0.799574</td>
      <td>0.791773</td>
      <td>0.791537</td>
      <td>0.006661</td>
      <td>160</td>
    </tr>
    <tr>
      <th>87</th>
      <td>0.532998</td>
      <td>0.038740</td>
      <td>0.207003</td>
      <td>0.016312</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.758341</td>
      <td>0.774449</td>
      <td>0.763856</td>
      <td>0.765549</td>
      <td>0.006684</td>
      <td>160</td>
      <td>0.783262</td>
      <td>0.799574</td>
      <td>0.791773</td>
      <td>0.791537</td>
      <td>0.006661</td>
      <td>160</td>
    </tr>
    <tr>
      <th>500</th>
      <td>2.889650</td>
      <td>0.028101</td>
      <td>0.405694</td>
      <td>0.025862</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.757353</td>
      <td>0.773316</td>
      <td>0.765383</td>
      <td>0.765351</td>
      <td>0.006517</td>
      <td>164</td>
      <td>0.776454</td>
      <td>0.793333</td>
      <td>0.785532</td>
      <td>0.785106</td>
      <td>0.006898</td>
      <td>181</td>
    </tr>
    <tr>
      <th>42</th>
      <td>0.549428</td>
      <td>0.014789</td>
      <td>0.189332</td>
      <td>0.008953</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.757757</td>
      <td>0.774242</td>
      <td>0.762362</td>
      <td>0.764787</td>
      <td>0.006945</td>
      <td>165</td>
      <td>0.782695</td>
      <td>0.799007</td>
      <td>0.792340</td>
      <td>0.791348</td>
      <td>0.006696</td>
      <td>164</td>
    </tr>
    <tr>
      <th>123</th>
      <td>0.839667</td>
      <td>0.063611</td>
      <td>0.204662</td>
      <td>0.026707</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.757953</td>
      <td>0.775337</td>
      <td>0.760958</td>
      <td>0.764749</td>
      <td>0.007586</td>
      <td>166</td>
      <td>0.777589</td>
      <td>0.795461</td>
      <td>0.782128</td>
      <td>0.785059</td>
      <td>0.007585</td>
      <td>183</td>
    </tr>
    <tr>
      <th>522</th>
      <td>0.768000</td>
      <td>0.021279</td>
      <td>0.229000</td>
      <td>0.043687</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.759474</td>
      <td>0.770588</td>
      <td>0.764150</td>
      <td>0.764738</td>
      <td>0.004556</td>
      <td>167</td>
      <td>0.781844</td>
      <td>0.794184</td>
      <td>0.789362</td>
      <td>0.788463</td>
      <td>0.005078</td>
      <td>170</td>
    </tr>
    <tr>
      <th>168</th>
      <td>0.542997</td>
      <td>0.024386</td>
      <td>0.235667</td>
      <td>0.034414</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.759464</td>
      <td>0.773513</td>
      <td>0.760570</td>
      <td>0.764516</td>
      <td>0.006378</td>
      <td>168</td>
      <td>0.786099</td>
      <td>0.800709</td>
      <td>0.794043</td>
      <td>0.793617</td>
      <td>0.005972</td>
      <td>146</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.522663</td>
      <td>0.040855</td>
      <td>0.212141</td>
      <td>0.023395</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.759464</td>
      <td>0.773513</td>
      <td>0.760570</td>
      <td>0.764516</td>
      <td>0.006378</td>
      <td>168</td>
      <td>0.786099</td>
      <td>0.800709</td>
      <td>0.794043</td>
      <td>0.793617</td>
      <td>0.005972</td>
      <td>146</td>
    </tr>
    <tr>
      <th>60</th>
      <td>0.549333</td>
      <td>0.014291</td>
      <td>0.184332</td>
      <td>0.007587</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.759464</td>
      <td>0.773513</td>
      <td>0.760570</td>
      <td>0.764516</td>
      <td>0.006378</td>
      <td>168</td>
      <td>0.786099</td>
      <td>0.800709</td>
      <td>0.794043</td>
      <td>0.793617</td>
      <td>0.005972</td>
      <td>146</td>
    </tr>
    <tr>
      <th>114</th>
      <td>0.485055</td>
      <td>0.023503</td>
      <td>0.218001</td>
      <td>0.015750</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.759464</td>
      <td>0.773513</td>
      <td>0.760570</td>
      <td>0.764516</td>
      <td>0.006378</td>
      <td>168</td>
      <td>0.786099</td>
      <td>0.800709</td>
      <td>0.794043</td>
      <td>0.793617</td>
      <td>0.005972</td>
      <td>146</td>
    </tr>
    <tr>
      <th>543</th>
      <td>0.479667</td>
      <td>0.019189</td>
      <td>0.207669</td>
      <td>0.014005</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.759607</td>
      <td>0.774040</td>
      <td>0.759580</td>
      <td>0.764409</td>
      <td>0.006810</td>
      <td>172</td>
      <td>0.787234</td>
      <td>0.801418</td>
      <td>0.793191</td>
      <td>0.793948</td>
      <td>0.005815</td>
      <td>133</td>
    </tr>
    <tr>
      <th>489</th>
      <td>0.511707</td>
      <td>0.033052</td>
      <td>0.225998</td>
      <td>0.037969</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.759607</td>
      <td>0.774040</td>
      <td>0.759580</td>
      <td>0.764409</td>
      <td>0.006810</td>
      <td>172</td>
      <td>0.787234</td>
      <td>0.801418</td>
      <td>0.793191</td>
      <td>0.793948</td>
      <td>0.005815</td>
      <td>133</td>
    </tr>
    <tr>
      <th>597</th>
      <td>0.492350</td>
      <td>0.022918</td>
      <td>0.196667</td>
      <td>0.015109</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.759607</td>
      <td>0.774040</td>
      <td>0.759580</td>
      <td>0.764409</td>
      <td>0.006810</td>
      <td>172</td>
      <td>0.787234</td>
      <td>0.801418</td>
      <td>0.793191</td>
      <td>0.793948</td>
      <td>0.005815</td>
      <td>133</td>
    </tr>
    <tr>
      <th>435</th>
      <td>0.541374</td>
      <td>0.052567</td>
      <td>0.203684</td>
      <td>0.018761</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.759607</td>
      <td>0.774040</td>
      <td>0.759580</td>
      <td>0.764409</td>
      <td>0.006810</td>
      <td>172</td>
      <td>0.787234</td>
      <td>0.801418</td>
      <td>0.793191</td>
      <td>0.793948</td>
      <td>0.005815</td>
      <td>133</td>
    </tr>
    <tr>
      <th>495</th>
      <td>0.777344</td>
      <td>0.009596</td>
      <td>0.211680</td>
      <td>0.019492</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.756822</td>
      <td>0.769519</td>
      <td>0.765323</td>
      <td>0.763888</td>
      <td>0.005282</td>
      <td>176</td>
      <td>0.780567</td>
      <td>0.793901</td>
      <td>0.790496</td>
      <td>0.788322</td>
      <td>0.005656</td>
      <td>171</td>
    </tr>
    <tr>
      <th>150</th>
      <td>0.866997</td>
      <td>0.053741</td>
      <td>0.206669</td>
      <td>0.019068</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.758904</td>
      <td>0.771657</td>
      <td>0.761082</td>
      <td>0.763881</td>
      <td>0.005570</td>
      <td>177</td>
      <td>0.776879</td>
      <td>0.790496</td>
      <td>0.780426</td>
      <td>0.782600</td>
      <td>0.005768</td>
      <td>193</td>
    </tr>
    <tr>
      <th>528</th>
      <td>0.799543</td>
      <td>0.067566</td>
      <td>0.206338</td>
      <td>0.020435</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.755863</td>
      <td>0.769573</td>
      <td>0.763123</td>
      <td>0.762853</td>
      <td>0.005600</td>
      <td>178</td>
      <td>0.783546</td>
      <td>0.797447</td>
      <td>0.792340</td>
      <td>0.791111</td>
      <td>0.005741</td>
      <td>166</td>
    </tr>
    <tr>
      <th>36</th>
      <td>0.554665</td>
      <td>0.011898</td>
      <td>0.198004</td>
      <td>0.002160</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.755037</td>
      <td>0.771960</td>
      <td>0.761070</td>
      <td>0.762689</td>
      <td>0.007003</td>
      <td>179</td>
      <td>0.772624</td>
      <td>0.789929</td>
      <td>0.781135</td>
      <td>0.781229</td>
      <td>0.007065</td>
      <td>217</td>
    </tr>
    <tr>
      <th>501</th>
      <td>0.762103</td>
      <td>0.012105</td>
      <td>0.200998</td>
      <td>0.021401</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.755166</td>
      <td>0.770425</td>
      <td>0.762191</td>
      <td>0.762594</td>
      <td>0.006236</td>
      <td>180</td>
      <td>0.784397</td>
      <td>0.799433</td>
      <td>0.792624</td>
      <td>0.792151</td>
      <td>0.006147</td>
      <td>156</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.570330</td>
      <td>0.053770</td>
      <td>0.186669</td>
      <td>0.000944</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.753249</td>
      <td>0.771208</td>
      <td>0.763040</td>
      <td>0.762499</td>
      <td>0.007342</td>
      <td>181</td>
      <td>0.772340</td>
      <td>0.790496</td>
      <td>0.789504</td>
      <td>0.784113</td>
      <td>0.008335</td>
      <td>187</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.592978</td>
      <td>0.002174</td>
      <td>0.196973</td>
      <td>0.012592</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.753906</td>
      <td>0.770846</td>
      <td>0.761982</td>
      <td>0.762245</td>
      <td>0.006918</td>
      <td>182</td>
      <td>0.772908</td>
      <td>0.790071</td>
      <td>0.783546</td>
      <td>0.782175</td>
      <td>0.007074</td>
      <td>199</td>
    </tr>
    <tr>
      <th>54</th>
      <td>0.568622</td>
      <td>0.044774</td>
      <td>0.208995</td>
      <td>0.027276</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.753906</td>
      <td>0.770846</td>
      <td>0.761982</td>
      <td>0.762245</td>
      <td>0.006918</td>
      <td>182</td>
      <td>0.772908</td>
      <td>0.790071</td>
      <td>0.783546</td>
      <td>0.782175</td>
      <td>0.007074</td>
      <td>199</td>
    </tr>
    <tr>
      <th>108</th>
      <td>0.523332</td>
      <td>0.037188</td>
      <td>0.187336</td>
      <td>0.003681</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.753906</td>
      <td>0.770846</td>
      <td>0.761982</td>
      <td>0.762245</td>
      <td>0.006918</td>
      <td>182</td>
      <td>0.772908</td>
      <td>0.790071</td>
      <td>0.783546</td>
      <td>0.782175</td>
      <td>0.007074</td>
      <td>199</td>
    </tr>
    <tr>
      <th>162</th>
      <td>0.509365</td>
      <td>0.030118</td>
      <td>0.197422</td>
      <td>0.002551</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.753906</td>
      <td>0.770846</td>
      <td>0.761982</td>
      <td>0.762245</td>
      <td>0.006918</td>
      <td>182</td>
      <td>0.772908</td>
      <td>0.790071</td>
      <td>0.783546</td>
      <td>0.782175</td>
      <td>0.007074</td>
      <td>199</td>
    </tr>
    <tr>
      <th>166</th>
      <td>1.288999</td>
      <td>0.002162</td>
      <td>0.356760</td>
      <td>0.024665</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.753679</td>
      <td>0.768416</td>
      <td>0.764295</td>
      <td>0.762130</td>
      <td>0.006208</td>
      <td>186</td>
      <td>0.773901</td>
      <td>0.788652</td>
      <td>0.785248</td>
      <td>0.782600</td>
      <td>0.006307</td>
      <td>193</td>
    </tr>
    <tr>
      <th>58</th>
      <td>1.324783</td>
      <td>0.021085</td>
      <td>0.313217</td>
      <td>0.013708</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.753679</td>
      <td>0.768416</td>
      <td>0.764295</td>
      <td>0.762130</td>
      <td>0.006208</td>
      <td>186</td>
      <td>0.773901</td>
      <td>0.788652</td>
      <td>0.785248</td>
      <td>0.782600</td>
      <td>0.006307</td>
      <td>193</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.265397</td>
      <td>0.011374</td>
      <td>0.316718</td>
      <td>0.016255</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.753679</td>
      <td>0.768416</td>
      <td>0.764295</td>
      <td>0.762130</td>
      <td>0.006208</td>
      <td>186</td>
      <td>0.773901</td>
      <td>0.788652</td>
      <td>0.785248</td>
      <td>0.782600</td>
      <td>0.006307</td>
      <td>193</td>
    </tr>
    <tr>
      <th>112</th>
      <td>1.248666</td>
      <td>0.008731</td>
      <td>0.344998</td>
      <td>0.029630</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.753679</td>
      <td>0.768416</td>
      <td>0.764295</td>
      <td>0.762130</td>
      <td>0.006208</td>
      <td>186</td>
      <td>0.773901</td>
      <td>0.788652</td>
      <td>0.785248</td>
      <td>0.782600</td>
      <td>0.006307</td>
      <td>193</td>
    </tr>
    <tr>
      <th>175</th>
      <td>1.284664</td>
      <td>0.007410</td>
      <td>0.364003</td>
      <td>0.012353</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.754168</td>
      <td>0.769201</td>
      <td>0.762087</td>
      <td>0.761819</td>
      <td>0.006140</td>
      <td>190</td>
      <td>0.775035</td>
      <td>0.790071</td>
      <td>0.792340</td>
      <td>0.785816</td>
      <td>0.007679</td>
      <td>178</td>
    </tr>
    <tr>
      <th>198</th>
      <td>0.513091</td>
      <td>0.012645</td>
      <td>0.209014</td>
      <td>0.019553</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.754679</td>
      <td>0.768881</td>
      <td>0.761335</td>
      <td>0.761632</td>
      <td>0.005801</td>
      <td>191</td>
      <td>0.772199</td>
      <td>0.787092</td>
      <td>0.784113</td>
      <td>0.781135</td>
      <td>0.006435</td>
      <td>218</td>
    </tr>
    <tr>
      <th>176</th>
      <td>1.964668</td>
      <td>0.019746</td>
      <td>0.418994</td>
      <td>0.030738</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.751825</td>
      <td>0.768343</td>
      <td>0.764392</td>
      <td>0.761520</td>
      <td>0.007043</td>
      <td>192</td>
      <td>0.772482</td>
      <td>0.788936</td>
      <td>0.793901</td>
      <td>0.785106</td>
      <td>0.009154</td>
      <td>181</td>
    </tr>
    <tr>
      <th>13</th>
      <td>1.515000</td>
      <td>0.028083</td>
      <td>0.368999</td>
      <td>0.044640</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.753062</td>
      <td>0.768557</td>
      <td>0.762639</td>
      <td>0.761419</td>
      <td>0.006384</td>
      <td>193</td>
      <td>0.773617</td>
      <td>0.788936</td>
      <td>0.785106</td>
      <td>0.782553</td>
      <td>0.006509</td>
      <td>198</td>
    </tr>
    <tr>
      <th>59</th>
      <td>1.968801</td>
      <td>0.059399</td>
      <td>0.400330</td>
      <td>0.014058</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752261</td>
      <td>0.767012</td>
      <td>0.764820</td>
      <td>0.761364</td>
      <td>0.006499</td>
      <td>194</td>
      <td>0.772199</td>
      <td>0.786809</td>
      <td>0.785390</td>
      <td>0.781466</td>
      <td>0.006578</td>
      <td>204</td>
    </tr>
    <tr>
      <th>113</th>
      <td>1.905841</td>
      <td>0.024688</td>
      <td>0.441332</td>
      <td>0.024005</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752261</td>
      <td>0.767012</td>
      <td>0.764820</td>
      <td>0.761364</td>
      <td>0.006499</td>
      <td>194</td>
      <td>0.772199</td>
      <td>0.786809</td>
      <td>0.785390</td>
      <td>0.781466</td>
      <td>0.006578</td>
      <td>204</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2.015177</td>
      <td>0.033560</td>
      <td>0.414205</td>
      <td>0.023059</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752261</td>
      <td>0.767012</td>
      <td>0.764820</td>
      <td>0.761364</td>
      <td>0.006499</td>
      <td>194</td>
      <td>0.772199</td>
      <td>0.786809</td>
      <td>0.785390</td>
      <td>0.781466</td>
      <td>0.006578</td>
      <td>204</td>
    </tr>
    <tr>
      <th>167</th>
      <td>2.055610</td>
      <td>0.051749</td>
      <td>0.430334</td>
      <td>0.033561</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752261</td>
      <td>0.767012</td>
      <td>0.764820</td>
      <td>0.761364</td>
      <td>0.006499</td>
      <td>194</td>
      <td>0.772199</td>
      <td>0.786809</td>
      <td>0.785390</td>
      <td>0.781466</td>
      <td>0.006578</td>
      <td>204</td>
    </tr>
    <tr>
      <th>135</th>
      <td>0.910169</td>
      <td>0.353096</td>
      <td>0.411474</td>
      <td>0.251358</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.753152</td>
      <td>0.770144</td>
      <td>0.760423</td>
      <td>0.761240</td>
      <td>0.006961</td>
      <td>198</td>
      <td>0.770780</td>
      <td>0.787801</td>
      <td>0.779149</td>
      <td>0.779243</td>
      <td>0.006949</td>
      <td>232</td>
    </tr>
    <tr>
      <th>81</th>
      <td>0.879617</td>
      <td>0.335380</td>
      <td>0.273332</td>
      <td>0.048662</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.753152</td>
      <td>0.770144</td>
      <td>0.760423</td>
      <td>0.761240</td>
      <td>0.006961</td>
      <td>198</td>
      <td>0.770780</td>
      <td>0.787801</td>
      <td>0.779149</td>
      <td>0.779243</td>
      <td>0.006949</td>
      <td>232</td>
    </tr>
    <tr>
      <th>27</th>
      <td>0.533506</td>
      <td>0.042215</td>
      <td>0.179215</td>
      <td>0.002373</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.753152</td>
      <td>0.770144</td>
      <td>0.760423</td>
      <td>0.761240</td>
      <td>0.006961</td>
      <td>198</td>
      <td>0.770780</td>
      <td>0.787801</td>
      <td>0.779149</td>
      <td>0.779243</td>
      <td>0.006949</td>
      <td>232</td>
    </tr>
    <tr>
      <th>189</th>
      <td>0.533923</td>
      <td>0.037135</td>
      <td>0.226999</td>
      <td>0.028083</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.753152</td>
      <td>0.770144</td>
      <td>0.760423</td>
      <td>0.761240</td>
      <td>0.006961</td>
      <td>198</td>
      <td>0.770780</td>
      <td>0.787801</td>
      <td>0.779149</td>
      <td>0.779243</td>
      <td>0.006949</td>
      <td>232</td>
    </tr>
    <tr>
      <th>202</th>
      <td>1.315806</td>
      <td>0.047051</td>
      <td>0.362600</td>
      <td>0.014218</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.753127</td>
      <td>0.769136</td>
      <td>0.761121</td>
      <td>0.761128</td>
      <td>0.006535</td>
      <td>202</td>
      <td>0.770496</td>
      <td>0.786241</td>
      <td>0.779716</td>
      <td>0.778818</td>
      <td>0.006459</td>
      <td>241</td>
    </tr>
    <tr>
      <th>40</th>
      <td>1.367014</td>
      <td>0.035417</td>
      <td>0.350174</td>
      <td>0.034098</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752488</td>
      <td>0.769462</td>
      <td>0.760784</td>
      <td>0.760911</td>
      <td>0.006930</td>
      <td>203</td>
      <td>0.769220</td>
      <td>0.786383</td>
      <td>0.778582</td>
      <td>0.778061</td>
      <td>0.007016</td>
      <td>249</td>
    </tr>
    <tr>
      <th>85</th>
      <td>1.305665</td>
      <td>0.039912</td>
      <td>0.348668</td>
      <td>0.021014</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752316</td>
      <td>0.769634</td>
      <td>0.760517</td>
      <td>0.760822</td>
      <td>0.007073</td>
      <td>204</td>
      <td>0.769078</td>
      <td>0.786525</td>
      <td>0.778298</td>
      <td>0.777967</td>
      <td>0.007126</td>
      <td>250</td>
    </tr>
    <tr>
      <th>193</th>
      <td>1.308002</td>
      <td>0.032341</td>
      <td>0.327331</td>
      <td>0.006182</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752316</td>
      <td>0.769634</td>
      <td>0.760517</td>
      <td>0.760822</td>
      <td>0.007073</td>
      <td>204</td>
      <td>0.769078</td>
      <td>0.786525</td>
      <td>0.778298</td>
      <td>0.777967</td>
      <td>0.007126</td>
      <td>250</td>
    </tr>
    <tr>
      <th>31</th>
      <td>1.243107</td>
      <td>0.022631</td>
      <td>0.312999</td>
      <td>0.011859</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752316</td>
      <td>0.769634</td>
      <td>0.760517</td>
      <td>0.760822</td>
      <td>0.007073</td>
      <td>204</td>
      <td>0.769078</td>
      <td>0.786525</td>
      <td>0.778298</td>
      <td>0.777967</td>
      <td>0.007126</td>
      <td>250</td>
    </tr>
    <tr>
      <th>139</th>
      <td>1.269604</td>
      <td>0.008112</td>
      <td>0.369667</td>
      <td>0.040474</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752316</td>
      <td>0.769634</td>
      <td>0.760517</td>
      <td>0.760822</td>
      <td>0.007073</td>
      <td>204</td>
      <td>0.769078</td>
      <td>0.786525</td>
      <td>0.778298</td>
      <td>0.777967</td>
      <td>0.007126</td>
      <td>250</td>
    </tr>
    <tr>
      <th>14</th>
      <td>2.160668</td>
      <td>0.080205</td>
      <td>0.412334</td>
      <td>0.015924</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752088</td>
      <td>0.766844</td>
      <td>0.763493</td>
      <td>0.760808</td>
      <td>0.006316</td>
      <td>208</td>
      <td>0.772340</td>
      <td>0.786809</td>
      <td>0.785674</td>
      <td>0.781608</td>
      <td>0.006569</td>
      <td>203</td>
    </tr>
    <tr>
      <th>203</th>
      <td>1.937808</td>
      <td>0.020026</td>
      <td>0.459059</td>
      <td>0.007061</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.751854</td>
      <td>0.768428</td>
      <td>0.762114</td>
      <td>0.760799</td>
      <td>0.006830</td>
      <td>209</td>
      <td>0.769220</td>
      <td>0.785532</td>
      <td>0.780426</td>
      <td>0.778392</td>
      <td>0.006813</td>
      <td>243</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.561330</td>
      <td>0.038419</td>
      <td>0.201003</td>
      <td>0.006377</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.759016</td>
      <td>0.773179</td>
      <td>0.750125</td>
      <td>0.760773</td>
      <td>0.009493</td>
      <td>210</td>
      <td>0.785248</td>
      <td>0.799574</td>
      <td>0.792057</td>
      <td>0.792293</td>
      <td>0.005851</td>
      <td>155</td>
    </tr>
    <tr>
      <th>525</th>
      <td>0.863666</td>
      <td>0.009846</td>
      <td>0.285666</td>
      <td>0.125912</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.755370</td>
      <td>0.766510</td>
      <td>0.760423</td>
      <td>0.760768</td>
      <td>0.004555</td>
      <td>211</td>
      <td>0.772766</td>
      <td>0.784965</td>
      <td>0.779149</td>
      <td>0.778960</td>
      <td>0.004982</td>
      <td>240</td>
    </tr>
    <tr>
      <th>63</th>
      <td>0.634333</td>
      <td>0.020418</td>
      <td>0.242336</td>
      <td>0.018372</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752777</td>
      <td>0.770476</td>
      <td>0.758989</td>
      <td>0.760747</td>
      <td>0.007332</td>
      <td>212</td>
      <td>0.769362</td>
      <td>0.787660</td>
      <td>0.777447</td>
      <td>0.778156</td>
      <td>0.007487</td>
      <td>244</td>
    </tr>
    <tr>
      <th>277</th>
      <td>1.276571</td>
      <td>0.021648</td>
      <td>0.319671</td>
      <td>0.017858</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.751584</td>
      <td>0.766101</td>
      <td>0.764099</td>
      <td>0.760595</td>
      <td>0.006424</td>
      <td>213</td>
      <td>0.770922</td>
      <td>0.785532</td>
      <td>0.784397</td>
      <td>0.780284</td>
      <td>0.006636</td>
      <td>222</td>
    </tr>
    <tr>
      <th>331</th>
      <td>1.569086</td>
      <td>0.159200</td>
      <td>0.622070</td>
      <td>0.227121</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.751584</td>
      <td>0.766101</td>
      <td>0.764099</td>
      <td>0.760595</td>
      <td>0.006424</td>
      <td>213</td>
      <td>0.770922</td>
      <td>0.785532</td>
      <td>0.784397</td>
      <td>0.780284</td>
      <td>0.006636</td>
      <td>222</td>
    </tr>
    <tr>
      <th>385</th>
      <td>1.223665</td>
      <td>0.013887</td>
      <td>0.356664</td>
      <td>0.008380</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.751584</td>
      <td>0.766101</td>
      <td>0.764099</td>
      <td>0.760595</td>
      <td>0.006424</td>
      <td>213</td>
      <td>0.770922</td>
      <td>0.785532</td>
      <td>0.784397</td>
      <td>0.780284</td>
      <td>0.006636</td>
      <td>222</td>
    </tr>
    <tr>
      <th>223</th>
      <td>1.287665</td>
      <td>0.023923</td>
      <td>0.322003</td>
      <td>0.017904</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.751584</td>
      <td>0.766101</td>
      <td>0.764099</td>
      <td>0.760595</td>
      <td>0.006424</td>
      <td>213</td>
      <td>0.770922</td>
      <td>0.785532</td>
      <td>0.784397</td>
      <td>0.780284</td>
      <td>0.006636</td>
      <td>222</td>
    </tr>
    <tr>
      <th>286</th>
      <td>1.277474</td>
      <td>0.006168</td>
      <td>0.324663</td>
      <td>0.001702</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.751909</td>
      <td>0.766794</td>
      <td>0.761625</td>
      <td>0.760109</td>
      <td>0.006171</td>
      <td>217</td>
      <td>0.771915</td>
      <td>0.786667</td>
      <td>0.783404</td>
      <td>0.780662</td>
      <td>0.006327</td>
      <td>220</td>
    </tr>
    <tr>
      <th>498</th>
      <td>0.801834</td>
      <td>0.016462</td>
      <td>0.251690</td>
      <td>0.035930</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.753402</td>
      <td>0.767940</td>
      <td>0.758912</td>
      <td>0.760084</td>
      <td>0.005993</td>
      <td>218</td>
      <td>0.773050</td>
      <td>0.788511</td>
      <td>0.779716</td>
      <td>0.780426</td>
      <td>0.006332</td>
      <td>221</td>
    </tr>
    <tr>
      <th>332</th>
      <td>2.861087</td>
      <td>0.182331</td>
      <td>0.455423</td>
      <td>0.059131</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.750132</td>
      <td>0.766412</td>
      <td>0.763687</td>
      <td>0.760077</td>
      <td>0.007120</td>
      <td>219</td>
      <td>0.769504</td>
      <td>0.785248</td>
      <td>0.783688</td>
      <td>0.779480</td>
      <td>0.007083</td>
      <td>228</td>
    </tr>
    <tr>
      <th>386</th>
      <td>1.937459</td>
      <td>0.032021</td>
      <td>0.699551</td>
      <td>0.195143</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.750132</td>
      <td>0.766412</td>
      <td>0.763687</td>
      <td>0.760077</td>
      <td>0.007120</td>
      <td>219</td>
      <td>0.769504</td>
      <td>0.785248</td>
      <td>0.783688</td>
      <td>0.779480</td>
      <td>0.007083</td>
      <td>228</td>
    </tr>
    <tr>
      <th>224</th>
      <td>1.912999</td>
      <td>0.036338</td>
      <td>0.415998</td>
      <td>0.015899</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.750132</td>
      <td>0.766412</td>
      <td>0.763687</td>
      <td>0.760077</td>
      <td>0.007120</td>
      <td>219</td>
      <td>0.769504</td>
      <td>0.785248</td>
      <td>0.783688</td>
      <td>0.779480</td>
      <td>0.007083</td>
      <td>228</td>
    </tr>
    <tr>
      <th>278</th>
      <td>1.915824</td>
      <td>0.059057</td>
      <td>0.406349</td>
      <td>0.032523</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.750132</td>
      <td>0.766412</td>
      <td>0.763687</td>
      <td>0.760077</td>
      <td>0.007120</td>
      <td>219</td>
      <td>0.769504</td>
      <td>0.785248</td>
      <td>0.783688</td>
      <td>0.779480</td>
      <td>0.007083</td>
      <td>228</td>
    </tr>
    <tr>
      <th>171</th>
      <td>0.589902</td>
      <td>0.025345</td>
      <td>0.234422</td>
      <td>0.035636</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.755499</td>
      <td>0.771413</td>
      <td>0.753311</td>
      <td>0.760074</td>
      <td>0.008067</td>
      <td>223</td>
      <td>0.774610</td>
      <td>0.790496</td>
      <td>0.792057</td>
      <td>0.785721</td>
      <td>0.007883</td>
      <td>180</td>
    </tr>
    <tr>
      <th>41</th>
      <td>2.070127</td>
      <td>0.045182</td>
      <td>0.428398</td>
      <td>0.018134</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.751074</td>
      <td>0.767817</td>
      <td>0.761116</td>
      <td>0.760002</td>
      <td>0.006881</td>
      <td>224</td>
      <td>0.768085</td>
      <td>0.784681</td>
      <td>0.778723</td>
      <td>0.777163</td>
      <td>0.006864</td>
      <td>266</td>
    </tr>
    <tr>
      <th>140</th>
      <td>1.868040</td>
      <td>0.030051</td>
      <td>0.479332</td>
      <td>0.016776</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.750822</td>
      <td>0.768237</td>
      <td>0.760903</td>
      <td>0.759987</td>
      <td>0.007139</td>
      <td>225</td>
      <td>0.767943</td>
      <td>0.785248</td>
      <td>0.778582</td>
      <td>0.777258</td>
      <td>0.007126</td>
      <td>262</td>
    </tr>
    <tr>
      <th>86</th>
      <td>2.047669</td>
      <td>0.024253</td>
      <td>0.415994</td>
      <td>0.012832</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.750822</td>
      <td>0.768237</td>
      <td>0.760903</td>
      <td>0.759987</td>
      <td>0.007139</td>
      <td>225</td>
      <td>0.767943</td>
      <td>0.785248</td>
      <td>0.778582</td>
      <td>0.777258</td>
      <td>0.007126</td>
      <td>262</td>
    </tr>
    <tr>
      <th>32</th>
      <td>2.053540</td>
      <td>0.080130</td>
      <td>0.440668</td>
      <td>0.013478</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.750822</td>
      <td>0.768237</td>
      <td>0.760903</td>
      <td>0.759987</td>
      <td>0.007139</td>
      <td>225</td>
      <td>0.767943</td>
      <td>0.785248</td>
      <td>0.778582</td>
      <td>0.777258</td>
      <td>0.007126</td>
      <td>262</td>
    </tr>
    <tr>
      <th>194</th>
      <td>1.951003</td>
      <td>0.002449</td>
      <td>0.436996</td>
      <td>0.017146</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.750822</td>
      <td>0.768237</td>
      <td>0.760903</td>
      <td>0.759987</td>
      <td>0.007139</td>
      <td>225</td>
      <td>0.767943</td>
      <td>0.785248</td>
      <td>0.778582</td>
      <td>0.777258</td>
      <td>0.007126</td>
      <td>262</td>
    </tr>
    <tr>
      <th>287</th>
      <td>2.164103</td>
      <td>0.034170</td>
      <td>0.432331</td>
      <td>0.020417</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.750098</td>
      <td>0.764596</td>
      <td>0.764388</td>
      <td>0.759694</td>
      <td>0.006786</td>
      <td>229</td>
      <td>0.769929</td>
      <td>0.784113</td>
      <td>0.785674</td>
      <td>0.779905</td>
      <td>0.007083</td>
      <td>227</td>
    </tr>
    <tr>
      <th>90</th>
      <td>0.671336</td>
      <td>0.012254</td>
      <td>0.189000</td>
      <td>0.003553</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752424</td>
      <td>0.768021</td>
      <td>0.757907</td>
      <td>0.759451</td>
      <td>0.006460</td>
      <td>230</td>
      <td>0.767801</td>
      <td>0.784255</td>
      <td>0.775177</td>
      <td>0.775745</td>
      <td>0.006729</td>
      <td>270</td>
    </tr>
    <tr>
      <th>260</th>
      <td>2.091368</td>
      <td>0.052532</td>
      <td>0.449333</td>
      <td>0.019605</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.746959</td>
      <td>0.766612</td>
      <td>0.762071</td>
      <td>0.758547</td>
      <td>0.008401</td>
      <td>231</td>
      <td>0.763972</td>
      <td>0.783121</td>
      <td>0.783830</td>
      <td>0.776974</td>
      <td>0.009199</td>
      <td>268</td>
    </tr>
    <tr>
      <th>313</th>
      <td>1.297377</td>
      <td>0.030338</td>
      <td>0.331595</td>
      <td>0.021215</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.749582</td>
      <td>0.766400</td>
      <td>0.759222</td>
      <td>0.758401</td>
      <td>0.006890</td>
      <td>232</td>
      <td>0.765816</td>
      <td>0.782695</td>
      <td>0.776454</td>
      <td>0.774988</td>
      <td>0.006969</td>
      <td>271</td>
    </tr>
    <tr>
      <th>111</th>
      <td>0.516334</td>
      <td>0.031030</td>
      <td>0.183001</td>
      <td>0.004964</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752087</td>
      <td>0.766819</td>
      <td>0.755427</td>
      <td>0.758111</td>
      <td>0.006307</td>
      <td>233</td>
      <td>0.772199</td>
      <td>0.787234</td>
      <td>0.777730</td>
      <td>0.779054</td>
      <td>0.006209</td>
      <td>236</td>
    </tr>
    <tr>
      <th>165</th>
      <td>0.500997</td>
      <td>0.020409</td>
      <td>0.244001</td>
      <td>0.052467</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752087</td>
      <td>0.766819</td>
      <td>0.755427</td>
      <td>0.758111</td>
      <td>0.006307</td>
      <td>233</td>
      <td>0.772199</td>
      <td>0.787234</td>
      <td>0.777730</td>
      <td>0.779054</td>
      <td>0.006209</td>
      <td>236</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.490647</td>
      <td>0.022519</td>
      <td>0.239673</td>
      <td>0.039448</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752087</td>
      <td>0.766819</td>
      <td>0.755427</td>
      <td>0.758111</td>
      <td>0.006307</td>
      <td>233</td>
      <td>0.772199</td>
      <td>0.787234</td>
      <td>0.777730</td>
      <td>0.779054</td>
      <td>0.006209</td>
      <td>236</td>
    </tr>
    <tr>
      <th>57</th>
      <td>0.522446</td>
      <td>0.029300</td>
      <td>0.204032</td>
      <td>0.002349</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752087</td>
      <td>0.766819</td>
      <td>0.755427</td>
      <td>0.758111</td>
      <td>0.006307</td>
      <td>233</td>
      <td>0.772199</td>
      <td>0.787234</td>
      <td>0.777730</td>
      <td>0.779054</td>
      <td>0.006209</td>
      <td>236</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.560332</td>
      <td>0.039204</td>
      <td>0.206335</td>
      <td>0.016047</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.750322</td>
      <td>0.766568</td>
      <td>0.757345</td>
      <td>0.758079</td>
      <td>0.006653</td>
      <td>237</td>
      <td>0.771064</td>
      <td>0.787518</td>
      <td>0.781277</td>
      <td>0.779953</td>
      <td>0.006782</td>
      <td>226</td>
    </tr>
    <tr>
      <th>358</th>
      <td>1.232996</td>
      <td>0.017147</td>
      <td>0.320333</td>
      <td>0.025036</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.748959</td>
      <td>0.766763</td>
      <td>0.758345</td>
      <td>0.758023</td>
      <td>0.007272</td>
      <td>238</td>
      <td>0.765106</td>
      <td>0.783121</td>
      <td>0.775603</td>
      <td>0.774610</td>
      <td>0.007388</td>
      <td>277</td>
    </tr>
    <tr>
      <th>250</th>
      <td>1.289666</td>
      <td>0.006019</td>
      <td>0.321332</td>
      <td>0.025249</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.748959</td>
      <td>0.766763</td>
      <td>0.758345</td>
      <td>0.758023</td>
      <td>0.007272</td>
      <td>238</td>
      <td>0.765106</td>
      <td>0.783121</td>
      <td>0.775603</td>
      <td>0.774610</td>
      <td>0.007388</td>
      <td>277</td>
    </tr>
    <tr>
      <th>304</th>
      <td>1.222666</td>
      <td>0.015172</td>
      <td>0.313665</td>
      <td>0.011585</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.748959</td>
      <td>0.766763</td>
      <td>0.758345</td>
      <td>0.758023</td>
      <td>0.007272</td>
      <td>238</td>
      <td>0.765106</td>
      <td>0.783121</td>
      <td>0.775603</td>
      <td>0.774610</td>
      <td>0.007388</td>
      <td>277</td>
    </tr>
    <tr>
      <th>412</th>
      <td>1.269668</td>
      <td>0.038679</td>
      <td>0.352000</td>
      <td>0.049663</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.748959</td>
      <td>0.766763</td>
      <td>0.758345</td>
      <td>0.758023</td>
      <td>0.007272</td>
      <td>238</td>
      <td>0.765106</td>
      <td>0.783121</td>
      <td>0.775603</td>
      <td>0.774610</td>
      <td>0.007388</td>
      <td>277</td>
    </tr>
    <tr>
      <th>201</th>
      <td>0.537146</td>
      <td>0.014944</td>
      <td>0.192325</td>
      <td>0.017635</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.749353</td>
      <td>0.767174</td>
      <td>0.757524</td>
      <td>0.758017</td>
      <td>0.007284</td>
      <td>242</td>
      <td>0.767234</td>
      <td>0.784823</td>
      <td>0.777589</td>
      <td>0.776548</td>
      <td>0.007218</td>
      <td>269</td>
    </tr>
    <tr>
      <th>259</th>
      <td>1.234347</td>
      <td>0.021352</td>
      <td>0.377662</td>
      <td>0.032221</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.747607</td>
      <td>0.766957</td>
      <td>0.758957</td>
      <td>0.757840</td>
      <td>0.007939</td>
      <td>243</td>
      <td>0.764539</td>
      <td>0.783688</td>
      <td>0.782837</td>
      <td>0.777021</td>
      <td>0.008833</td>
      <td>267</td>
    </tr>
    <tr>
      <th>192</th>
      <td>0.532660</td>
      <td>0.009179</td>
      <td>0.219336</td>
      <td>0.011115</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.751031</td>
      <td>0.765387</td>
      <td>0.756418</td>
      <td>0.757612</td>
      <td>0.005921</td>
      <td>244</td>
      <td>0.767660</td>
      <td>0.782553</td>
      <td>0.774184</td>
      <td>0.774799</td>
      <td>0.006096</td>
      <td>273</td>
    </tr>
    <tr>
      <th>30</th>
      <td>0.556928</td>
      <td>0.012691</td>
      <td>0.221622</td>
      <td>0.025717</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.751031</td>
      <td>0.765387</td>
      <td>0.756418</td>
      <td>0.757612</td>
      <td>0.005921</td>
      <td>244</td>
      <td>0.767660</td>
      <td>0.782553</td>
      <td>0.774184</td>
      <td>0.774799</td>
      <td>0.006096</td>
      <td>273</td>
    </tr>
    <tr>
      <th>84</th>
      <td>0.543000</td>
      <td>0.008603</td>
      <td>0.244003</td>
      <td>0.013590</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.751031</td>
      <td>0.765387</td>
      <td>0.756418</td>
      <td>0.757612</td>
      <td>0.005921</td>
      <td>244</td>
      <td>0.767660</td>
      <td>0.782553</td>
      <td>0.774184</td>
      <td>0.774799</td>
      <td>0.006096</td>
      <td>273</td>
    </tr>
    <tr>
      <th>138</th>
      <td>0.487964</td>
      <td>0.017738</td>
      <td>0.214186</td>
      <td>0.022032</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.751031</td>
      <td>0.765387</td>
      <td>0.756418</td>
      <td>0.757612</td>
      <td>0.005921</td>
      <td>244</td>
      <td>0.767660</td>
      <td>0.782553</td>
      <td>0.774184</td>
      <td>0.774799</td>
      <td>0.006096</td>
      <td>273</td>
    </tr>
    <tr>
      <th>359</th>
      <td>1.936999</td>
      <td>0.040357</td>
      <td>0.393665</td>
      <td>0.014200</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.747527</td>
      <td>0.766383</td>
      <td>0.758808</td>
      <td>0.757573</td>
      <td>0.007747</td>
      <td>248</td>
      <td>0.764113</td>
      <td>0.782837</td>
      <td>0.775887</td>
      <td>0.774279</td>
      <td>0.007728</td>
      <td>281</td>
    </tr>
    <tr>
      <th>305</th>
      <td>1.968668</td>
      <td>0.024524</td>
      <td>0.419328</td>
      <td>0.026248</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.747527</td>
      <td>0.766383</td>
      <td>0.758808</td>
      <td>0.757573</td>
      <td>0.007747</td>
      <td>248</td>
      <td>0.764113</td>
      <td>0.782837</td>
      <td>0.775887</td>
      <td>0.774279</td>
      <td>0.007728</td>
      <td>281</td>
    </tr>
    <tr>
      <th>413</th>
      <td>1.925670</td>
      <td>0.024639</td>
      <td>0.431329</td>
      <td>0.040272</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.747527</td>
      <td>0.766383</td>
      <td>0.758808</td>
      <td>0.757573</td>
      <td>0.007747</td>
      <td>248</td>
      <td>0.764113</td>
      <td>0.782837</td>
      <td>0.775887</td>
      <td>0.774279</td>
      <td>0.007728</td>
      <td>281</td>
    </tr>
    <tr>
      <th>251</th>
      <td>1.932041</td>
      <td>0.039190</td>
      <td>0.412776</td>
      <td>0.024978</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.747527</td>
      <td>0.766383</td>
      <td>0.758808</td>
      <td>0.757573</td>
      <td>0.007747</td>
      <td>248</td>
      <td>0.764113</td>
      <td>0.782837</td>
      <td>0.775887</td>
      <td>0.774279</td>
      <td>0.007728</td>
      <td>281</td>
    </tr>
    <tr>
      <th>39</th>
      <td>0.554665</td>
      <td>0.033825</td>
      <td>0.228008</td>
      <td>0.014169</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.750094</td>
      <td>0.766323</td>
      <td>0.756186</td>
      <td>0.757534</td>
      <td>0.006694</td>
      <td>252</td>
      <td>0.766950</td>
      <td>0.783546</td>
      <td>0.774326</td>
      <td>0.774941</td>
      <td>0.006789</td>
      <td>272</td>
    </tr>
    <tr>
      <th>276</th>
      <td>0.520161</td>
      <td>0.003889</td>
      <td>0.238937</td>
      <td>0.045961</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752417</td>
      <td>0.765716</td>
      <td>0.753989</td>
      <td>0.757374</td>
      <td>0.005933</td>
      <td>253</td>
      <td>0.771631</td>
      <td>0.785390</td>
      <td>0.775177</td>
      <td>0.777400</td>
      <td>0.005833</td>
      <td>258</td>
    </tr>
    <tr>
      <th>384</th>
      <td>0.501666</td>
      <td>0.006130</td>
      <td>0.209668</td>
      <td>0.016776</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752417</td>
      <td>0.765716</td>
      <td>0.753989</td>
      <td>0.757374</td>
      <td>0.005933</td>
      <td>253</td>
      <td>0.771631</td>
      <td>0.785390</td>
      <td>0.775177</td>
      <td>0.777400</td>
      <td>0.005833</td>
      <td>258</td>
    </tr>
    <tr>
      <th>330</th>
      <td>0.709484</td>
      <td>0.225055</td>
      <td>0.234666</td>
      <td>0.041409</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752417</td>
      <td>0.765716</td>
      <td>0.753989</td>
      <td>0.757374</td>
      <td>0.005933</td>
      <td>253</td>
      <td>0.771631</td>
      <td>0.785390</td>
      <td>0.775177</td>
      <td>0.777400</td>
      <td>0.005833</td>
      <td>258</td>
    </tr>
    <tr>
      <th>222</th>
      <td>0.568328</td>
      <td>0.004785</td>
      <td>0.226333</td>
      <td>0.014703</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.752417</td>
      <td>0.765716</td>
      <td>0.753989</td>
      <td>0.757374</td>
      <td>0.005933</td>
      <td>253</td>
      <td>0.771631</td>
      <td>0.785390</td>
      <td>0.775177</td>
      <td>0.777400</td>
      <td>0.005833</td>
      <td>258</td>
    </tr>
    <tr>
      <th>285</th>
      <td>0.543355</td>
      <td>0.020807</td>
      <td>0.232644</td>
      <td>0.019570</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.750408</td>
      <td>0.766357</td>
      <td>0.755252</td>
      <td>0.757339</td>
      <td>0.006676</td>
      <td>257</td>
      <td>0.770355</td>
      <td>0.786383</td>
      <td>0.778440</td>
      <td>0.778392</td>
      <td>0.006544</td>
      <td>242</td>
    </tr>
    <tr>
      <th>174</th>
      <td>0.497666</td>
      <td>0.036236</td>
      <td>0.214335</td>
      <td>0.023978</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.750926</td>
      <td>0.767428</td>
      <td>0.753054</td>
      <td>0.757136</td>
      <td>0.007329</td>
      <td>258</td>
      <td>0.772482</td>
      <td>0.789078</td>
      <td>0.786383</td>
      <td>0.782648</td>
      <td>0.007272</td>
      <td>192</td>
    </tr>
    <tr>
      <th>314</th>
      <td>2.017687</td>
      <td>0.032593</td>
      <td>0.407250</td>
      <td>0.040118</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.746563</td>
      <td>0.765218</td>
      <td>0.759340</td>
      <td>0.757040</td>
      <td>0.007788</td>
      <td>259</td>
      <td>0.763121</td>
      <td>0.781560</td>
      <td>0.776454</td>
      <td>0.773712</td>
      <td>0.007774</td>
      <td>285</td>
    </tr>
    <tr>
      <th>312</th>
      <td>0.545963</td>
      <td>0.022176</td>
      <td>0.250256</td>
      <td>0.047074</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.748423</td>
      <td>0.763960</td>
      <td>0.757177</td>
      <td>0.756520</td>
      <td>0.006360</td>
      <td>260</td>
      <td>0.764823</td>
      <td>0.780426</td>
      <td>0.774610</td>
      <td>0.773286</td>
      <td>0.006438</td>
      <td>286</td>
    </tr>
    <tr>
      <th>303</th>
      <td>0.513665</td>
      <td>0.030727</td>
      <td>0.207669</td>
      <td>0.015925</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.749454</td>
      <td>0.762626</td>
      <td>0.756961</td>
      <td>0.756347</td>
      <td>0.005395</td>
      <td>261</td>
      <td>0.765390</td>
      <td>0.779007</td>
      <td>0.774043</td>
      <td>0.772813</td>
      <td>0.005627</td>
      <td>287</td>
    </tr>
    <tr>
      <th>249</th>
      <td>0.587348</td>
      <td>0.028489</td>
      <td>0.279002</td>
      <td>0.068472</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.749454</td>
      <td>0.762626</td>
      <td>0.756961</td>
      <td>0.756347</td>
      <td>0.005395</td>
      <td>261</td>
      <td>0.765390</td>
      <td>0.779007</td>
      <td>0.774043</td>
      <td>0.772813</td>
      <td>0.005627</td>
      <td>287</td>
    </tr>
    <tr>
      <th>357</th>
      <td>0.608331</td>
      <td>0.077436</td>
      <td>0.187673</td>
      <td>0.008954</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.749454</td>
      <td>0.762626</td>
      <td>0.756961</td>
      <td>0.756347</td>
      <td>0.005395</td>
      <td>261</td>
      <td>0.765390</td>
      <td>0.779007</td>
      <td>0.774043</td>
      <td>0.772813</td>
      <td>0.005627</td>
      <td>287</td>
    </tr>
    <tr>
      <th>411</th>
      <td>0.520999</td>
      <td>0.042924</td>
      <td>0.195336</td>
      <td>0.003679</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.749454</td>
      <td>0.762626</td>
      <td>0.756961</td>
      <td>0.756347</td>
      <td>0.005395</td>
      <td>261</td>
      <td>0.765390</td>
      <td>0.779007</td>
      <td>0.774043</td>
      <td>0.772813</td>
      <td>0.005627</td>
      <td>287</td>
    </tr>
    <tr>
      <th>204</th>
      <td>0.502758</td>
      <td>0.023471</td>
      <td>0.195434</td>
      <td>0.004738</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.749792</td>
      <td>0.769637</td>
      <td>0.746306</td>
      <td>0.755245</td>
      <td>0.010276</td>
      <td>265</td>
      <td>0.774468</td>
      <td>0.794326</td>
      <td>0.784823</td>
      <td>0.784539</td>
      <td>0.008110</td>
      <td>184</td>
    </tr>
    <tr>
      <th>441</th>
      <td>0.645347</td>
      <td>0.072597</td>
      <td>0.209002</td>
      <td>0.019648</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.744868</td>
      <td>0.763738</td>
      <td>0.754142</td>
      <td>0.754249</td>
      <td>0.007704</td>
      <td>266</td>
      <td>0.776312</td>
      <td>0.793901</td>
      <td>0.788227</td>
      <td>0.786147</td>
      <td>0.007330</td>
      <td>177</td>
    </tr>
    <tr>
      <th>468</th>
      <td>0.615149</td>
      <td>0.063422</td>
      <td>0.206019</td>
      <td>0.013427</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.742547</td>
      <td>0.763228</td>
      <td>0.753523</td>
      <td>0.753099</td>
      <td>0.008448</td>
      <td>267</td>
      <td>0.772908</td>
      <td>0.792057</td>
      <td>0.784965</td>
      <td>0.783310</td>
      <td>0.007905</td>
      <td>189</td>
    </tr>
    <tr>
      <th>474</th>
      <td>0.519334</td>
      <td>0.020237</td>
      <td>0.223668</td>
      <td>0.016497</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.744885</td>
      <td>0.762557</td>
      <td>0.749793</td>
      <td>0.752412</td>
      <td>0.007448</td>
      <td>268</td>
      <td>0.776454</td>
      <td>0.793475</td>
      <td>0.782553</td>
      <td>0.784161</td>
      <td>0.007041</td>
      <td>186</td>
    </tr>
    <tr>
      <th>341</th>
      <td>2.411665</td>
      <td>0.064220</td>
      <td>0.438662</td>
      <td>0.024853</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.741255</td>
      <td>0.758919</td>
      <td>0.755338</td>
      <td>0.751837</td>
      <td>0.007625</td>
      <td>269</td>
      <td>0.759149</td>
      <td>0.776596</td>
      <td>0.773333</td>
      <td>0.769693</td>
      <td>0.007574</td>
      <td>292</td>
    </tr>
    <tr>
      <th>340</th>
      <td>1.628668</td>
      <td>0.015151</td>
      <td>0.294333</td>
      <td>0.004497</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.740867</td>
      <td>0.759478</td>
      <td>0.754572</td>
      <td>0.751639</td>
      <td>0.007876</td>
      <td>270</td>
      <td>0.758865</td>
      <td>0.777021</td>
      <td>0.772908</td>
      <td>0.769598</td>
      <td>0.007773</td>
      <td>293</td>
    </tr>
    <tr>
      <th>67</th>
      <td>1.527866</td>
      <td>0.020207</td>
      <td>0.348713</td>
      <td>0.010983</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.740011</td>
      <td>0.759891</td>
      <td>0.753619</td>
      <td>0.751173</td>
      <td>0.008298</td>
      <td>271</td>
      <td>0.758440</td>
      <td>0.777589</td>
      <td>0.772199</td>
      <td>0.769409</td>
      <td>0.008063</td>
      <td>294</td>
    </tr>
    <tr>
      <th>68</th>
      <td>2.368238</td>
      <td>0.035157</td>
      <td>0.413686</td>
      <td>0.016564</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.740167</td>
      <td>0.757522</td>
      <td>0.754950</td>
      <td>0.750880</td>
      <td>0.007647</td>
      <td>272</td>
      <td>0.758156</td>
      <td>0.775319</td>
      <td>0.773050</td>
      <td>0.768842</td>
      <td>0.007612</td>
      <td>295</td>
    </tr>
    <tr>
      <th>368</th>
      <td>2.402733</td>
      <td>0.013660</td>
      <td>0.427329</td>
      <td>0.003091</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.739326</td>
      <td>0.758364</td>
      <td>0.754189</td>
      <td>0.750626</td>
      <td>0.008170</td>
      <td>273</td>
      <td>0.754752</td>
      <td>0.773475</td>
      <td>0.770213</td>
      <td>0.766147</td>
      <td>0.008167</td>
      <td>301</td>
    </tr>
    <tr>
      <th>447</th>
      <td>0.597667</td>
      <td>0.018835</td>
      <td>0.191667</td>
      <td>0.004787</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.743398</td>
      <td>0.757310</td>
      <td>0.750955</td>
      <td>0.750555</td>
      <td>0.005687</td>
      <td>274</td>
      <td>0.777021</td>
      <td>0.790496</td>
      <td>0.785957</td>
      <td>0.784492</td>
      <td>0.005598</td>
      <td>185</td>
    </tr>
    <tr>
      <th>603</th>
      <td>0.550359</td>
      <td>0.054049</td>
      <td>0.197001</td>
      <td>0.009271</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.741734</td>
      <td>0.758231</td>
      <td>0.750896</td>
      <td>0.750287</td>
      <td>0.006749</td>
      <td>275</td>
      <td>0.773333</td>
      <td>0.789220</td>
      <td>0.788085</td>
      <td>0.783546</td>
      <td>0.007236</td>
      <td>188</td>
    </tr>
    <tr>
      <th>630</th>
      <td>0.503670</td>
      <td>0.006603</td>
      <td>0.216330</td>
      <td>0.024581</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.739100</td>
      <td>0.757542</td>
      <td>0.753721</td>
      <td>0.750121</td>
      <td>0.007948</td>
      <td>276</td>
      <td>0.770071</td>
      <td>0.787376</td>
      <td>0.786525</td>
      <td>0.781324</td>
      <td>0.007965</td>
      <td>212</td>
    </tr>
    <tr>
      <th>339</th>
      <td>0.683936</td>
      <td>0.028088</td>
      <td>0.216382</td>
      <td>0.006900</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.740991</td>
      <td>0.761314</td>
      <td>0.748001</td>
      <td>0.750102</td>
      <td>0.008429</td>
      <td>277</td>
      <td>0.758865</td>
      <td>0.779574</td>
      <td>0.766809</td>
      <td>0.768416</td>
      <td>0.008531</td>
      <td>298</td>
    </tr>
    <tr>
      <th>367</th>
      <td>1.542764</td>
      <td>0.011613</td>
      <td>0.326662</td>
      <td>0.006798</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.739348</td>
      <td>0.759392</td>
      <td>0.749792</td>
      <td>0.749511</td>
      <td>0.008185</td>
      <td>278</td>
      <td>0.754326</td>
      <td>0.774610</td>
      <td>0.765957</td>
      <td>0.764965</td>
      <td>0.008310</td>
      <td>304</td>
    </tr>
    <tr>
      <th>95</th>
      <td>2.354999</td>
      <td>0.021920</td>
      <td>0.416668</td>
      <td>0.032872</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.738668</td>
      <td>0.757433</td>
      <td>0.752427</td>
      <td>0.749509</td>
      <td>0.007934</td>
      <td>279</td>
      <td>0.754043</td>
      <td>0.772482</td>
      <td>0.768369</td>
      <td>0.764965</td>
      <td>0.007903</td>
      <td>304</td>
    </tr>
    <tr>
      <th>459</th>
      <td>0.504668</td>
      <td>0.047542</td>
      <td>0.199333</td>
      <td>0.015324</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.740632</td>
      <td>0.757375</td>
      <td>0.749332</td>
      <td>0.749113</td>
      <td>0.006837</td>
      <td>280</td>
      <td>0.772340</td>
      <td>0.788794</td>
      <td>0.782695</td>
      <td>0.781277</td>
      <td>0.006792</td>
      <td>213</td>
    </tr>
    <tr>
      <th>621</th>
      <td>0.577428</td>
      <td>0.091344</td>
      <td>0.251684</td>
      <td>0.042361</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.740632</td>
      <td>0.757375</td>
      <td>0.749332</td>
      <td>0.749113</td>
      <td>0.006837</td>
      <td>280</td>
      <td>0.772340</td>
      <td>0.788794</td>
      <td>0.782695</td>
      <td>0.781277</td>
      <td>0.006792</td>
      <td>213</td>
    </tr>
    <tr>
      <th>567</th>
      <td>0.515615</td>
      <td>0.036636</td>
      <td>0.193128</td>
      <td>0.006533</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.740632</td>
      <td>0.757375</td>
      <td>0.749332</td>
      <td>0.749113</td>
      <td>0.006837</td>
      <td>280</td>
      <td>0.772340</td>
      <td>0.788794</td>
      <td>0.782695</td>
      <td>0.781277</td>
      <td>0.006792</td>
      <td>213</td>
    </tr>
    <tr>
      <th>513</th>
      <td>0.604040</td>
      <td>0.013439</td>
      <td>0.197335</td>
      <td>0.002623</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.740632</td>
      <td>0.757375</td>
      <td>0.749332</td>
      <td>0.749113</td>
      <td>0.006837</td>
      <td>280</td>
      <td>0.772340</td>
      <td>0.788794</td>
      <td>0.782695</td>
      <td>0.781277</td>
      <td>0.006792</td>
      <td>213</td>
    </tr>
    <tr>
      <th>94</th>
      <td>1.568329</td>
      <td>0.025251</td>
      <td>0.347001</td>
      <td>0.032931</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.738764</td>
      <td>0.757227</td>
      <td>0.749207</td>
      <td>0.748400</td>
      <td>0.007559</td>
      <td>284</td>
      <td>0.753901</td>
      <td>0.772340</td>
      <td>0.765248</td>
      <td>0.763830</td>
      <td>0.007595</td>
      <td>308</td>
    </tr>
    <tr>
      <th>258</th>
      <td>0.489492</td>
      <td>0.016306</td>
      <td>0.214032</td>
      <td>0.027833</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.743188</td>
      <td>0.762010</td>
      <td>0.739969</td>
      <td>0.748389</td>
      <td>0.009721</td>
      <td>285</td>
      <td>0.760567</td>
      <td>0.779716</td>
      <td>0.775745</td>
      <td>0.772009</td>
      <td>0.008252</td>
      <td>291</td>
    </tr>
    <tr>
      <th>366</th>
      <td>0.660946</td>
      <td>0.047037</td>
      <td>0.219960</td>
      <td>0.004099</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.738840</td>
      <td>0.757996</td>
      <td>0.748236</td>
      <td>0.748357</td>
      <td>0.007821</td>
      <td>286</td>
      <td>0.753901</td>
      <td>0.773475</td>
      <td>0.764539</td>
      <td>0.763972</td>
      <td>0.008001</td>
      <td>307</td>
    </tr>
    <tr>
      <th>551</th>
      <td>3.426666</td>
      <td>0.083945</td>
      <td>0.373667</td>
      <td>0.007584</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.735605</td>
      <td>0.759959</td>
      <td>0.749411</td>
      <td>0.748325</td>
      <td>0.009972</td>
      <td>287</td>
      <td>0.751489</td>
      <td>0.775887</td>
      <td>0.765674</td>
      <td>0.764350</td>
      <td>0.010004</td>
      <td>306</td>
    </tr>
    <tr>
      <th>66</th>
      <td>0.726069</td>
      <td>0.017182</td>
      <td>0.196375</td>
      <td>0.003884</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.738662</td>
      <td>0.759275</td>
      <td>0.745776</td>
      <td>0.747904</td>
      <td>0.008549</td>
      <td>288</td>
      <td>0.757305</td>
      <td>0.778014</td>
      <td>0.765106</td>
      <td>0.766809</td>
      <td>0.008540</td>
      <td>299</td>
    </tr>
    <tr>
      <th>636</th>
      <td>0.513193</td>
      <td>0.045175</td>
      <td>0.252934</td>
      <td>0.034298</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.736147</td>
      <td>0.758110</td>
      <td>0.749313</td>
      <td>0.747857</td>
      <td>0.009025</td>
      <td>289</td>
      <td>0.769645</td>
      <td>0.790355</td>
      <td>0.783121</td>
      <td>0.781040</td>
      <td>0.008582</td>
      <td>219</td>
    </tr>
    <tr>
      <th>93</th>
      <td>0.752667</td>
      <td>0.018625</td>
      <td>0.194667</td>
      <td>0.005437</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.736240</td>
      <td>0.757868</td>
      <td>0.748384</td>
      <td>0.747497</td>
      <td>0.008852</td>
      <td>290</td>
      <td>0.751631</td>
      <td>0.773617</td>
      <td>0.764823</td>
      <td>0.763357</td>
      <td>0.009035</td>
      <td>309</td>
    </tr>
    <tr>
      <th>432</th>
      <td>0.510011</td>
      <td>0.025122</td>
      <td>0.182666</td>
      <td>0.006947</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.738555</td>
      <td>0.755097</td>
      <td>0.748132</td>
      <td>0.747261</td>
      <td>0.006781</td>
      <td>291</td>
      <td>0.771064</td>
      <td>0.788227</td>
      <td>0.784965</td>
      <td>0.781418</td>
      <td>0.007442</td>
      <td>208</td>
    </tr>
    <tr>
      <th>486</th>
      <td>0.548700</td>
      <td>0.017719</td>
      <td>0.187108</td>
      <td>0.011902</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.738555</td>
      <td>0.755097</td>
      <td>0.748132</td>
      <td>0.747261</td>
      <td>0.006781</td>
      <td>291</td>
      <td>0.771064</td>
      <td>0.788227</td>
      <td>0.784965</td>
      <td>0.781418</td>
      <td>0.007442</td>
      <td>208</td>
    </tr>
    <tr>
      <th>594</th>
      <td>0.516333</td>
      <td>0.033321</td>
      <td>0.196332</td>
      <td>0.003858</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.738555</td>
      <td>0.755097</td>
      <td>0.748132</td>
      <td>0.747261</td>
      <td>0.006781</td>
      <td>291</td>
      <td>0.771064</td>
      <td>0.788227</td>
      <td>0.784965</td>
      <td>0.781418</td>
      <td>0.007442</td>
      <td>208</td>
    </tr>
    <tr>
      <th>540</th>
      <td>0.487672</td>
      <td>0.016029</td>
      <td>0.208996</td>
      <td>0.022465</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.738555</td>
      <td>0.755097</td>
      <td>0.748132</td>
      <td>0.747261</td>
      <td>0.006781</td>
      <td>291</td>
      <td>0.771064</td>
      <td>0.788227</td>
      <td>0.784965</td>
      <td>0.781418</td>
      <td>0.007442</td>
      <td>208</td>
    </tr>
    <tr>
      <th>609</th>
      <td>0.546663</td>
      <td>0.059441</td>
      <td>0.226003</td>
      <td>0.028601</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.739286</td>
      <td>0.754517</td>
      <td>0.747387</td>
      <td>0.747063</td>
      <td>0.006222</td>
      <td>295</td>
      <td>0.773475</td>
      <td>0.788369</td>
      <td>0.786667</td>
      <td>0.782837</td>
      <td>0.006656</td>
      <td>191</td>
    </tr>
    <tr>
      <th>550</th>
      <td>2.110334</td>
      <td>0.054929</td>
      <td>0.305002</td>
      <td>0.007072</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.732864</td>
      <td>0.758776</td>
      <td>0.747730</td>
      <td>0.746457</td>
      <td>0.010617</td>
      <td>296</td>
      <td>0.747943</td>
      <td>0.773759</td>
      <td>0.763830</td>
      <td>0.761844</td>
      <td>0.010632</td>
      <td>311</td>
    </tr>
    <tr>
      <th>619</th>
      <td>1.736670</td>
      <td>0.030340</td>
      <td>0.367038</td>
      <td>0.057494</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.733560</td>
      <td>0.754197</td>
      <td>0.747776</td>
      <td>0.745177</td>
      <td>0.008623</td>
      <td>297</td>
      <td>0.751064</td>
      <td>0.770922</td>
      <td>0.765106</td>
      <td>0.762364</td>
      <td>0.008336</td>
      <td>310</td>
    </tr>
    <tr>
      <th>578</th>
      <td>3.444655</td>
      <td>0.031356</td>
      <td>0.422667</td>
      <td>0.026512</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.730612</td>
      <td>0.756511</td>
      <td>0.747329</td>
      <td>0.744817</td>
      <td>0.010722</td>
      <td>298</td>
      <td>0.744539</td>
      <td>0.770355</td>
      <td>0.761986</td>
      <td>0.758960</td>
      <td>0.010754</td>
      <td>317</td>
    </tr>
    <tr>
      <th>187</th>
      <td>1.867667</td>
      <td>0.014057</td>
      <td>0.353871</td>
      <td>0.013416</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.732946</td>
      <td>0.753229</td>
      <td>0.747552</td>
      <td>0.744576</td>
      <td>0.008544</td>
      <td>299</td>
      <td>0.750355</td>
      <td>0.769929</td>
      <td>0.764823</td>
      <td>0.761702</td>
      <td>0.008290</td>
      <td>312</td>
    </tr>
    <tr>
      <th>519</th>
      <td>0.522841</td>
      <td>0.030893</td>
      <td>0.199001</td>
      <td>0.009202</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.738401</td>
      <td>0.753921</td>
      <td>0.741372</td>
      <td>0.744564</td>
      <td>0.006726</td>
      <td>300</td>
      <td>0.770071</td>
      <td>0.786241</td>
      <td>0.776170</td>
      <td>0.777494</td>
      <td>0.006668</td>
      <td>254</td>
    </tr>
    <tr>
      <th>465</th>
      <td>0.500108</td>
      <td>0.027638</td>
      <td>0.224960</td>
      <td>0.028480</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.738401</td>
      <td>0.753921</td>
      <td>0.741372</td>
      <td>0.744564</td>
      <td>0.006726</td>
      <td>300</td>
      <td>0.770071</td>
      <td>0.786241</td>
      <td>0.776170</td>
      <td>0.777494</td>
      <td>0.006668</td>
      <td>254</td>
    </tr>
    <tr>
      <th>573</th>
      <td>0.475000</td>
      <td>0.013061</td>
      <td>0.226003</td>
      <td>0.031966</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.738401</td>
      <td>0.753921</td>
      <td>0.741372</td>
      <td>0.744564</td>
      <td>0.006726</td>
      <td>300</td>
      <td>0.770071</td>
      <td>0.786241</td>
      <td>0.776170</td>
      <td>0.777494</td>
      <td>0.006668</td>
      <td>254</td>
    </tr>
    <tr>
      <th>627</th>
      <td>0.517000</td>
      <td>0.044451</td>
      <td>0.182003</td>
      <td>0.009629</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.738401</td>
      <td>0.753921</td>
      <td>0.741372</td>
      <td>0.744564</td>
      <td>0.006726</td>
      <td>300</td>
      <td>0.770071</td>
      <td>0.786241</td>
      <td>0.776170</td>
      <td>0.777494</td>
      <td>0.006668</td>
      <td>254</td>
    </tr>
    <tr>
      <th>620</th>
      <td>2.920370</td>
      <td>0.151689</td>
      <td>0.602021</td>
      <td>0.029720</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.730309</td>
      <td>0.752650</td>
      <td>0.749419</td>
      <td>0.744126</td>
      <td>0.009859</td>
      <td>304</td>
      <td>0.748085</td>
      <td>0.769645</td>
      <td>0.766525</td>
      <td>0.761418</td>
      <td>0.009514</td>
      <td>313</td>
    </tr>
    <tr>
      <th>577</th>
      <td>2.235004</td>
      <td>0.004319</td>
      <td>0.347668</td>
      <td>0.007319</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.730151</td>
      <td>0.756228</td>
      <td>0.745419</td>
      <td>0.743933</td>
      <td>0.010697</td>
      <td>305</td>
      <td>0.743262</td>
      <td>0.769645</td>
      <td>0.759858</td>
      <td>0.757589</td>
      <td>0.010890</td>
      <td>319</td>
    </tr>
    <tr>
      <th>422</th>
      <td>1.906221</td>
      <td>0.017721</td>
      <td>0.462667</td>
      <td>0.025459</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.737013</td>
      <td>0.757669</td>
      <td>0.736362</td>
      <td>0.743681</td>
      <td>0.009894</td>
      <td>306</td>
      <td>0.754752</td>
      <td>0.775177</td>
      <td>0.775461</td>
      <td>0.768463</td>
      <td>0.009696</td>
      <td>297</td>
    </tr>
    <tr>
      <th>188</th>
      <td>2.816719</td>
      <td>0.100079</td>
      <td>0.418999</td>
      <td>0.012570</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.729916</td>
      <td>0.751643</td>
      <td>0.748400</td>
      <td>0.743320</td>
      <td>0.009570</td>
      <td>307</td>
      <td>0.747660</td>
      <td>0.768652</td>
      <td>0.765390</td>
      <td>0.760567</td>
      <td>0.009224</td>
      <td>314</td>
    </tr>
    <tr>
      <th>618</th>
      <td>1.056573</td>
      <td>0.300594</td>
      <td>0.199003</td>
      <td>0.005099</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.734774</td>
      <td>0.751999</td>
      <td>0.741213</td>
      <td>0.742662</td>
      <td>0.007106</td>
      <td>308</td>
      <td>0.752199</td>
      <td>0.769504</td>
      <td>0.759149</td>
      <td>0.760284</td>
      <td>0.007110</td>
      <td>315</td>
    </tr>
    <tr>
      <th>177</th>
      <td>0.513333</td>
      <td>0.009566</td>
      <td>0.205335</td>
      <td>0.024724</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.750925</td>
      <td>0.769402</td>
      <td>0.707263</td>
      <td>0.742530</td>
      <td>0.026053</td>
      <td>309</td>
      <td>0.777021</td>
      <td>0.794894</td>
      <td>0.777163</td>
      <td>0.783026</td>
      <td>0.008392</td>
      <td>190</td>
    </tr>
    <tr>
      <th>646</th>
      <td>1.741249</td>
      <td>0.042352</td>
      <td>0.342095</td>
      <td>0.033733</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.728519</td>
      <td>0.751204</td>
      <td>0.745976</td>
      <td>0.741900</td>
      <td>0.009699</td>
      <td>310</td>
      <td>0.743121</td>
      <td>0.765248</td>
      <td>0.760851</td>
      <td>0.756407</td>
      <td>0.009565</td>
      <td>322</td>
    </tr>
    <tr>
      <th>546</th>
      <td>0.478999</td>
      <td>0.048197</td>
      <td>0.221999</td>
      <td>0.043183</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.735588</td>
      <td>0.753045</td>
      <td>0.736345</td>
      <td>0.741659</td>
      <td>0.008057</td>
      <td>311</td>
      <td>0.770780</td>
      <td>0.787518</td>
      <td>0.776170</td>
      <td>0.778156</td>
      <td>0.006976</td>
      <td>244</td>
    </tr>
    <tr>
      <th>600</th>
      <td>0.497045</td>
      <td>0.024590</td>
      <td>0.239329</td>
      <td>0.026079</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.735588</td>
      <td>0.753045</td>
      <td>0.736345</td>
      <td>0.741659</td>
      <td>0.008057</td>
      <td>311</td>
      <td>0.770780</td>
      <td>0.787518</td>
      <td>0.776170</td>
      <td>0.778156</td>
      <td>0.006976</td>
      <td>244</td>
    </tr>
    <tr>
      <th>492</th>
      <td>0.507512</td>
      <td>0.071837</td>
      <td>0.206688</td>
      <td>0.014067</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.735588</td>
      <td>0.753045</td>
      <td>0.736345</td>
      <td>0.741659</td>
      <td>0.008057</td>
      <td>311</td>
      <td>0.770780</td>
      <td>0.787518</td>
      <td>0.776170</td>
      <td>0.778156</td>
      <td>0.006976</td>
      <td>244</td>
    </tr>
    <tr>
      <th>438</th>
      <td>0.528999</td>
      <td>0.012327</td>
      <td>0.214696</td>
      <td>0.021244</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.735588</td>
      <td>0.753045</td>
      <td>0.736345</td>
      <td>0.741659</td>
      <td>0.008057</td>
      <td>311</td>
      <td>0.770780</td>
      <td>0.787518</td>
      <td>0.776170</td>
      <td>0.778156</td>
      <td>0.006976</td>
      <td>244</td>
    </tr>
    <tr>
      <th>186</th>
      <td>1.011599</td>
      <td>0.183956</td>
      <td>0.235665</td>
      <td>0.027108</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.733566</td>
      <td>0.750807</td>
      <td>0.740555</td>
      <td>0.741643</td>
      <td>0.007080</td>
      <td>315</td>
      <td>0.751206</td>
      <td>0.768227</td>
      <td>0.758440</td>
      <td>0.759291</td>
      <td>0.006975</td>
      <td>316</td>
    </tr>
    <tr>
      <th>214</th>
      <td>1.708668</td>
      <td>0.023978</td>
      <td>0.352666</td>
      <td>0.009568</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.728295</td>
      <td>0.750877</td>
      <td>0.745426</td>
      <td>0.741533</td>
      <td>0.009622</td>
      <td>316</td>
      <td>0.742837</td>
      <td>0.764823</td>
      <td>0.760142</td>
      <td>0.755934</td>
      <td>0.009456</td>
      <td>324</td>
    </tr>
    <tr>
      <th>645</th>
      <td>0.834750</td>
      <td>0.065053</td>
      <td>0.226505</td>
      <td>0.026863</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.731499</td>
      <td>0.752434</td>
      <td>0.740621</td>
      <td>0.741518</td>
      <td>0.008570</td>
      <td>317</td>
      <td>0.746099</td>
      <td>0.767376</td>
      <td>0.756312</td>
      <td>0.756596</td>
      <td>0.008688</td>
      <td>321</td>
    </tr>
    <tr>
      <th>213</th>
      <td>0.808998</td>
      <td>0.040007</td>
      <td>0.199998</td>
      <td>0.011431</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.729943</td>
      <td>0.752617</td>
      <td>0.739738</td>
      <td>0.740766</td>
      <td>0.009285</td>
      <td>318</td>
      <td>0.744539</td>
      <td>0.767376</td>
      <td>0.755319</td>
      <td>0.755745</td>
      <td>0.009328</td>
      <td>325</td>
    </tr>
    <tr>
      <th>647</th>
      <td>2.595526</td>
      <td>0.028926</td>
      <td>0.397330</td>
      <td>0.012555</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.726554</td>
      <td>0.748509</td>
      <td>0.744935</td>
      <td>0.739999</td>
      <td>0.009618</td>
      <td>319</td>
      <td>0.740993</td>
      <td>0.762553</td>
      <td>0.759574</td>
      <td>0.754374</td>
      <td>0.009539</td>
      <td>329</td>
    </tr>
    <tr>
      <th>215</th>
      <td>2.599669</td>
      <td>0.028289</td>
      <td>0.433664</td>
      <td>0.006550</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.726068</td>
      <td>0.747919</td>
      <td>0.743974</td>
      <td>0.739320</td>
      <td>0.009508</td>
      <td>320</td>
      <td>0.740426</td>
      <td>0.761844</td>
      <td>0.758582</td>
      <td>0.753617</td>
      <td>0.009422</td>
      <td>331</td>
    </tr>
    <tr>
      <th>549</th>
      <td>0.871665</td>
      <td>0.036933</td>
      <td>0.194669</td>
      <td>0.001885</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.729755</td>
      <td>0.748859</td>
      <td>0.738761</td>
      <td>0.739125</td>
      <td>0.007804</td>
      <td>321</td>
      <td>0.743972</td>
      <td>0.763121</td>
      <td>0.754184</td>
      <td>0.753759</td>
      <td>0.007823</td>
      <td>330</td>
    </tr>
    <tr>
      <th>576</th>
      <td>0.855001</td>
      <td>0.014236</td>
      <td>0.200998</td>
      <td>0.018548</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.728103</td>
      <td>0.750220</td>
      <td>0.737235</td>
      <td>0.738519</td>
      <td>0.009074</td>
      <td>322</td>
      <td>0.740709</td>
      <td>0.763262</td>
      <td>0.751489</td>
      <td>0.751820</td>
      <td>0.009210</td>
      <td>332</td>
    </tr>
    <tr>
      <th>404</th>
      <td>2.421297</td>
      <td>0.024323</td>
      <td>0.396667</td>
      <td>0.011609</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.723752</td>
      <td>0.745903</td>
      <td>0.744543</td>
      <td>0.738066</td>
      <td>0.010137</td>
      <td>323</td>
      <td>0.741560</td>
      <td>0.762837</td>
      <td>0.761418</td>
      <td>0.755272</td>
      <td>0.009713</td>
      <td>326</td>
    </tr>
    <tr>
      <th>421</th>
      <td>1.248256</td>
      <td>0.028155</td>
      <td>0.379661</td>
      <td>0.041249</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.735556</td>
      <td>0.754368</td>
      <td>0.723550</td>
      <td>0.737825</td>
      <td>0.012683</td>
      <td>324</td>
      <td>0.754043</td>
      <td>0.772340</td>
      <td>0.770780</td>
      <td>0.765721</td>
      <td>0.008282</td>
      <td>303</td>
    </tr>
    <tr>
      <th>403</th>
      <td>1.612951</td>
      <td>0.055125</td>
      <td>0.334179</td>
      <td>0.026367</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.724919</td>
      <td>0.745546</td>
      <td>0.742617</td>
      <td>0.737694</td>
      <td>0.009112</td>
      <td>325</td>
      <td>0.742553</td>
      <td>0.762411</td>
      <td>0.759433</td>
      <td>0.754799</td>
      <td>0.008744</td>
      <td>327</td>
    </tr>
    <tr>
      <th>118</th>
      <td>1.925668</td>
      <td>0.042083</td>
      <td>0.356667</td>
      <td>0.020758</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.723339</td>
      <td>0.748766</td>
      <td>0.740528</td>
      <td>0.737544</td>
      <td>0.010593</td>
      <td>326</td>
      <td>0.737589</td>
      <td>0.762411</td>
      <td>0.755035</td>
      <td>0.751678</td>
      <td>0.010408</td>
      <td>334</td>
    </tr>
    <tr>
      <th>402</th>
      <td>0.708975</td>
      <td>0.011255</td>
      <td>0.206443</td>
      <td>0.004126</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.727950</td>
      <td>0.746080</td>
      <td>0.737407</td>
      <td>0.737146</td>
      <td>0.007404</td>
      <td>327</td>
      <td>0.745390</td>
      <td>0.763546</td>
      <td>0.755177</td>
      <td>0.754704</td>
      <td>0.007420</td>
      <td>328</td>
    </tr>
    <tr>
      <th>119</th>
      <td>3.199669</td>
      <td>0.057989</td>
      <td>0.395330</td>
      <td>0.014705</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.721662</td>
      <td>0.745257</td>
      <td>0.741756</td>
      <td>0.736225</td>
      <td>0.010396</td>
      <td>328</td>
      <td>0.736596</td>
      <td>0.760000</td>
      <td>0.756596</td>
      <td>0.751064</td>
      <td>0.010324</td>
      <td>335</td>
    </tr>
    <tr>
      <th>429</th>
      <td>0.703164</td>
      <td>0.058180</td>
      <td>0.206314</td>
      <td>0.014445</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.723750</td>
      <td>0.745012</td>
      <td>0.735270</td>
      <td>0.734677</td>
      <td>0.008690</td>
      <td>329</td>
      <td>0.737872</td>
      <td>0.759149</td>
      <td>0.749929</td>
      <td>0.748983</td>
      <td>0.008712</td>
      <td>336</td>
    </tr>
    <tr>
      <th>117</th>
      <td>0.816999</td>
      <td>0.016307</td>
      <td>0.214000</td>
      <td>0.007874</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.723948</td>
      <td>0.744302</td>
      <td>0.735378</td>
      <td>0.734543</td>
      <td>0.008331</td>
      <td>330</td>
      <td>0.737447</td>
      <td>0.758156</td>
      <td>0.749645</td>
      <td>0.748416</td>
      <td>0.008499</td>
      <td>338</td>
    </tr>
    <tr>
      <th>145</th>
      <td>1.974004</td>
      <td>0.008833</td>
      <td>0.319998</td>
      <td>0.008286</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.720376</td>
      <td>0.742711</td>
      <td>0.739084</td>
      <td>0.734057</td>
      <td>0.009786</td>
      <td>331</td>
      <td>0.732766</td>
      <td>0.755035</td>
      <td>0.752057</td>
      <td>0.746619</td>
      <td>0.009871</td>
      <td>340</td>
    </tr>
    <tr>
      <th>430</th>
      <td>1.560883</td>
      <td>0.028256</td>
      <td>0.394689</td>
      <td>0.005244</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.718280</td>
      <td>0.741381</td>
      <td>0.737959</td>
      <td>0.732540</td>
      <td>0.010180</td>
      <td>332</td>
      <td>0.732340</td>
      <td>0.754752</td>
      <td>0.751915</td>
      <td>0.746336</td>
      <td>0.009964</td>
      <td>341</td>
    </tr>
    <tr>
      <th>144</th>
      <td>0.823333</td>
      <td>0.022878</td>
      <td>0.203666</td>
      <td>0.007925</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.720523</td>
      <td>0.742607</td>
      <td>0.732684</td>
      <td>0.731938</td>
      <td>0.009031</td>
      <td>333</td>
      <td>0.732624</td>
      <td>0.755177</td>
      <td>0.745957</td>
      <td>0.744586</td>
      <td>0.009258</td>
      <td>347</td>
    </tr>
    <tr>
      <th>146</th>
      <td>3.285339</td>
      <td>0.203690</td>
      <td>0.379329</td>
      <td>0.008340</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.717195</td>
      <td>0.739731</td>
      <td>0.736836</td>
      <td>0.731254</td>
      <td>0.010011</td>
      <td>334</td>
      <td>0.729929</td>
      <td>0.752199</td>
      <td>0.749787</td>
      <td>0.743972</td>
      <td>0.009978</td>
      <td>355</td>
    </tr>
    <tr>
      <th>431</th>
      <td>2.374843</td>
      <td>0.041649</td>
      <td>0.413509</td>
      <td>0.056753</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.716507</td>
      <td>0.737873</td>
      <td>0.737217</td>
      <td>0.730532</td>
      <td>0.009921</td>
      <td>335</td>
      <td>0.729929</td>
      <td>0.751206</td>
      <td>0.750922</td>
      <td>0.744019</td>
      <td>0.009964</td>
      <td>354</td>
    </tr>
    <tr>
      <th>275</th>
      <td>1.972393</td>
      <td>0.077594</td>
      <td>0.450089</td>
      <td>0.060260</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.714560</td>
      <td>0.731664</td>
      <td>0.735080</td>
      <td>0.727101</td>
      <td>0.008977</td>
      <td>336</td>
      <td>0.733333</td>
      <td>0.749645</td>
      <td>0.753759</td>
      <td>0.745579</td>
      <td>0.008820</td>
      <td>342</td>
    </tr>
    <tr>
      <th>383</th>
      <td>1.939668</td>
      <td>0.040742</td>
      <td>0.452998</td>
      <td>0.036393</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.714560</td>
      <td>0.731664</td>
      <td>0.735080</td>
      <td>0.727101</td>
      <td>0.008977</td>
      <td>336</td>
      <td>0.733333</td>
      <td>0.749645</td>
      <td>0.753759</td>
      <td>0.745579</td>
      <td>0.008820</td>
      <td>342</td>
    </tr>
    <tr>
      <th>221</th>
      <td>1.945334</td>
      <td>0.018372</td>
      <td>0.436668</td>
      <td>0.023684</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.714560</td>
      <td>0.731664</td>
      <td>0.735080</td>
      <td>0.727101</td>
      <td>0.008977</td>
      <td>336</td>
      <td>0.733333</td>
      <td>0.749645</td>
      <td>0.753759</td>
      <td>0.745579</td>
      <td>0.008820</td>
      <td>342</td>
    </tr>
    <tr>
      <th>329</th>
      <td>2.722834</td>
      <td>0.167420</td>
      <td>0.457484</td>
      <td>0.043237</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.714560</td>
      <td>0.731664</td>
      <td>0.735080</td>
      <td>0.727101</td>
      <td>0.008977</td>
      <td>336</td>
      <td>0.733333</td>
      <td>0.749645</td>
      <td>0.753759</td>
      <td>0.745579</td>
      <td>0.008820</td>
      <td>342</td>
    </tr>
    <tr>
      <th>274</th>
      <td>1.250993</td>
      <td>0.013971</td>
      <td>0.306400</td>
      <td>0.012277</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.712559</td>
      <td>0.731452</td>
      <td>0.732857</td>
      <td>0.725623</td>
      <td>0.009255</td>
      <td>340</td>
      <td>0.731631</td>
      <td>0.749645</td>
      <td>0.751773</td>
      <td>0.744350</td>
      <td>0.009035</td>
      <td>348</td>
    </tr>
    <tr>
      <th>328</th>
      <td>1.436667</td>
      <td>0.031200</td>
      <td>0.626937</td>
      <td>0.025820</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.712559</td>
      <td>0.731452</td>
      <td>0.732857</td>
      <td>0.725623</td>
      <td>0.009255</td>
      <td>340</td>
      <td>0.731631</td>
      <td>0.749645</td>
      <td>0.751773</td>
      <td>0.744350</td>
      <td>0.009035</td>
      <td>348</td>
    </tr>
    <tr>
      <th>382</th>
      <td>1.239334</td>
      <td>0.017931</td>
      <td>0.324668</td>
      <td>0.020038</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.712559</td>
      <td>0.731452</td>
      <td>0.732857</td>
      <td>0.725623</td>
      <td>0.009255</td>
      <td>340</td>
      <td>0.731631</td>
      <td>0.749645</td>
      <td>0.751773</td>
      <td>0.744350</td>
      <td>0.009035</td>
      <td>348</td>
    </tr>
    <tr>
      <th>220</th>
      <td>1.220670</td>
      <td>0.022937</td>
      <td>0.321331</td>
      <td>0.022575</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.712559</td>
      <td>0.731452</td>
      <td>0.732857</td>
      <td>0.725623</td>
      <td>0.009255</td>
      <td>340</td>
      <td>0.731631</td>
      <td>0.749645</td>
      <td>0.751773</td>
      <td>0.744350</td>
      <td>0.009035</td>
      <td>348</td>
    </tr>
    <tr>
      <th>284</th>
      <td>1.970469</td>
      <td>0.055234</td>
      <td>0.417303</td>
      <td>0.019388</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.712823</td>
      <td>0.729663</td>
      <td>0.734079</td>
      <td>0.725522</td>
      <td>0.009159</td>
      <td>344</td>
      <td>0.731773</td>
      <td>0.747660</td>
      <td>0.753050</td>
      <td>0.744161</td>
      <td>0.009032</td>
      <td>353</td>
    </tr>
    <tr>
      <th>458</th>
      <td>2.366335</td>
      <td>0.034758</td>
      <td>0.427329</td>
      <td>0.015796</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.711352</td>
      <td>0.729872</td>
      <td>0.731657</td>
      <td>0.724294</td>
      <td>0.009180</td>
      <td>345</td>
      <td>0.727801</td>
      <td>0.745248</td>
      <td>0.747518</td>
      <td>0.740189</td>
      <td>0.008808</td>
      <td>367</td>
    </tr>
    <tr>
      <th>283</th>
      <td>1.300665</td>
      <td>0.015105</td>
      <td>0.344668</td>
      <td>0.026549</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.711026</td>
      <td>0.729450</td>
      <td>0.732159</td>
      <td>0.724212</td>
      <td>0.009389</td>
      <td>346</td>
      <td>0.730496</td>
      <td>0.747660</td>
      <td>0.751206</td>
      <td>0.743121</td>
      <td>0.009043</td>
      <td>357</td>
    </tr>
    <tr>
      <th>26</th>
      <td>2.278604</td>
      <td>0.032741</td>
      <td>0.376833</td>
      <td>0.007729</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.711481</td>
      <td>0.729309</td>
      <td>0.731224</td>
      <td>0.724005</td>
      <td>0.008890</td>
      <td>347</td>
      <td>0.727943</td>
      <td>0.744681</td>
      <td>0.747092</td>
      <td>0.739905</td>
      <td>0.008516</td>
      <td>369</td>
    </tr>
    <tr>
      <th>225</th>
      <td>0.525331</td>
      <td>0.015325</td>
      <td>0.191001</td>
      <td>0.007119</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.710002</td>
      <td>0.731421</td>
      <td>0.730271</td>
      <td>0.723898</td>
      <td>0.009837</td>
      <td>348</td>
      <td>0.726099</td>
      <td>0.746383</td>
      <td>0.762979</td>
      <td>0.745154</td>
      <td>0.015081</td>
      <td>346</td>
    </tr>
    <tr>
      <th>419</th>
      <td>1.915262</td>
      <td>0.056839</td>
      <td>0.427145</td>
      <td>0.030484</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.708253</td>
      <td>0.727637</td>
      <td>0.734612</td>
      <td>0.723501</td>
      <td>0.011151</td>
      <td>349</td>
      <td>0.723830</td>
      <td>0.742411</td>
      <td>0.755461</td>
      <td>0.740567</td>
      <td>0.012979</td>
      <td>365</td>
    </tr>
    <tr>
      <th>457</th>
      <td>1.539668</td>
      <td>0.015371</td>
      <td>0.337667</td>
      <td>0.039667</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.709124</td>
      <td>0.730371</td>
      <td>0.730383</td>
      <td>0.723293</td>
      <td>0.010019</td>
      <td>350</td>
      <td>0.725957</td>
      <td>0.746383</td>
      <td>0.746525</td>
      <td>0.739622</td>
      <td>0.009662</td>
      <td>370</td>
    </tr>
    <tr>
      <th>25</th>
      <td>1.541055</td>
      <td>0.014053</td>
      <td>0.390451</td>
      <td>0.018606</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.708994</td>
      <td>0.730240</td>
      <td>0.730383</td>
      <td>0.723206</td>
      <td>0.010049</td>
      <td>351</td>
      <td>0.725816</td>
      <td>0.746241</td>
      <td>0.746525</td>
      <td>0.739527</td>
      <td>0.009696</td>
      <td>371</td>
    </tr>
    <tr>
      <th>242</th>
      <td>2.246664</td>
      <td>0.047749</td>
      <td>0.399005</td>
      <td>0.034184</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.710008</td>
      <td>0.727699</td>
      <td>0.730005</td>
      <td>0.722571</td>
      <td>0.008933</td>
      <td>352</td>
      <td>0.726241</td>
      <td>0.742979</td>
      <td>0.745816</td>
      <td>0.738345</td>
      <td>0.008637</td>
      <td>375</td>
    </tr>
    <tr>
      <th>418</th>
      <td>1.250486</td>
      <td>0.023232</td>
      <td>0.340854</td>
      <td>0.048612</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.708187</td>
      <td>0.726207</td>
      <td>0.732984</td>
      <td>0.722459</td>
      <td>0.010464</td>
      <td>353</td>
      <td>0.724113</td>
      <td>0.741277</td>
      <td>0.755319</td>
      <td>0.740236</td>
      <td>0.012761</td>
      <td>366</td>
    </tr>
    <tr>
      <th>241</th>
      <td>1.508334</td>
      <td>0.036462</td>
      <td>0.340334</td>
      <td>0.003301</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.707787</td>
      <td>0.729403</td>
      <td>0.729438</td>
      <td>0.722209</td>
      <td>0.010198</td>
      <td>354</td>
      <td>0.724539</td>
      <td>0.745248</td>
      <td>0.745674</td>
      <td>0.738487</td>
      <td>0.009864</td>
      <td>373</td>
    </tr>
    <tr>
      <th>219</th>
      <td>0.519666</td>
      <td>0.014521</td>
      <td>0.219000</td>
      <td>0.016756</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.712022</td>
      <td>0.728578</td>
      <td>0.725261</td>
      <td>0.721954</td>
      <td>0.007152</td>
      <td>355</td>
      <td>0.731489</td>
      <td>0.748085</td>
      <td>0.744965</td>
      <td>0.741513</td>
      <td>0.007201</td>
      <td>359</td>
    </tr>
    <tr>
      <th>381</th>
      <td>0.537667</td>
      <td>0.018118</td>
      <td>0.192999</td>
      <td>0.002159</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.712022</td>
      <td>0.728578</td>
      <td>0.725261</td>
      <td>0.721954</td>
      <td>0.007152</td>
      <td>355</td>
      <td>0.731489</td>
      <td>0.748085</td>
      <td>0.744965</td>
      <td>0.741513</td>
      <td>0.007201</td>
      <td>359</td>
    </tr>
    <tr>
      <th>327</th>
      <td>0.484332</td>
      <td>0.017971</td>
      <td>0.205668</td>
      <td>0.015627</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.712022</td>
      <td>0.728578</td>
      <td>0.725261</td>
      <td>0.721954</td>
      <td>0.007152</td>
      <td>355</td>
      <td>0.731489</td>
      <td>0.748085</td>
      <td>0.744965</td>
      <td>0.741513</td>
      <td>0.007201</td>
      <td>359</td>
    </tr>
    <tr>
      <th>273</th>
      <td>0.506332</td>
      <td>0.019621</td>
      <td>0.218999</td>
      <td>0.035138</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.712022</td>
      <td>0.728578</td>
      <td>0.725261</td>
      <td>0.721954</td>
      <td>0.007152</td>
      <td>355</td>
      <td>0.731489</td>
      <td>0.748085</td>
      <td>0.744965</td>
      <td>0.741513</td>
      <td>0.007201</td>
      <td>359</td>
    </tr>
    <tr>
      <th>257</th>
      <td>1.948257</td>
      <td>0.014603</td>
      <td>0.454774</td>
      <td>0.016346</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.710791</td>
      <td>0.727106</td>
      <td>0.727565</td>
      <td>0.721821</td>
      <td>0.007801</td>
      <td>359</td>
      <td>0.724681</td>
      <td>0.739858</td>
      <td>0.741844</td>
      <td>0.735461</td>
      <td>0.007666</td>
      <td>382</td>
    </tr>
    <tr>
      <th>456</th>
      <td>0.782001</td>
      <td>0.014852</td>
      <td>0.205330</td>
      <td>0.017213</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.709946</td>
      <td>0.728984</td>
      <td>0.726150</td>
      <td>0.721693</td>
      <td>0.008387</td>
      <td>360</td>
      <td>0.726950</td>
      <td>0.746241</td>
      <td>0.743121</td>
      <td>0.738771</td>
      <td>0.008455</td>
      <td>372</td>
    </tr>
    <tr>
      <th>226</th>
      <td>1.261668</td>
      <td>0.033191</td>
      <td>0.319998</td>
      <td>0.018456</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.711776</td>
      <td>0.724721</td>
      <td>0.728345</td>
      <td>0.721614</td>
      <td>0.007112</td>
      <td>361</td>
      <td>0.733759</td>
      <td>0.738723</td>
      <td>0.759149</td>
      <td>0.743877</td>
      <td>0.010987</td>
      <td>356</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.782998</td>
      <td>0.014165</td>
      <td>0.196668</td>
      <td>0.011672</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.709385</td>
      <td>0.728895</td>
      <td>0.726020</td>
      <td>0.721433</td>
      <td>0.008600</td>
      <td>362</td>
      <td>0.726383</td>
      <td>0.746099</td>
      <td>0.742979</td>
      <td>0.738487</td>
      <td>0.008653</td>
      <td>373</td>
    </tr>
    <tr>
      <th>255</th>
      <td>0.961030</td>
      <td>0.276689</td>
      <td>0.278221</td>
      <td>0.023011</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.707457</td>
      <td>0.726947</td>
      <td>0.729493</td>
      <td>0.721299</td>
      <td>0.009843</td>
      <td>363</td>
      <td>0.722695</td>
      <td>0.741418</td>
      <td>0.746525</td>
      <td>0.736879</td>
      <td>0.010244</td>
      <td>378</td>
    </tr>
    <tr>
      <th>420</th>
      <td>0.487659</td>
      <td>0.047605</td>
      <td>0.186142</td>
      <td>0.004423</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.730273</td>
      <td>0.745598</td>
      <td>0.687641</td>
      <td>0.721171</td>
      <td>0.024521</td>
      <td>364</td>
      <td>0.751206</td>
      <td>0.766525</td>
      <td>0.756454</td>
      <td>0.758061</td>
      <td>0.006356</td>
      <td>318</td>
    </tr>
    <tr>
      <th>256</th>
      <td>1.304030</td>
      <td>0.018548</td>
      <td>0.350909</td>
      <td>0.016545</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.709241</td>
      <td>0.726524</td>
      <td>0.727260</td>
      <td>0.721008</td>
      <td>0.008326</td>
      <td>365</td>
      <td>0.723404</td>
      <td>0.740000</td>
      <td>0.742128</td>
      <td>0.735177</td>
      <td>0.008370</td>
      <td>384</td>
    </tr>
    <tr>
      <th>282</th>
      <td>0.549350</td>
      <td>0.003677</td>
      <td>0.199357</td>
      <td>0.030966</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.711314</td>
      <td>0.726360</td>
      <td>0.723552</td>
      <td>0.720408</td>
      <td>0.006532</td>
      <td>366</td>
      <td>0.731064</td>
      <td>0.745674</td>
      <td>0.743546</td>
      <td>0.740095</td>
      <td>0.006444</td>
      <td>368</td>
    </tr>
    <tr>
      <th>229</th>
      <td>1.238152</td>
      <td>0.012323</td>
      <td>0.340333</td>
      <td>0.024086</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.720004</td>
      <td>0.732039</td>
      <td>0.708451</td>
      <td>0.720165</td>
      <td>0.009630</td>
      <td>367</td>
      <td>0.747943</td>
      <td>0.757872</td>
      <td>0.762128</td>
      <td>0.755981</td>
      <td>0.005943</td>
      <td>323</td>
    </tr>
    <tr>
      <th>417</th>
      <td>0.501185</td>
      <td>0.039762</td>
      <td>0.186784</td>
      <td>0.001892</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.707178</td>
      <td>0.726772</td>
      <td>0.726212</td>
      <td>0.720054</td>
      <td>0.009107</td>
      <td>368</td>
      <td>0.723688</td>
      <td>0.743262</td>
      <td>0.755887</td>
      <td>0.740946</td>
      <td>0.013247</td>
      <td>364</td>
    </tr>
    <tr>
      <th>232</th>
      <td>1.230333</td>
      <td>0.016740</td>
      <td>0.341332</td>
      <td>0.024934</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.748293</td>
      <td>0.764185</td>
      <td>0.645424</td>
      <td>0.719301</td>
      <td>0.052640</td>
      <td>369</td>
      <td>0.768794</td>
      <td>0.784397</td>
      <td>0.752766</td>
      <td>0.768652</td>
      <td>0.012914</td>
      <td>296</td>
    </tr>
    <tr>
      <th>240</th>
      <td>0.688999</td>
      <td>0.040420</td>
      <td>0.205998</td>
      <td>0.019098</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.706500</td>
      <td>0.726507</td>
      <td>0.724769</td>
      <td>0.719259</td>
      <td>0.009049</td>
      <td>370</td>
      <td>0.723546</td>
      <td>0.743688</td>
      <td>0.741844</td>
      <td>0.736359</td>
      <td>0.009092</td>
      <td>380</td>
    </tr>
    <tr>
      <th>228</th>
      <td>0.580343</td>
      <td>0.074325</td>
      <td>0.225066</td>
      <td>0.022929</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.713625</td>
      <td>0.730568</td>
      <td>0.712466</td>
      <td>0.718886</td>
      <td>0.008274</td>
      <td>371</td>
      <td>0.740284</td>
      <td>0.755603</td>
      <td>0.759291</td>
      <td>0.751726</td>
      <td>0.008230</td>
      <td>333</td>
    </tr>
    <tr>
      <th>356</th>
      <td>2.078000</td>
      <td>0.096294</td>
      <td>0.421002</td>
      <td>0.034099</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.705288</td>
      <td>0.726554</td>
      <td>0.723716</td>
      <td>0.718520</td>
      <td>0.009428</td>
      <td>372</td>
      <td>0.717447</td>
      <td>0.738298</td>
      <td>0.735745</td>
      <td>0.730496</td>
      <td>0.009286</td>
      <td>389</td>
    </tr>
    <tr>
      <th>248</th>
      <td>2.040350</td>
      <td>0.124468</td>
      <td>0.391998</td>
      <td>0.009415</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.705288</td>
      <td>0.726554</td>
      <td>0.723716</td>
      <td>0.718520</td>
      <td>0.009428</td>
      <td>372</td>
      <td>0.717447</td>
      <td>0.738298</td>
      <td>0.735745</td>
      <td>0.730496</td>
      <td>0.009286</td>
      <td>389</td>
    </tr>
    <tr>
      <th>410</th>
      <td>1.906001</td>
      <td>0.011045</td>
      <td>0.423000</td>
      <td>0.047461</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.705288</td>
      <td>0.726554</td>
      <td>0.723716</td>
      <td>0.718520</td>
      <td>0.009428</td>
      <td>372</td>
      <td>0.717447</td>
      <td>0.738298</td>
      <td>0.735745</td>
      <td>0.730496</td>
      <td>0.009286</td>
      <td>389</td>
    </tr>
    <tr>
      <th>302</th>
      <td>1.944673</td>
      <td>0.021852</td>
      <td>0.416660</td>
      <td>0.014053</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.705288</td>
      <td>0.726554</td>
      <td>0.723716</td>
      <td>0.718520</td>
      <td>0.009428</td>
      <td>372</td>
      <td>0.717447</td>
      <td>0.738298</td>
      <td>0.735745</td>
      <td>0.730496</td>
      <td>0.009286</td>
      <td>389</td>
    </tr>
    <tr>
      <th>230</th>
      <td>1.888165</td>
      <td>0.056966</td>
      <td>0.437331</td>
      <td>0.010532</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.721196</td>
      <td>0.736338</td>
      <td>0.697784</td>
      <td>0.718439</td>
      <td>0.015860</td>
      <td>376</td>
      <td>0.750922</td>
      <td>0.762411</td>
      <td>0.758156</td>
      <td>0.757163</td>
      <td>0.004743</td>
      <td>320</td>
    </tr>
    <tr>
      <th>483</th>
      <td>0.719818</td>
      <td>0.020228</td>
      <td>0.216747</td>
      <td>0.018096</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.702844</td>
      <td>0.725345</td>
      <td>0.724797</td>
      <td>0.717662</td>
      <td>0.010480</td>
      <td>377</td>
      <td>0.715887</td>
      <td>0.738298</td>
      <td>0.738014</td>
      <td>0.730733</td>
      <td>0.010499</td>
      <td>388</td>
    </tr>
    <tr>
      <th>51</th>
      <td>0.805915</td>
      <td>0.045324</td>
      <td>0.218353</td>
      <td>0.009535</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.702714</td>
      <td>0.725047</td>
      <td>0.724535</td>
      <td>0.717432</td>
      <td>0.010409</td>
      <td>378</td>
      <td>0.715745</td>
      <td>0.738014</td>
      <td>0.737730</td>
      <td>0.730496</td>
      <td>0.010432</td>
      <td>389</td>
    </tr>
    <tr>
      <th>409</th>
      <td>1.243001</td>
      <td>0.022465</td>
      <td>0.331332</td>
      <td>0.032066</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.702539</td>
      <td>0.725000</td>
      <td>0.723703</td>
      <td>0.717081</td>
      <td>0.010296</td>
      <td>379</td>
      <td>0.715035</td>
      <td>0.737021</td>
      <td>0.736028</td>
      <td>0.729362</td>
      <td>0.010138</td>
      <td>395</td>
    </tr>
    <tr>
      <th>301</th>
      <td>1.299999</td>
      <td>0.042163</td>
      <td>0.343669</td>
      <td>0.032064</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.702539</td>
      <td>0.725000</td>
      <td>0.723703</td>
      <td>0.717081</td>
      <td>0.010296</td>
      <td>379</td>
      <td>0.715035</td>
      <td>0.737021</td>
      <td>0.736028</td>
      <td>0.729362</td>
      <td>0.010138</td>
      <td>395</td>
    </tr>
    <tr>
      <th>247</th>
      <td>1.171334</td>
      <td>0.001245</td>
      <td>0.305331</td>
      <td>0.014057</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.702539</td>
      <td>0.725000</td>
      <td>0.723703</td>
      <td>0.717081</td>
      <td>0.010296</td>
      <td>379</td>
      <td>0.715035</td>
      <td>0.737021</td>
      <td>0.736028</td>
      <td>0.729362</td>
      <td>0.010138</td>
      <td>395</td>
    </tr>
    <tr>
      <th>355</th>
      <td>1.236000</td>
      <td>0.019611</td>
      <td>0.296333</td>
      <td>0.012682</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.702539</td>
      <td>0.725000</td>
      <td>0.723703</td>
      <td>0.717081</td>
      <td>0.010296</td>
      <td>379</td>
      <td>0.715035</td>
      <td>0.737021</td>
      <td>0.736028</td>
      <td>0.729362</td>
      <td>0.010138</td>
      <td>395</td>
    </tr>
    <tr>
      <th>416</th>
      <td>1.891066</td>
      <td>0.028939</td>
      <td>0.424945</td>
      <td>0.011806</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.704974</td>
      <td>0.719156</td>
      <td>0.727050</td>
      <td>0.717060</td>
      <td>0.009134</td>
      <td>383</td>
      <td>0.720284</td>
      <td>0.733333</td>
      <td>0.746667</td>
      <td>0.733428</td>
      <td>0.010771</td>
      <td>386</td>
    </tr>
    <tr>
      <th>311</th>
      <td>2.028220</td>
      <td>0.032715</td>
      <td>0.427016</td>
      <td>0.021853</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.702838</td>
      <td>0.724584</td>
      <td>0.723197</td>
      <td>0.716873</td>
      <td>0.009940</td>
      <td>384</td>
      <td>0.714894</td>
      <td>0.736170</td>
      <td>0.735035</td>
      <td>0.728700</td>
      <td>0.009773</td>
      <td>399</td>
    </tr>
    <tr>
      <th>252</th>
      <td>0.477954</td>
      <td>0.038916</td>
      <td>0.187497</td>
      <td>0.003323</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.701282</td>
      <td>0.721909</td>
      <td>0.726992</td>
      <td>0.716727</td>
      <td>0.011117</td>
      <td>385</td>
      <td>0.713901</td>
      <td>0.733901</td>
      <td>0.742128</td>
      <td>0.729976</td>
      <td>0.011853</td>
      <td>394</td>
    </tr>
    <tr>
      <th>233</th>
      <td>1.893683</td>
      <td>0.009873</td>
      <td>0.429000</td>
      <td>0.008286</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.747411</td>
      <td>0.761871</td>
      <td>0.639532</td>
      <td>0.716271</td>
      <td>0.054583</td>
      <td>386</td>
      <td>0.767943</td>
      <td>0.781986</td>
      <td>0.749504</td>
      <td>0.766478</td>
      <td>0.013301</td>
      <td>300</td>
    </tr>
    <tr>
      <th>231</th>
      <td>0.478013</td>
      <td>0.040759</td>
      <td>0.196335</td>
      <td>0.022840</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.744147</td>
      <td>0.761135</td>
      <td>0.642415</td>
      <td>0.715899</td>
      <td>0.052422</td>
      <td>387</td>
      <td>0.764965</td>
      <td>0.782128</td>
      <td>0.750780</td>
      <td>0.765957</td>
      <td>0.012817</td>
      <td>302</td>
    </tr>
    <tr>
      <th>310</th>
      <td>1.307003</td>
      <td>0.011522</td>
      <td>0.340998</td>
      <td>0.023249</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.700351</td>
      <td>0.724475</td>
      <td>0.722723</td>
      <td>0.715850</td>
      <td>0.010983</td>
      <td>388</td>
      <td>0.712766</td>
      <td>0.736454</td>
      <td>0.734894</td>
      <td>0.728038</td>
      <td>0.010818</td>
      <td>405</td>
    </tr>
    <tr>
      <th>414</th>
      <td>0.486999</td>
      <td>0.029016</td>
      <td>0.196340</td>
      <td>0.007365</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.698433</td>
      <td>0.723581</td>
      <td>0.725482</td>
      <td>0.715832</td>
      <td>0.012327</td>
      <td>389</td>
      <td>0.712340</td>
      <td>0.737447</td>
      <td>0.752482</td>
      <td>0.734090</td>
      <td>0.016559</td>
      <td>385</td>
    </tr>
    <tr>
      <th>300</th>
      <td>0.495994</td>
      <td>0.024128</td>
      <td>0.211002</td>
      <td>0.023789</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.701433</td>
      <td>0.723188</td>
      <td>0.722332</td>
      <td>0.715651</td>
      <td>0.010059</td>
      <td>390</td>
      <td>0.714752</td>
      <td>0.735887</td>
      <td>0.735461</td>
      <td>0.728700</td>
      <td>0.009864</td>
      <td>399</td>
    </tr>
    <tr>
      <th>408</th>
      <td>0.506998</td>
      <td>0.041577</td>
      <td>0.204669</td>
      <td>0.003681</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.701433</td>
      <td>0.723188</td>
      <td>0.722332</td>
      <td>0.715651</td>
      <td>0.010059</td>
      <td>390</td>
      <td>0.714752</td>
      <td>0.735887</td>
      <td>0.735461</td>
      <td>0.728700</td>
      <td>0.009864</td>
      <td>399</td>
    </tr>
    <tr>
      <th>246</th>
      <td>0.533663</td>
      <td>0.017307</td>
      <td>0.197337</td>
      <td>0.016214</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.701433</td>
      <td>0.723188</td>
      <td>0.722332</td>
      <td>0.715651</td>
      <td>0.010059</td>
      <td>390</td>
      <td>0.714752</td>
      <td>0.735887</td>
      <td>0.735461</td>
      <td>0.728700</td>
      <td>0.009864</td>
      <td>399</td>
    </tr>
    <tr>
      <th>354</th>
      <td>0.526666</td>
      <td>0.017746</td>
      <td>0.235000</td>
      <td>0.045521</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.701433</td>
      <td>0.723188</td>
      <td>0.722332</td>
      <td>0.715651</td>
      <td>0.010059</td>
      <td>390</td>
      <td>0.714752</td>
      <td>0.735887</td>
      <td>0.735461</td>
      <td>0.728700</td>
      <td>0.009864</td>
      <td>399</td>
    </tr>
    <tr>
      <th>52</th>
      <td>1.559109</td>
      <td>0.016821</td>
      <td>0.345064</td>
      <td>0.007050</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.699455</td>
      <td>0.724903</td>
      <td>0.722227</td>
      <td>0.715528</td>
      <td>0.011418</td>
      <td>394</td>
      <td>0.711206</td>
      <td>0.736879</td>
      <td>0.734468</td>
      <td>0.727518</td>
      <td>0.011576</td>
      <td>408</td>
    </tr>
    <tr>
      <th>484</th>
      <td>1.528442</td>
      <td>0.007409</td>
      <td>0.307001</td>
      <td>0.021774</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.699290</td>
      <td>0.724903</td>
      <td>0.722358</td>
      <td>0.715517</td>
      <td>0.011521</td>
      <td>395</td>
      <td>0.711064</td>
      <td>0.736879</td>
      <td>0.734610</td>
      <td>0.727518</td>
      <td>0.011671</td>
      <td>408</td>
    </tr>
    <tr>
      <th>254</th>
      <td>2.648909</td>
      <td>0.392598</td>
      <td>0.486075</td>
      <td>0.038405</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.702677</td>
      <td>0.722302</td>
      <td>0.720531</td>
      <td>0.715170</td>
      <td>0.008863</td>
      <td>396</td>
      <td>0.715745</td>
      <td>0.734326</td>
      <td>0.733901</td>
      <td>0.727991</td>
      <td>0.008661</td>
      <td>406</td>
    </tr>
    <tr>
      <th>267</th>
      <td>0.690780</td>
      <td>0.015526</td>
      <td>0.202792</td>
      <td>0.009306</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.700506</td>
      <td>0.722235</td>
      <td>0.722547</td>
      <td>0.715096</td>
      <td>0.010317</td>
      <td>397</td>
      <td>0.713333</td>
      <td>0.734894</td>
      <td>0.735461</td>
      <td>0.727896</td>
      <td>0.010300</td>
      <td>407</td>
    </tr>
    <tr>
      <th>415</th>
      <td>1.223705</td>
      <td>0.021192</td>
      <td>0.370122</td>
      <td>0.049270</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.700038</td>
      <td>0.717628</td>
      <td>0.727206</td>
      <td>0.714957</td>
      <td>0.011251</td>
      <td>398</td>
      <td>0.714184</td>
      <td>0.731348</td>
      <td>0.747376</td>
      <td>0.730969</td>
      <td>0.013553</td>
      <td>387</td>
    </tr>
    <tr>
      <th>485</th>
      <td>2.271955</td>
      <td>0.008601</td>
      <td>0.448364</td>
      <td>0.038444</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.698712</td>
      <td>0.724225</td>
      <td>0.721428</td>
      <td>0.714788</td>
      <td>0.011425</td>
      <td>399</td>
      <td>0.709645</td>
      <td>0.735603</td>
      <td>0.733050</td>
      <td>0.726099</td>
      <td>0.011681</td>
      <td>412</td>
    </tr>
    <tr>
      <th>53</th>
      <td>2.378865</td>
      <td>0.054268</td>
      <td>0.416378</td>
      <td>0.027289</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.698615</td>
      <td>0.724258</td>
      <td>0.721296</td>
      <td>0.714723</td>
      <td>0.011454</td>
      <td>400</td>
      <td>0.709504</td>
      <td>0.735603</td>
      <td>0.732908</td>
      <td>0.726005</td>
      <td>0.011720</td>
      <td>413</td>
    </tr>
    <tr>
      <th>227</th>
      <td>2.015395</td>
      <td>0.074925</td>
      <td>0.452539</td>
      <td>0.029597</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.714978</td>
      <td>0.700061</td>
      <td>0.728367</td>
      <td>0.714468</td>
      <td>0.011562</td>
      <td>401</td>
      <td>0.739716</td>
      <td>0.707376</td>
      <td>0.763404</td>
      <td>0.736832</td>
      <td>0.022964</td>
      <td>379</td>
    </tr>
    <tr>
      <th>269</th>
      <td>2.185470</td>
      <td>0.023638</td>
      <td>0.393343</td>
      <td>0.031112</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.698001</td>
      <td>0.722386</td>
      <td>0.721104</td>
      <td>0.713830</td>
      <td>0.011205</td>
      <td>402</td>
      <td>0.708652</td>
      <td>0.733475</td>
      <td>0.732482</td>
      <td>0.724870</td>
      <td>0.011475</td>
      <td>416</td>
    </tr>
    <tr>
      <th>268</th>
      <td>1.510884</td>
      <td>0.013855</td>
      <td>0.345062</td>
      <td>0.016650</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.697279</td>
      <td>0.722706</td>
      <td>0.720199</td>
      <td>0.713395</td>
      <td>0.011441</td>
      <td>403</td>
      <td>0.708794</td>
      <td>0.734468</td>
      <td>0.732199</td>
      <td>0.725154</td>
      <td>0.011605</td>
      <td>415</td>
    </tr>
    <tr>
      <th>309</th>
      <td>0.504670</td>
      <td>0.009027</td>
      <td>0.212666</td>
      <td>0.022305</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.699393</td>
      <td>0.720749</td>
      <td>0.719594</td>
      <td>0.713245</td>
      <td>0.009807</td>
      <td>404</td>
      <td>0.712766</td>
      <td>0.733475</td>
      <td>0.732766</td>
      <td>0.726336</td>
      <td>0.009600</td>
      <td>411</td>
    </tr>
    <tr>
      <th>253</th>
      <td>1.234869</td>
      <td>0.041214</td>
      <td>0.398622</td>
      <td>0.098170</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.698543</td>
      <td>0.717903</td>
      <td>0.722195</td>
      <td>0.712880</td>
      <td>0.010289</td>
      <td>405</td>
      <td>0.711348</td>
      <td>0.729787</td>
      <td>0.735745</td>
      <td>0.725626</td>
      <td>0.010386</td>
      <td>414</td>
    </tr>
    <tr>
      <th>552</th>
      <td>0.722334</td>
      <td>0.054952</td>
      <td>0.211335</td>
      <td>0.014384</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.700517</td>
      <td>0.718733</td>
      <td>0.718068</td>
      <td>0.712439</td>
      <td>0.008435</td>
      <td>406</td>
      <td>0.717021</td>
      <td>0.734610</td>
      <td>0.734326</td>
      <td>0.728652</td>
      <td>0.008225</td>
      <td>404</td>
    </tr>
    <tr>
      <th>279</th>
      <td>0.528380</td>
      <td>0.024551</td>
      <td>0.206433</td>
      <td>0.012779</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.699240</td>
      <td>0.719137</td>
      <td>0.718669</td>
      <td>0.712348</td>
      <td>0.009271</td>
      <td>407</td>
      <td>0.711631</td>
      <td>0.730213</td>
      <td>0.731489</td>
      <td>0.724444</td>
      <td>0.009075</td>
      <td>417</td>
    </tr>
    <tr>
      <th>351</th>
      <td>0.505666</td>
      <td>0.039300</td>
      <td>0.211334</td>
      <td>0.036576</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.700121</td>
      <td>0.720048</td>
      <td>0.716050</td>
      <td>0.712073</td>
      <td>0.008608</td>
      <td>408</td>
      <td>0.710922</td>
      <td>0.730496</td>
      <td>0.727376</td>
      <td>0.722931</td>
      <td>0.008587</td>
      <td>420</td>
    </tr>
    <tr>
      <th>243</th>
      <td>0.491666</td>
      <td>0.029397</td>
      <td>0.203332</td>
      <td>0.028800</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.700121</td>
      <td>0.720048</td>
      <td>0.716050</td>
      <td>0.712073</td>
      <td>0.008608</td>
      <td>408</td>
      <td>0.710922</td>
      <td>0.730496</td>
      <td>0.727376</td>
      <td>0.722931</td>
      <td>0.008587</td>
      <td>420</td>
    </tr>
    <tr>
      <th>405</th>
      <td>0.480666</td>
      <td>0.026135</td>
      <td>0.229667</td>
      <td>0.026231</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.700121</td>
      <td>0.720048</td>
      <td>0.716050</td>
      <td>0.712073</td>
      <td>0.008608</td>
      <td>408</td>
      <td>0.710922</td>
      <td>0.730496</td>
      <td>0.727376</td>
      <td>0.722931</td>
      <td>0.008587</td>
      <td>420</td>
    </tr>
    <tr>
      <th>297</th>
      <td>0.468998</td>
      <td>0.035899</td>
      <td>0.266001</td>
      <td>0.013143</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.700121</td>
      <td>0.720048</td>
      <td>0.716050</td>
      <td>0.712073</td>
      <td>0.008608</td>
      <td>408</td>
      <td>0.710922</td>
      <td>0.730496</td>
      <td>0.727376</td>
      <td>0.722931</td>
      <td>0.008587</td>
      <td>420</td>
    </tr>
    <tr>
      <th>216</th>
      <td>0.498999</td>
      <td>0.031876</td>
      <td>0.219003</td>
      <td>0.010036</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.700341</td>
      <td>0.717464</td>
      <td>0.717094</td>
      <td>0.711633</td>
      <td>0.007986</td>
      <td>412</td>
      <td>0.712057</td>
      <td>0.727234</td>
      <td>0.728652</td>
      <td>0.722648</td>
      <td>0.007511</td>
      <td>425</td>
    </tr>
    <tr>
      <th>270</th>
      <td>0.488472</td>
      <td>0.026996</td>
      <td>0.202721</td>
      <td>0.022976</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.700341</td>
      <td>0.717464</td>
      <td>0.717094</td>
      <td>0.711633</td>
      <td>0.007986</td>
      <td>412</td>
      <td>0.712057</td>
      <td>0.727234</td>
      <td>0.728652</td>
      <td>0.722648</td>
      <td>0.007511</td>
      <td>425</td>
    </tr>
    <tr>
      <th>324</th>
      <td>0.509001</td>
      <td>0.022909</td>
      <td>0.199669</td>
      <td>0.015434</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.700341</td>
      <td>0.717464</td>
      <td>0.717094</td>
      <td>0.711633</td>
      <td>0.007986</td>
      <td>412</td>
      <td>0.712057</td>
      <td>0.727234</td>
      <td>0.728652</td>
      <td>0.722648</td>
      <td>0.007511</td>
      <td>425</td>
    </tr>
    <tr>
      <th>378</th>
      <td>0.521998</td>
      <td>0.029808</td>
      <td>0.221001</td>
      <td>0.042552</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.700341</td>
      <td>0.717464</td>
      <td>0.717094</td>
      <td>0.711633</td>
      <td>0.007986</td>
      <td>412</td>
      <td>0.712057</td>
      <td>0.727234</td>
      <td>0.728652</td>
      <td>0.722648</td>
      <td>0.007511</td>
      <td>425</td>
    </tr>
    <tr>
      <th>308</th>
      <td>2.039002</td>
      <td>0.037344</td>
      <td>0.454665</td>
      <td>0.037061</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.696274</td>
      <td>0.719596</td>
      <td>0.718902</td>
      <td>0.711591</td>
      <td>0.010835</td>
      <td>416</td>
      <td>0.707660</td>
      <td>0.730496</td>
      <td>0.730355</td>
      <td>0.722837</td>
      <td>0.010732</td>
      <td>424</td>
    </tr>
    <tr>
      <th>353</th>
      <td>1.973002</td>
      <td>0.025510</td>
      <td>0.425662</td>
      <td>0.015325</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.695849</td>
      <td>0.719399</td>
      <td>0.717823</td>
      <td>0.711024</td>
      <td>0.010749</td>
      <td>417</td>
      <td>0.707234</td>
      <td>0.730213</td>
      <td>0.729078</td>
      <td>0.722175</td>
      <td>0.010575</td>
      <td>429</td>
    </tr>
    <tr>
      <th>245</th>
      <td>1.898840</td>
      <td>0.046218</td>
      <td>0.444332</td>
      <td>0.043516</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.695849</td>
      <td>0.719399</td>
      <td>0.717823</td>
      <td>0.711024</td>
      <td>0.010749</td>
      <td>417</td>
      <td>0.707234</td>
      <td>0.730213</td>
      <td>0.729078</td>
      <td>0.722175</td>
      <td>0.010575</td>
      <td>429</td>
    </tr>
    <tr>
      <th>407</th>
      <td>1.893000</td>
      <td>0.049556</td>
      <td>0.440667</td>
      <td>0.040613</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.695849</td>
      <td>0.719399</td>
      <td>0.717823</td>
      <td>0.711024</td>
      <td>0.010749</td>
      <td>417</td>
      <td>0.707234</td>
      <td>0.730213</td>
      <td>0.729078</td>
      <td>0.722175</td>
      <td>0.010575</td>
      <td>429</td>
    </tr>
    <tr>
      <th>299</th>
      <td>1.947335</td>
      <td>0.041772</td>
      <td>0.420998</td>
      <td>0.007070</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.695849</td>
      <td>0.719399</td>
      <td>0.717823</td>
      <td>0.711024</td>
      <td>0.010749</td>
      <td>417</td>
      <td>0.707234</td>
      <td>0.730213</td>
      <td>0.729078</td>
      <td>0.722175</td>
      <td>0.010575</td>
      <td>429</td>
    </tr>
    <tr>
      <th>306</th>
      <td>0.579336</td>
      <td>0.011441</td>
      <td>0.208997</td>
      <td>0.028859</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.698508</td>
      <td>0.718738</td>
      <td>0.715426</td>
      <td>0.710890</td>
      <td>0.008859</td>
      <td>421</td>
      <td>0.709645</td>
      <td>0.729220</td>
      <td>0.726809</td>
      <td>0.721891</td>
      <td>0.008715</td>
      <td>433</td>
    </tr>
    <tr>
      <th>120</th>
      <td>0.726333</td>
      <td>0.020984</td>
      <td>0.222001</td>
      <td>0.026623</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.700428</td>
      <td>0.716650</td>
      <td>0.715556</td>
      <td>0.710878</td>
      <td>0.007403</td>
      <td>422</td>
      <td>0.716738</td>
      <td>0.732340</td>
      <td>0.731631</td>
      <td>0.726903</td>
      <td>0.007194</td>
      <td>410</td>
    </tr>
    <tr>
      <th>553</th>
      <td>1.430173</td>
      <td>0.036498</td>
      <td>0.300002</td>
      <td>0.010038</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.699281</td>
      <td>0.716231</td>
      <td>0.715726</td>
      <td>0.710413</td>
      <td>0.007874</td>
      <td>423</td>
      <td>0.714043</td>
      <td>0.728652</td>
      <td>0.729645</td>
      <td>0.724113</td>
      <td>0.007133</td>
      <td>418</td>
    </tr>
    <tr>
      <th>121</th>
      <td>1.373671</td>
      <td>0.018837</td>
      <td>0.349663</td>
      <td>0.044855</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.697668</td>
      <td>0.715788</td>
      <td>0.715448</td>
      <td>0.709634</td>
      <td>0.008463</td>
      <td>424</td>
      <td>0.712057</td>
      <td>0.727943</td>
      <td>0.729220</td>
      <td>0.723073</td>
      <td>0.007807</td>
      <td>419</td>
    </tr>
    <tr>
      <th>406</th>
      <td>1.266665</td>
      <td>0.004188</td>
      <td>0.369999</td>
      <td>0.029811</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.694495</td>
      <td>0.716310</td>
      <td>0.716973</td>
      <td>0.709259</td>
      <td>0.010444</td>
      <td>425</td>
      <td>0.705532</td>
      <td>0.726667</td>
      <td>0.727943</td>
      <td>0.720047</td>
      <td>0.010277</td>
      <td>434</td>
    </tr>
    <tr>
      <th>298</th>
      <td>1.261665</td>
      <td>0.022096</td>
      <td>0.355673</td>
      <td>0.006236</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.694495</td>
      <td>0.716310</td>
      <td>0.716973</td>
      <td>0.709259</td>
      <td>0.010444</td>
      <td>425</td>
      <td>0.705532</td>
      <td>0.726667</td>
      <td>0.727943</td>
      <td>0.720047</td>
      <td>0.010277</td>
      <td>434</td>
    </tr>
    <tr>
      <th>352</th>
      <td>1.277001</td>
      <td>0.024533</td>
      <td>0.303663</td>
      <td>0.008183</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.694495</td>
      <td>0.716310</td>
      <td>0.716973</td>
      <td>0.709259</td>
      <td>0.010444</td>
      <td>425</td>
      <td>0.705532</td>
      <td>0.726667</td>
      <td>0.727943</td>
      <td>0.720047</td>
      <td>0.010277</td>
      <td>434</td>
    </tr>
    <tr>
      <th>244</th>
      <td>1.243524</td>
      <td>0.012329</td>
      <td>0.338332</td>
      <td>0.022096</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.694495</td>
      <td>0.716310</td>
      <td>0.716973</td>
      <td>0.709259</td>
      <td>0.010444</td>
      <td>425</td>
      <td>0.705532</td>
      <td>0.726667</td>
      <td>0.727943</td>
      <td>0.720047</td>
      <td>0.010277</td>
      <td>434</td>
    </tr>
    <tr>
      <th>362</th>
      <td>2.239689</td>
      <td>0.033496</td>
      <td>0.422290</td>
      <td>0.040893</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.692989</td>
      <td>0.717200</td>
      <td>0.715759</td>
      <td>0.708649</td>
      <td>0.011089</td>
      <td>429</td>
      <td>0.704113</td>
      <td>0.727801</td>
      <td>0.726809</td>
      <td>0.719574</td>
      <td>0.010940</td>
      <td>438</td>
    </tr>
    <tr>
      <th>307</th>
      <td>1.345336</td>
      <td>0.020952</td>
      <td>0.369664</td>
      <td>0.065589</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.692652</td>
      <td>0.715430</td>
      <td>0.716872</td>
      <td>0.708318</td>
      <td>0.011093</td>
      <td>430</td>
      <td>0.703972</td>
      <td>0.725957</td>
      <td>0.728085</td>
      <td>0.719338</td>
      <td>0.010900</td>
      <td>439</td>
    </tr>
    <tr>
      <th>335</th>
      <td>2.346203</td>
      <td>0.036520</td>
      <td>0.401977</td>
      <td>0.008392</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.693976</td>
      <td>0.710654</td>
      <td>0.718989</td>
      <td>0.707873</td>
      <td>0.010399</td>
      <td>431</td>
      <td>0.705957</td>
      <td>0.719433</td>
      <td>0.731915</td>
      <td>0.719102</td>
      <td>0.010600</td>
      <td>440</td>
    </tr>
    <tr>
      <th>554</th>
      <td>1.885526</td>
      <td>0.018671</td>
      <td>0.386000</td>
      <td>0.014308</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.694011</td>
      <td>0.712577</td>
      <td>0.710691</td>
      <td>0.705760</td>
      <td>0.008343</td>
      <td>432</td>
      <td>0.705957</td>
      <td>0.722837</td>
      <td>0.722411</td>
      <td>0.717069</td>
      <td>0.007859</td>
      <td>443</td>
    </tr>
    <tr>
      <th>337</th>
      <td>1.264595</td>
      <td>0.011318</td>
      <td>0.336492</td>
      <td>0.025196</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.693949</td>
      <td>0.711761</td>
      <td>0.711105</td>
      <td>0.705605</td>
      <td>0.008247</td>
      <td>433</td>
      <td>0.707092</td>
      <td>0.722837</td>
      <td>0.723546</td>
      <td>0.717825</td>
      <td>0.007595</td>
      <td>442</td>
    </tr>
    <tr>
      <th>122</th>
      <td>1.915004</td>
      <td>0.049486</td>
      <td>0.415665</td>
      <td>0.057520</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.693044</td>
      <td>0.712577</td>
      <td>0.710993</td>
      <td>0.705538</td>
      <td>0.008858</td>
      <td>434</td>
      <td>0.704823</td>
      <td>0.722837</td>
      <td>0.722553</td>
      <td>0.716738</td>
      <td>0.008426</td>
      <td>444</td>
    </tr>
    <tr>
      <th>361</th>
      <td>1.561180</td>
      <td>0.018184</td>
      <td>0.297665</td>
      <td>0.012393</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.688609</td>
      <td>0.714185</td>
      <td>0.712972</td>
      <td>0.705255</td>
      <td>0.011781</td>
      <td>435</td>
      <td>0.699858</td>
      <td>0.724681</td>
      <td>0.724113</td>
      <td>0.716217</td>
      <td>0.011570</td>
      <td>445</td>
    </tr>
    <tr>
      <th>338</th>
      <td>1.975473</td>
      <td>0.033009</td>
      <td>0.411997</td>
      <td>0.010194</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.691039</td>
      <td>0.712708</td>
      <td>0.710315</td>
      <td>0.704687</td>
      <td>0.009700</td>
      <td>436</td>
      <td>0.702553</td>
      <td>0.722979</td>
      <td>0.721560</td>
      <td>0.715697</td>
      <td>0.009312</td>
      <td>447</td>
    </tr>
    <tr>
      <th>280</th>
      <td>1.289972</td>
      <td>0.020822</td>
      <td>0.330999</td>
      <td>0.018833</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.693610</td>
      <td>0.702564</td>
      <td>0.717622</td>
      <td>0.704599</td>
      <td>0.009908</td>
      <td>437</td>
      <td>0.705248</td>
      <td>0.710071</td>
      <td>0.729078</td>
      <td>0.714799</td>
      <td>0.010287</td>
      <td>448</td>
    </tr>
    <tr>
      <th>281</th>
      <td>2.026504</td>
      <td>0.029429</td>
      <td>0.457700</td>
      <td>0.007754</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.694636</td>
      <td>0.696011</td>
      <td>0.721939</td>
      <td>0.704196</td>
      <td>0.012559</td>
      <td>438</td>
      <td>0.705390</td>
      <td>0.702128</td>
      <td>0.735035</td>
      <td>0.714184</td>
      <td>0.014804</td>
      <td>451</td>
    </tr>
    <tr>
      <th>579</th>
      <td>0.717334</td>
      <td>0.011899</td>
      <td>0.196001</td>
      <td>0.005717</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.691914</td>
      <td>0.709919</td>
      <td>0.710092</td>
      <td>0.703975</td>
      <td>0.008528</td>
      <td>439</td>
      <td>0.704255</td>
      <td>0.721277</td>
      <td>0.721986</td>
      <td>0.715839</td>
      <td>0.008196</td>
      <td>446</td>
    </tr>
    <tr>
      <th>336</th>
      <td>0.619681</td>
      <td>0.044083</td>
      <td>0.236314</td>
      <td>0.056240</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.693918</td>
      <td>0.709209</td>
      <td>0.708621</td>
      <td>0.703916</td>
      <td>0.007074</td>
      <td>440</td>
      <td>0.709078</td>
      <td>0.723121</td>
      <td>0.723404</td>
      <td>0.718534</td>
      <td>0.006688</td>
      <td>441</td>
    </tr>
    <tr>
      <th>580</th>
      <td>1.399664</td>
      <td>0.066215</td>
      <td>0.329669</td>
      <td>0.042991</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.687785</td>
      <td>0.710831</td>
      <td>0.710225</td>
      <td>0.702947</td>
      <td>0.010724</td>
      <td>441</td>
      <td>0.698582</td>
      <td>0.720709</td>
      <td>0.720709</td>
      <td>0.713333</td>
      <td>0.010431</td>
      <td>452</td>
    </tr>
    <tr>
      <th>581</th>
      <td>1.968669</td>
      <td>0.021202</td>
      <td>0.451331</td>
      <td>0.025103</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.687936</td>
      <td>0.711861</td>
      <td>0.708414</td>
      <td>0.702737</td>
      <td>0.010560</td>
      <td>442</td>
      <td>0.697872</td>
      <td>0.721418</td>
      <td>0.718298</td>
      <td>0.712530</td>
      <td>0.010442</td>
      <td>455</td>
    </tr>
    <tr>
      <th>333</th>
      <td>0.708656</td>
      <td>0.018204</td>
      <td>0.229358</td>
      <td>0.016781</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.689857</td>
      <td>0.708491</td>
      <td>0.709830</td>
      <td>0.702726</td>
      <td>0.009116</td>
      <td>443</td>
      <td>0.701844</td>
      <td>0.719149</td>
      <td>0.721702</td>
      <td>0.714232</td>
      <td>0.008821</td>
      <td>450</td>
    </tr>
    <tr>
      <th>149</th>
      <td>1.869335</td>
      <td>0.044961</td>
      <td>0.411666</td>
      <td>0.039105</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.687806</td>
      <td>0.711861</td>
      <td>0.708414</td>
      <td>0.702693</td>
      <td>0.010621</td>
      <td>444</td>
      <td>0.697730</td>
      <td>0.721418</td>
      <td>0.718298</td>
      <td>0.712482</td>
      <td>0.010509</td>
      <td>456</td>
    </tr>
    <tr>
      <th>147</th>
      <td>0.768998</td>
      <td>0.093382</td>
      <td>0.247666</td>
      <td>0.055571</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.690951</td>
      <td>0.708907</td>
      <td>0.707969</td>
      <td>0.702609</td>
      <td>0.008252</td>
      <td>445</td>
      <td>0.703121</td>
      <td>0.720142</td>
      <td>0.719716</td>
      <td>0.714326</td>
      <td>0.007926</td>
      <td>449</td>
    </tr>
    <tr>
      <th>148</th>
      <td>1.361331</td>
      <td>0.044577</td>
      <td>0.330667</td>
      <td>0.024281</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.687300</td>
      <td>0.710569</td>
      <td>0.709635</td>
      <td>0.702501</td>
      <td>0.010756</td>
      <td>446</td>
      <td>0.698014</td>
      <td>0.720426</td>
      <td>0.720000</td>
      <td>0.712813</td>
      <td>0.010466</td>
      <td>454</td>
    </tr>
    <tr>
      <th>365</th>
      <td>1.825696</td>
      <td>0.053887</td>
      <td>0.419460</td>
      <td>0.017065</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.687545</td>
      <td>0.711861</td>
      <td>0.708021</td>
      <td>0.702476</td>
      <td>0.010673</td>
      <td>447</td>
      <td>0.697447</td>
      <td>0.721418</td>
      <td>0.717872</td>
      <td>0.712246</td>
      <td>0.010564</td>
      <td>457</td>
    </tr>
    <tr>
      <th>334</th>
      <td>1.612745</td>
      <td>0.023571</td>
      <td>0.317131</td>
      <td>0.016898</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.688198</td>
      <td>0.703933</td>
      <td>0.715125</td>
      <td>0.702419</td>
      <td>0.011045</td>
      <td>448</td>
      <td>0.699716</td>
      <td>0.712340</td>
      <td>0.727376</td>
      <td>0.713144</td>
      <td>0.011306</td>
      <td>453</td>
    </tr>
    <tr>
      <th>641</th>
      <td>2.327332</td>
      <td>0.102418</td>
      <td>0.403157</td>
      <td>0.008226</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.680475</td>
      <td>0.711519</td>
      <td>0.709525</td>
      <td>0.700507</td>
      <td>0.014188</td>
      <td>449</td>
      <td>0.688511</td>
      <td>0.720851</td>
      <td>0.719433</td>
      <td>0.709598</td>
      <td>0.014922</td>
      <td>460</td>
    </tr>
    <tr>
      <th>364</th>
      <td>1.259123</td>
      <td>0.019126</td>
      <td>0.326459</td>
      <td>0.016378</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.683986</td>
      <td>0.709126</td>
      <td>0.707834</td>
      <td>0.700315</td>
      <td>0.011559</td>
      <td>450</td>
      <td>0.694468</td>
      <td>0.718865</td>
      <td>0.718014</td>
      <td>0.710449</td>
      <td>0.011306</td>
      <td>459</td>
    </tr>
    <tr>
      <th>209</th>
      <td>2.181668</td>
      <td>0.030946</td>
      <td>0.399664</td>
      <td>0.014655</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.680416</td>
      <td>0.711256</td>
      <td>0.709032</td>
      <td>0.700235</td>
      <td>0.014043</td>
      <td>451</td>
      <td>0.688511</td>
      <td>0.720567</td>
      <td>0.718865</td>
      <td>0.709314</td>
      <td>0.014727</td>
      <td>461</td>
    </tr>
    <tr>
      <th>360</th>
      <td>0.625333</td>
      <td>0.011618</td>
      <td>0.220668</td>
      <td>0.035346</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.686896</td>
      <td>0.706364</td>
      <td>0.707347</td>
      <td>0.700202</td>
      <td>0.009418</td>
      <td>452</td>
      <td>0.697872</td>
      <td>0.716596</td>
      <td>0.718014</td>
      <td>0.710827</td>
      <td>0.009179</td>
      <td>458</td>
    </tr>
    <tr>
      <th>640</th>
      <td>1.484334</td>
      <td>0.019939</td>
      <td>0.373670</td>
      <td>0.011323</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.679160</td>
      <td>0.708101</td>
      <td>0.707933</td>
      <td>0.698398</td>
      <td>0.013603</td>
      <td>453</td>
      <td>0.687801</td>
      <td>0.717589</td>
      <td>0.718156</td>
      <td>0.707849</td>
      <td>0.014177</td>
      <td>462</td>
    </tr>
    <tr>
      <th>425</th>
      <td>2.131126</td>
      <td>0.093817</td>
      <td>0.416933</td>
      <td>0.041347</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.678324</td>
      <td>0.710033</td>
      <td>0.706766</td>
      <td>0.698375</td>
      <td>0.014240</td>
      <td>454</td>
      <td>0.685957</td>
      <td>0.719149</td>
      <td>0.716312</td>
      <td>0.707139</td>
      <td>0.015023</td>
      <td>464</td>
    </tr>
    <tr>
      <th>208</th>
      <td>1.447001</td>
      <td>0.015578</td>
      <td>0.343332</td>
      <td>0.024906</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.678308</td>
      <td>0.707839</td>
      <td>0.707639</td>
      <td>0.697929</td>
      <td>0.013874</td>
      <td>455</td>
      <td>0.686809</td>
      <td>0.717305</td>
      <td>0.717872</td>
      <td>0.707329</td>
      <td>0.014512</td>
      <td>463</td>
    </tr>
    <tr>
      <th>424</th>
      <td>1.502333</td>
      <td>0.044064</td>
      <td>0.315769</td>
      <td>0.005437</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.677576</td>
      <td>0.706256</td>
      <td>0.705311</td>
      <td>0.696381</td>
      <td>0.013303</td>
      <td>456</td>
      <td>0.685816</td>
      <td>0.715461</td>
      <td>0.715177</td>
      <td>0.705485</td>
      <td>0.013909</td>
      <td>466</td>
    </tr>
    <tr>
      <th>363</th>
      <td>0.575443</td>
      <td>0.030629</td>
      <td>0.183209</td>
      <td>0.010481</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.682616</td>
      <td>0.703000</td>
      <td>0.703288</td>
      <td>0.696301</td>
      <td>0.009678</td>
      <td>457</td>
      <td>0.693759</td>
      <td>0.713475</td>
      <td>0.714184</td>
      <td>0.707139</td>
      <td>0.009466</td>
      <td>464</td>
    </tr>
    <tr>
      <th>428</th>
      <td>1.987314</td>
      <td>0.044180</td>
      <td>0.384912</td>
      <td>0.010362</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.671853</td>
      <td>0.709417</td>
      <td>0.705162</td>
      <td>0.695478</td>
      <td>0.016795</td>
      <td>458</td>
      <td>0.678014</td>
      <td>0.718582</td>
      <td>0.714610</td>
      <td>0.703735</td>
      <td>0.018260</td>
      <td>467</td>
    </tr>
    <tr>
      <th>212</th>
      <td>1.941005</td>
      <td>0.009201</td>
      <td>0.449328</td>
      <td>0.017308</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.671536</td>
      <td>0.709508</td>
      <td>0.705293</td>
      <td>0.695446</td>
      <td>0.016994</td>
      <td>459</td>
      <td>0.677589</td>
      <td>0.718582</td>
      <td>0.714752</td>
      <td>0.703641</td>
      <td>0.018488</td>
      <td>468</td>
    </tr>
    <tr>
      <th>644</th>
      <td>2.008889</td>
      <td>0.027596</td>
      <td>0.457406</td>
      <td>0.047061</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.671273</td>
      <td>0.709508</td>
      <td>0.705162</td>
      <td>0.695314</td>
      <td>0.017092</td>
      <td>460</td>
      <td>0.677305</td>
      <td>0.718582</td>
      <td>0.714610</td>
      <td>0.703499</td>
      <td>0.018593</td>
      <td>469</td>
    </tr>
    <tr>
      <th>263</th>
      <td>2.000494</td>
      <td>0.040109</td>
      <td>0.396579</td>
      <td>0.003305</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.670855</td>
      <td>0.708839</td>
      <td>0.703541</td>
      <td>0.694412</td>
      <td>0.016797</td>
      <td>461</td>
      <td>0.677163</td>
      <td>0.717730</td>
      <td>0.712624</td>
      <td>0.702506</td>
      <td>0.018041</td>
      <td>472</td>
    </tr>
    <tr>
      <th>479</th>
      <td>1.958514</td>
      <td>0.021676</td>
      <td>0.475438</td>
      <td>0.062928</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.670881</td>
      <td>0.708546</td>
      <td>0.703541</td>
      <td>0.694323</td>
      <td>0.016701</td>
      <td>462</td>
      <td>0.677163</td>
      <td>0.717447</td>
      <td>0.712624</td>
      <td>0.702411</td>
      <td>0.017961</td>
      <td>474</td>
    </tr>
    <tr>
      <th>211</th>
      <td>1.259001</td>
      <td>0.017207</td>
      <td>0.324331</td>
      <td>0.028285</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.671063</td>
      <td>0.706589</td>
      <td>0.705300</td>
      <td>0.694317</td>
      <td>0.016452</td>
      <td>463</td>
      <td>0.677589</td>
      <td>0.715887</td>
      <td>0.714894</td>
      <td>0.702790</td>
      <td>0.017824</td>
      <td>470</td>
    </tr>
    <tr>
      <th>643</th>
      <td>1.411241</td>
      <td>0.094229</td>
      <td>0.382414</td>
      <td>0.007263</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.671248</td>
      <td>0.706457</td>
      <td>0.705138</td>
      <td>0.694281</td>
      <td>0.016296</td>
      <td>464</td>
      <td>0.677730</td>
      <td>0.715745</td>
      <td>0.714752</td>
      <td>0.702742</td>
      <td>0.017691</td>
      <td>471</td>
    </tr>
    <tr>
      <th>47</th>
      <td>2.817886</td>
      <td>0.326474</td>
      <td>0.619572</td>
      <td>0.105010</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.670723</td>
      <td>0.708546</td>
      <td>0.703541</td>
      <td>0.694270</td>
      <td>0.016775</td>
      <td>465</td>
      <td>0.677021</td>
      <td>0.717447</td>
      <td>0.712624</td>
      <td>0.702364</td>
      <td>0.018028</td>
      <td>475</td>
    </tr>
    <tr>
      <th>427</th>
      <td>1.317247</td>
      <td>0.055740</td>
      <td>0.331942</td>
      <td>0.028665</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.670982</td>
      <td>0.705478</td>
      <td>0.705400</td>
      <td>0.693953</td>
      <td>0.016243</td>
      <td>466</td>
      <td>0.677589</td>
      <td>0.714752</td>
      <td>0.715035</td>
      <td>0.702459</td>
      <td>0.017586</td>
      <td>473</td>
    </tr>
    <tr>
      <th>478</th>
      <td>1.298674</td>
      <td>0.027722</td>
      <td>0.353896</td>
      <td>0.042953</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.670426</td>
      <td>0.704510</td>
      <td>0.703042</td>
      <td>0.692659</td>
      <td>0.015733</td>
      <td>467</td>
      <td>0.677163</td>
      <td>0.713475</td>
      <td>0.712482</td>
      <td>0.701040</td>
      <td>0.016889</td>
      <td>477</td>
    </tr>
    <tr>
      <th>262</th>
      <td>1.292003</td>
      <td>0.063267</td>
      <td>0.335929</td>
      <td>0.017562</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.670163</td>
      <td>0.704379</td>
      <td>0.703335</td>
      <td>0.692626</td>
      <td>0.015889</td>
      <td>468</td>
      <td>0.676879</td>
      <td>0.713333</td>
      <td>0.712766</td>
      <td>0.700993</td>
      <td>0.017052</td>
      <td>478</td>
    </tr>
    <tr>
      <th>46</th>
      <td>1.329333</td>
      <td>0.015963</td>
      <td>0.356846</td>
      <td>0.001830</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.670295</td>
      <td>0.704248</td>
      <td>0.703204</td>
      <td>0.692582</td>
      <td>0.015765</td>
      <td>469</td>
      <td>0.677021</td>
      <td>0.713191</td>
      <td>0.712624</td>
      <td>0.700946</td>
      <td>0.016919</td>
      <td>479</td>
    </tr>
    <tr>
      <th>107</th>
      <td>1.959999</td>
      <td>0.011312</td>
      <td>0.425665</td>
      <td>0.004110</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.665773</td>
      <td>0.707728</td>
      <td>0.702946</td>
      <td>0.692149</td>
      <td>0.018753</td>
      <td>470</td>
      <td>0.671064</td>
      <td>0.716596</td>
      <td>0.711915</td>
      <td>0.699858</td>
      <td>0.020450</td>
      <td>483</td>
    </tr>
    <tr>
      <th>323</th>
      <td>1.907004</td>
      <td>0.039255</td>
      <td>0.419326</td>
      <td>0.022666</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.665773</td>
      <td>0.707728</td>
      <td>0.702946</td>
      <td>0.692149</td>
      <td>0.018753</td>
      <td>470</td>
      <td>0.671064</td>
      <td>0.716596</td>
      <td>0.711915</td>
      <td>0.699858</td>
      <td>0.020450</td>
      <td>483</td>
    </tr>
    <tr>
      <th>539</th>
      <td>1.833337</td>
      <td>0.026959</td>
      <td>0.496663</td>
      <td>0.009740</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.665773</td>
      <td>0.707728</td>
      <td>0.702946</td>
      <td>0.692149</td>
      <td>0.018753</td>
      <td>470</td>
      <td>0.671064</td>
      <td>0.716596</td>
      <td>0.711915</td>
      <td>0.699858</td>
      <td>0.020450</td>
      <td>483</td>
    </tr>
    <tr>
      <th>266</th>
      <td>1.902322</td>
      <td>0.031473</td>
      <td>0.390949</td>
      <td>0.018480</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.665161</td>
      <td>0.707991</td>
      <td>0.702946</td>
      <td>0.692033</td>
      <td>0.019112</td>
      <td>473</td>
      <td>0.670355</td>
      <td>0.716879</td>
      <td>0.711915</td>
      <td>0.699716</td>
      <td>0.020861</td>
      <td>486</td>
    </tr>
    <tr>
      <th>50</th>
      <td>1.939616</td>
      <td>0.060678</td>
      <td>0.429001</td>
      <td>0.012754</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.665304</td>
      <td>0.707860</td>
      <td>0.702714</td>
      <td>0.691959</td>
      <td>0.018965</td>
      <td>474</td>
      <td>0.670355</td>
      <td>0.716738</td>
      <td>0.711631</td>
      <td>0.699574</td>
      <td>0.020766</td>
      <td>487</td>
    </tr>
    <tr>
      <th>482</th>
      <td>1.903430</td>
      <td>0.032370</td>
      <td>0.474066</td>
      <td>0.020592</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.665304</td>
      <td>0.707860</td>
      <td>0.702714</td>
      <td>0.691959</td>
      <td>0.018965</td>
      <td>474</td>
      <td>0.670355</td>
      <td>0.716738</td>
      <td>0.711631</td>
      <td>0.699574</td>
      <td>0.020766</td>
      <td>487</td>
    </tr>
    <tr>
      <th>639</th>
      <td>0.790070</td>
      <td>0.007021</td>
      <td>0.195002</td>
      <td>0.011575</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.676555</td>
      <td>0.699955</td>
      <td>0.697777</td>
      <td>0.691429</td>
      <td>0.010555</td>
      <td>476</td>
      <td>0.685957</td>
      <td>0.709645</td>
      <td>0.707801</td>
      <td>0.701135</td>
      <td>0.010758</td>
      <td>476</td>
    </tr>
    <tr>
      <th>207</th>
      <td>0.773670</td>
      <td>0.017988</td>
      <td>0.208331</td>
      <td>0.022006</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.676717</td>
      <td>0.699301</td>
      <td>0.697646</td>
      <td>0.691221</td>
      <td>0.010278</td>
      <td>477</td>
      <td>0.686099</td>
      <td>0.708936</td>
      <td>0.707660</td>
      <td>0.700898</td>
      <td>0.010477</td>
      <td>480</td>
    </tr>
    <tr>
      <th>615</th>
      <td>0.843029</td>
      <td>0.158222</td>
      <td>0.207817</td>
      <td>0.013813</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.662682</td>
      <td>0.705099</td>
      <td>0.704411</td>
      <td>0.690731</td>
      <td>0.019836</td>
      <td>478</td>
      <td>0.668936</td>
      <td>0.716596</td>
      <td>0.716454</td>
      <td>0.700662</td>
      <td>0.022434</td>
      <td>481</td>
    </tr>
    <tr>
      <th>320</th>
      <td>1.919641</td>
      <td>0.043575</td>
      <td>0.402998</td>
      <td>0.028331</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.661959</td>
      <td>0.706355</td>
      <td>0.702500</td>
      <td>0.690271</td>
      <td>0.020082</td>
      <td>479</td>
      <td>0.666667</td>
      <td>0.715177</td>
      <td>0.711206</td>
      <td>0.697683</td>
      <td>0.021992</td>
      <td>493</td>
    </tr>
    <tr>
      <th>104</th>
      <td>1.963354</td>
      <td>0.062075</td>
      <td>0.384336</td>
      <td>0.011327</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.661562</td>
      <td>0.706355</td>
      <td>0.702500</td>
      <td>0.690139</td>
      <td>0.020268</td>
      <td>480</td>
      <td>0.666241</td>
      <td>0.715177</td>
      <td>0.711206</td>
      <td>0.697541</td>
      <td>0.022192</td>
      <td>494</td>
    </tr>
    <tr>
      <th>536</th>
      <td>1.797377</td>
      <td>0.010222</td>
      <td>0.475561</td>
      <td>0.007153</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.661562</td>
      <td>0.706355</td>
      <td>0.702500</td>
      <td>0.690139</td>
      <td>0.020268</td>
      <td>480</td>
      <td>0.666241</td>
      <td>0.715177</td>
      <td>0.711206</td>
      <td>0.697541</td>
      <td>0.022192</td>
      <td>494</td>
    </tr>
    <tr>
      <th>183</th>
      <td>0.569998</td>
      <td>0.015516</td>
      <td>0.215998</td>
      <td>0.023147</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.661000</td>
      <td>0.705099</td>
      <td>0.704291</td>
      <td>0.690130</td>
      <td>0.020601</td>
      <td>482</td>
      <td>0.666950</td>
      <td>0.716596</td>
      <td>0.716170</td>
      <td>0.699905</td>
      <td>0.023303</td>
      <td>482</td>
    </tr>
    <tr>
      <th>593</th>
      <td>1.897445</td>
      <td>0.044711</td>
      <td>0.411017</td>
      <td>0.006365</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.661429</td>
      <td>0.706355</td>
      <td>0.702500</td>
      <td>0.690095</td>
      <td>0.020331</td>
      <td>483</td>
      <td>0.666099</td>
      <td>0.715177</td>
      <td>0.711206</td>
      <td>0.697494</td>
      <td>0.022259</td>
      <td>496</td>
    </tr>
    <tr>
      <th>161</th>
      <td>1.933171</td>
      <td>0.065651</td>
      <td>0.469737</td>
      <td>0.034823</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.661429</td>
      <td>0.706355</td>
      <td>0.702500</td>
      <td>0.690095</td>
      <td>0.020331</td>
      <td>483</td>
      <td>0.666099</td>
      <td>0.715177</td>
      <td>0.711206</td>
      <td>0.697494</td>
      <td>0.022259</td>
      <td>496</td>
    </tr>
    <tr>
      <th>377</th>
      <td>1.897002</td>
      <td>0.089072</td>
      <td>0.401997</td>
      <td>0.016389</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.661429</td>
      <td>0.706355</td>
      <td>0.702500</td>
      <td>0.690095</td>
      <td>0.020331</td>
      <td>483</td>
      <td>0.666099</td>
      <td>0.715177</td>
      <td>0.711206</td>
      <td>0.697494</td>
      <td>0.022259</td>
      <td>496</td>
    </tr>
    <tr>
      <th>590</th>
      <td>1.935392</td>
      <td>0.051428</td>
      <td>0.402524</td>
      <td>0.014432</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.661164</td>
      <td>0.706516</td>
      <td>0.702369</td>
      <td>0.690016</td>
      <td>0.020472</td>
      <td>486</td>
      <td>0.665816</td>
      <td>0.715319</td>
      <td>0.711064</td>
      <td>0.697400</td>
      <td>0.022401</td>
      <td>499</td>
    </tr>
    <tr>
      <th>374</th>
      <td>1.876668</td>
      <td>0.006013</td>
      <td>0.443667</td>
      <td>0.018080</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.661164</td>
      <td>0.706516</td>
      <td>0.702369</td>
      <td>0.690016</td>
      <td>0.020472</td>
      <td>486</td>
      <td>0.665816</td>
      <td>0.715319</td>
      <td>0.711064</td>
      <td>0.697400</td>
      <td>0.022401</td>
      <td>499</td>
    </tr>
    <tr>
      <th>371</th>
      <td>1.872000</td>
      <td>0.001625</td>
      <td>0.433329</td>
      <td>0.036057</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.661164</td>
      <td>0.706516</td>
      <td>0.702369</td>
      <td>0.690016</td>
      <td>0.020472</td>
      <td>486</td>
      <td>0.665816</td>
      <td>0.715319</td>
      <td>0.711064</td>
      <td>0.697400</td>
      <td>0.022401</td>
      <td>499</td>
    </tr>
    <tr>
      <th>533</th>
      <td>1.897806</td>
      <td>0.021479</td>
      <td>0.474781</td>
      <td>0.069333</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.661164</td>
      <td>0.706516</td>
      <td>0.702369</td>
      <td>0.690016</td>
      <td>0.020472</td>
      <td>486</td>
      <td>0.665816</td>
      <td>0.715319</td>
      <td>0.711064</td>
      <td>0.697400</td>
      <td>0.022401</td>
      <td>499</td>
    </tr>
    <tr>
      <th>101</th>
      <td>1.884019</td>
      <td>0.079896</td>
      <td>0.421018</td>
      <td>0.034111</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.661164</td>
      <td>0.706516</td>
      <td>0.702369</td>
      <td>0.690016</td>
      <td>0.020472</td>
      <td>486</td>
      <td>0.665816</td>
      <td>0.715319</td>
      <td>0.711064</td>
      <td>0.697400</td>
      <td>0.022401</td>
      <td>499</td>
    </tr>
    <tr>
      <th>155</th>
      <td>1.828669</td>
      <td>0.010338</td>
      <td>0.440329</td>
      <td>0.028547</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.661164</td>
      <td>0.706516</td>
      <td>0.702369</td>
      <td>0.690016</td>
      <td>0.020472</td>
      <td>486</td>
      <td>0.665816</td>
      <td>0.715319</td>
      <td>0.711064</td>
      <td>0.697400</td>
      <td>0.022401</td>
      <td>499</td>
    </tr>
    <tr>
      <th>587</th>
      <td>1.854289</td>
      <td>0.051447</td>
      <td>0.425371</td>
      <td>0.025851</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.661164</td>
      <td>0.706516</td>
      <td>0.702369</td>
      <td>0.690016</td>
      <td>0.020472</td>
      <td>486</td>
      <td>0.665816</td>
      <td>0.715319</td>
      <td>0.711064</td>
      <td>0.697400</td>
      <td>0.022401</td>
      <td>499</td>
    </tr>
    <tr>
      <th>317</th>
      <td>1.923160</td>
      <td>0.010460</td>
      <td>0.387380</td>
      <td>0.014151</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.661164</td>
      <td>0.706516</td>
      <td>0.702369</td>
      <td>0.690016</td>
      <td>0.020472</td>
      <td>486</td>
      <td>0.665816</td>
      <td>0.715319</td>
      <td>0.711064</td>
      <td>0.697400</td>
      <td>0.022401</td>
      <td>499</td>
    </tr>
    <tr>
      <th>158</th>
      <td>1.928846</td>
      <td>0.064033</td>
      <td>0.418283</td>
      <td>0.029486</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.661164</td>
      <td>0.706516</td>
      <td>0.702369</td>
      <td>0.690016</td>
      <td>0.020472</td>
      <td>486</td>
      <td>0.665816</td>
      <td>0.715319</td>
      <td>0.711064</td>
      <td>0.697400</td>
      <td>0.022401</td>
      <td>499</td>
    </tr>
    <tr>
      <th>642</th>
      <td>0.570665</td>
      <td>0.042908</td>
      <td>0.186004</td>
      <td>0.000815</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.670942</td>
      <td>0.698683</td>
      <td>0.699278</td>
      <td>0.689634</td>
      <td>0.013220</td>
      <td>495</td>
      <td>0.678865</td>
      <td>0.708369</td>
      <td>0.709362</td>
      <td>0.698865</td>
      <td>0.014148</td>
      <td>489</td>
    </tr>
    <tr>
      <th>210</th>
      <td>0.537333</td>
      <td>0.018195</td>
      <td>0.200669</td>
      <td>0.009431</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.671072</td>
      <td>0.698390</td>
      <td>0.698886</td>
      <td>0.689449</td>
      <td>0.012996</td>
      <td>496</td>
      <td>0.679007</td>
      <td>0.708085</td>
      <td>0.708936</td>
      <td>0.698676</td>
      <td>0.013912</td>
      <td>490</td>
    </tr>
    <tr>
      <th>612</th>
      <td>0.791719</td>
      <td>0.064552</td>
      <td>0.251420</td>
      <td>0.015625</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.670459</td>
      <td>0.697742</td>
      <td>0.700127</td>
      <td>0.689443</td>
      <td>0.013459</td>
      <td>497</td>
      <td>0.677589</td>
      <td>0.706809</td>
      <td>0.710496</td>
      <td>0.698298</td>
      <td>0.014721</td>
      <td>491</td>
    </tr>
    <tr>
      <th>538</th>
      <td>1.238333</td>
      <td>0.044005</td>
      <td>0.363332</td>
      <td>0.044950</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.663071</td>
      <td>0.703854</td>
      <td>0.701100</td>
      <td>0.689342</td>
      <td>0.018610</td>
      <td>498</td>
      <td>0.668369</td>
      <td>0.712766</td>
      <td>0.710213</td>
      <td>0.697116</td>
      <td>0.020354</td>
      <td>508</td>
    </tr>
    <tr>
      <th>106</th>
      <td>1.246381</td>
      <td>0.006518</td>
      <td>0.330999</td>
      <td>0.018386</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.663071</td>
      <td>0.703854</td>
      <td>0.701100</td>
      <td>0.689342</td>
      <td>0.018610</td>
      <td>498</td>
      <td>0.668369</td>
      <td>0.712766</td>
      <td>0.710213</td>
      <td>0.697116</td>
      <td>0.020354</td>
      <td>508</td>
    </tr>
    <tr>
      <th>265</th>
      <td>1.235133</td>
      <td>0.011033</td>
      <td>0.325750</td>
      <td>0.011668</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.662856</td>
      <td>0.704015</td>
      <td>0.700938</td>
      <td>0.689270</td>
      <td>0.018720</td>
      <td>500</td>
      <td>0.668085</td>
      <td>0.712908</td>
      <td>0.710071</td>
      <td>0.697021</td>
      <td>0.020494</td>
      <td>511</td>
    </tr>
    <tr>
      <th>322</th>
      <td>1.252331</td>
      <td>0.020949</td>
      <td>0.316666</td>
      <td>0.006944</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.662759</td>
      <td>0.703854</td>
      <td>0.701100</td>
      <td>0.689237</td>
      <td>0.018757</td>
      <td>501</td>
      <td>0.668085</td>
      <td>0.712766</td>
      <td>0.710213</td>
      <td>0.697021</td>
      <td>0.020487</td>
      <td>512</td>
    </tr>
    <tr>
      <th>49</th>
      <td>1.269677</td>
      <td>0.025009</td>
      <td>0.343334</td>
      <td>0.025039</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.662712</td>
      <td>0.703884</td>
      <td>0.700938</td>
      <td>0.689178</td>
      <td>0.018753</td>
      <td>502</td>
      <td>0.667801</td>
      <td>0.712766</td>
      <td>0.710071</td>
      <td>0.696879</td>
      <td>0.020591</td>
      <td>513</td>
    </tr>
    <tr>
      <th>481</th>
      <td>1.286744</td>
      <td>0.030027</td>
      <td>0.340159</td>
      <td>0.040089</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.662580</td>
      <td>0.703884</td>
      <td>0.700938</td>
      <td>0.689134</td>
      <td>0.018815</td>
      <td>503</td>
      <td>0.667660</td>
      <td>0.712766</td>
      <td>0.710071</td>
      <td>0.696832</td>
      <td>0.020657</td>
      <td>514</td>
    </tr>
    <tr>
      <th>426</th>
      <td>0.542011</td>
      <td>0.028300</td>
      <td>0.275348</td>
      <td>0.030293</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.670651</td>
      <td>0.698029</td>
      <td>0.698004</td>
      <td>0.688895</td>
      <td>0.012900</td>
      <td>504</td>
      <td>0.678582</td>
      <td>0.707660</td>
      <td>0.707943</td>
      <td>0.698061</td>
      <td>0.013775</td>
      <td>492</td>
    </tr>
    <tr>
      <th>180</th>
      <td>0.777997</td>
      <td>0.036175</td>
      <td>0.243003</td>
      <td>0.014514</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.667109</td>
      <td>0.697663</td>
      <td>0.699083</td>
      <td>0.687951</td>
      <td>0.014749</td>
      <td>505</td>
      <td>0.673901</td>
      <td>0.706525</td>
      <td>0.709362</td>
      <td>0.696596</td>
      <td>0.016090</td>
      <td>515</td>
    </tr>
    <tr>
      <th>423</th>
      <td>0.652332</td>
      <td>0.015153</td>
      <td>0.240668</td>
      <td>0.029169</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.672522</td>
      <td>0.696487</td>
      <td>0.694318</td>
      <td>0.687776</td>
      <td>0.010822</td>
      <td>506</td>
      <td>0.681418</td>
      <td>0.705816</td>
      <td>0.704113</td>
      <td>0.697116</td>
      <td>0.011121</td>
      <td>508</td>
    </tr>
    <tr>
      <th>103</th>
      <td>1.216060</td>
      <td>0.012754</td>
      <td>0.305001</td>
      <td>0.008285</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.659617</td>
      <td>0.702923</td>
      <td>0.700566</td>
      <td>0.687702</td>
      <td>0.019883</td>
      <td>507</td>
      <td>0.664255</td>
      <td>0.711631</td>
      <td>0.709504</td>
      <td>0.695130</td>
      <td>0.021849</td>
      <td>516</td>
    </tr>
    <tr>
      <th>535</th>
      <td>1.226691</td>
      <td>0.009369</td>
      <td>0.403965</td>
      <td>0.020181</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.659484</td>
      <td>0.702923</td>
      <td>0.700566</td>
      <td>0.687658</td>
      <td>0.019945</td>
      <td>508</td>
      <td>0.664113</td>
      <td>0.711631</td>
      <td>0.709504</td>
      <td>0.695083</td>
      <td>0.021916</td>
      <td>517</td>
    </tr>
    <tr>
      <th>319</th>
      <td>1.270549</td>
      <td>0.026226</td>
      <td>0.301668</td>
      <td>0.011585</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.659461</td>
      <td>0.702923</td>
      <td>0.700566</td>
      <td>0.687650</td>
      <td>0.019956</td>
      <td>509</td>
      <td>0.664113</td>
      <td>0.711631</td>
      <td>0.709504</td>
      <td>0.695083</td>
      <td>0.021916</td>
      <td>517</td>
    </tr>
    <tr>
      <th>376</th>
      <td>1.249336</td>
      <td>0.031903</td>
      <td>0.359331</td>
      <td>0.029773</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.659352</td>
      <td>0.702923</td>
      <td>0.700566</td>
      <td>0.687614</td>
      <td>0.020007</td>
      <td>510</td>
      <td>0.663972</td>
      <td>0.711631</td>
      <td>0.709504</td>
      <td>0.695035</td>
      <td>0.021983</td>
      <td>519</td>
    </tr>
    <tr>
      <th>160</th>
      <td>1.221859</td>
      <td>0.001886</td>
      <td>0.333283</td>
      <td>0.061157</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.659352</td>
      <td>0.702923</td>
      <td>0.700566</td>
      <td>0.687614</td>
      <td>0.020007</td>
      <td>510</td>
      <td>0.663972</td>
      <td>0.711631</td>
      <td>0.709504</td>
      <td>0.695035</td>
      <td>0.021983</td>
      <td>519</td>
    </tr>
    <tr>
      <th>592</th>
      <td>1.250832</td>
      <td>0.015580</td>
      <td>0.327687</td>
      <td>0.025719</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.659352</td>
      <td>0.702923</td>
      <td>0.700566</td>
      <td>0.687614</td>
      <td>0.020007</td>
      <td>510</td>
      <td>0.663972</td>
      <td>0.711631</td>
      <td>0.709504</td>
      <td>0.695035</td>
      <td>0.021983</td>
      <td>519</td>
    </tr>
    <tr>
      <th>373</th>
      <td>1.240001</td>
      <td>0.028181</td>
      <td>0.337667</td>
      <td>0.017213</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.659110</td>
      <td>0.702661</td>
      <td>0.700435</td>
      <td>0.687402</td>
      <td>0.020026</td>
      <td>513</td>
      <td>0.663688</td>
      <td>0.711348</td>
      <td>0.709362</td>
      <td>0.694799</td>
      <td>0.022014</td>
      <td>522</td>
    </tr>
    <tr>
      <th>316</th>
      <td>1.196567</td>
      <td>0.024662</td>
      <td>0.307749</td>
      <td>0.002788</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.658955</td>
      <td>0.702661</td>
      <td>0.700566</td>
      <td>0.687394</td>
      <td>0.020128</td>
      <td>514</td>
      <td>0.663546</td>
      <td>0.711348</td>
      <td>0.709504</td>
      <td>0.694799</td>
      <td>0.022112</td>
      <td>522</td>
    </tr>
    <tr>
      <th>157</th>
      <td>1.239349</td>
      <td>0.013818</td>
      <td>0.375042</td>
      <td>0.068346</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.659110</td>
      <td>0.702661</td>
      <td>0.700304</td>
      <td>0.687358</td>
      <td>0.019998</td>
      <td>515</td>
      <td>0.663688</td>
      <td>0.711348</td>
      <td>0.709220</td>
      <td>0.694752</td>
      <td>0.021983</td>
      <td>524</td>
    </tr>
    <tr>
      <th>589</th>
      <td>1.250226</td>
      <td>0.022678</td>
      <td>0.302247</td>
      <td>0.002215</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.659110</td>
      <td>0.702661</td>
      <td>0.700304</td>
      <td>0.687358</td>
      <td>0.019998</td>
      <td>515</td>
      <td>0.663688</td>
      <td>0.711348</td>
      <td>0.709220</td>
      <td>0.694752</td>
      <td>0.021983</td>
      <td>524</td>
    </tr>
    <tr>
      <th>154</th>
      <td>1.259999</td>
      <td>0.035692</td>
      <td>0.323000</td>
      <td>0.027471</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.659110</td>
      <td>0.702661</td>
      <td>0.700304</td>
      <td>0.687358</td>
      <td>0.019998</td>
      <td>515</td>
      <td>0.663688</td>
      <td>0.711348</td>
      <td>0.709220</td>
      <td>0.694752</td>
      <td>0.021983</td>
      <td>524</td>
    </tr>
    <tr>
      <th>532</th>
      <td>1.269865</td>
      <td>0.018161</td>
      <td>0.320853</td>
      <td>0.027394</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.659110</td>
      <td>0.702661</td>
      <td>0.700304</td>
      <td>0.687358</td>
      <td>0.019998</td>
      <td>515</td>
      <td>0.663688</td>
      <td>0.711348</td>
      <td>0.709220</td>
      <td>0.694752</td>
      <td>0.021983</td>
      <td>524</td>
    </tr>
    <tr>
      <th>586</th>
      <td>1.225192</td>
      <td>0.030805</td>
      <td>0.344352</td>
      <td>0.023165</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.659110</td>
      <td>0.702661</td>
      <td>0.700304</td>
      <td>0.687358</td>
      <td>0.019998</td>
      <td>515</td>
      <td>0.663688</td>
      <td>0.711348</td>
      <td>0.709220</td>
      <td>0.694752</td>
      <td>0.021983</td>
      <td>524</td>
    </tr>
    <tr>
      <th>370</th>
      <td>1.263334</td>
      <td>0.005558</td>
      <td>0.336998</td>
      <td>0.035015</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.659110</td>
      <td>0.702661</td>
      <td>0.700304</td>
      <td>0.687358</td>
      <td>0.019998</td>
      <td>515</td>
      <td>0.663688</td>
      <td>0.711348</td>
      <td>0.709220</td>
      <td>0.694752</td>
      <td>0.021983</td>
      <td>524</td>
    </tr>
    <tr>
      <th>100</th>
      <td>1.311052</td>
      <td>0.012909</td>
      <td>0.382001</td>
      <td>0.026981</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.659110</td>
      <td>0.702661</td>
      <td>0.700304</td>
      <td>0.687358</td>
      <td>0.019998</td>
      <td>515</td>
      <td>0.663688</td>
      <td>0.711348</td>
      <td>0.709220</td>
      <td>0.694752</td>
      <td>0.021983</td>
      <td>524</td>
    </tr>
    <tr>
      <th>399</th>
      <td>0.591334</td>
      <td>0.026336</td>
      <td>0.255668</td>
      <td>0.041343</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.649057</td>
      <td>0.702792</td>
      <td>0.702928</td>
      <td>0.684926</td>
      <td>0.025363</td>
      <td>522</td>
      <td>0.653475</td>
      <td>0.713901</td>
      <td>0.714610</td>
      <td>0.693995</td>
      <td>0.028653</td>
      <td>531</td>
    </tr>
    <tr>
      <th>477</th>
      <td>0.625210</td>
      <td>0.027016</td>
      <td>0.203944</td>
      <td>0.008415</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.665473</td>
      <td>0.694879</td>
      <td>0.691177</td>
      <td>0.683843</td>
      <td>0.013077</td>
      <td>523</td>
      <td>0.673050</td>
      <td>0.703972</td>
      <td>0.700426</td>
      <td>0.692482</td>
      <td>0.013817</td>
      <td>532</td>
    </tr>
    <tr>
      <th>45</th>
      <td>0.593333</td>
      <td>0.006942</td>
      <td>0.205667</td>
      <td>0.016419</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.665473</td>
      <td>0.694718</td>
      <td>0.690754</td>
      <td>0.683648</td>
      <td>0.012953</td>
      <td>524</td>
      <td>0.673050</td>
      <td>0.703830</td>
      <td>0.700000</td>
      <td>0.692293</td>
      <td>0.013697</td>
      <td>533</td>
    </tr>
    <tr>
      <th>261</th>
      <td>0.606666</td>
      <td>0.066243</td>
      <td>0.226667</td>
      <td>0.016777</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.664849</td>
      <td>0.694456</td>
      <td>0.691047</td>
      <td>0.683451</td>
      <td>0.013227</td>
      <td>525</td>
      <td>0.672340</td>
      <td>0.703546</td>
      <td>0.700284</td>
      <td>0.692057</td>
      <td>0.014005</td>
      <td>534</td>
    </tr>
    <tr>
      <th>321</th>
      <td>0.548722</td>
      <td>0.038692</td>
      <td>0.189334</td>
      <td>0.005557</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.660578</td>
      <td>0.695857</td>
      <td>0.692932</td>
      <td>0.683122</td>
      <td>0.015986</td>
      <td>526</td>
      <td>0.666950</td>
      <td>0.704965</td>
      <td>0.702128</td>
      <td>0.691348</td>
      <td>0.017290</td>
      <td>535</td>
    </tr>
    <tr>
      <th>537</th>
      <td>0.470032</td>
      <td>0.009173</td>
      <td>0.194593</td>
      <td>0.015519</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.660316</td>
      <td>0.696018</td>
      <td>0.692770</td>
      <td>0.683035</td>
      <td>0.016120</td>
      <td>527</td>
      <td>0.666667</td>
      <td>0.705106</td>
      <td>0.701986</td>
      <td>0.691253</td>
      <td>0.017432</td>
      <td>536</td>
    </tr>
    <tr>
      <th>105</th>
      <td>0.530661</td>
      <td>0.015839</td>
      <td>0.217672</td>
      <td>0.015281</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.660316</td>
      <td>0.696018</td>
      <td>0.692770</td>
      <td>0.683035</td>
      <td>0.016120</td>
      <td>527</td>
      <td>0.666667</td>
      <td>0.705106</td>
      <td>0.701986</td>
      <td>0.691253</td>
      <td>0.017432</td>
      <td>536</td>
    </tr>
    <tr>
      <th>379</th>
      <td>1.234332</td>
      <td>0.015322</td>
      <td>0.311001</td>
      <td>0.011312</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.681566</td>
      <td>0.683207</td>
      <td>0.684077</td>
      <td>0.682950</td>
      <td>0.001041</td>
      <td>529</td>
      <td>0.689220</td>
      <td>0.687943</td>
      <td>0.689645</td>
      <td>0.688936</td>
      <td>0.000723</td>
      <td>541</td>
    </tr>
    <tr>
      <th>271</th>
      <td>1.272334</td>
      <td>0.031626</td>
      <td>0.339664</td>
      <td>0.010401</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.681566</td>
      <td>0.683207</td>
      <td>0.684077</td>
      <td>0.682950</td>
      <td>0.001041</td>
      <td>529</td>
      <td>0.689220</td>
      <td>0.687943</td>
      <td>0.689645</td>
      <td>0.688936</td>
      <td>0.000723</td>
      <td>541</td>
    </tr>
    <tr>
      <th>217</th>
      <td>1.277001</td>
      <td>0.011863</td>
      <td>0.354335</td>
      <td>0.018661</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.681566</td>
      <td>0.683207</td>
      <td>0.684077</td>
      <td>0.682950</td>
      <td>0.001041</td>
      <td>529</td>
      <td>0.689220</td>
      <td>0.687943</td>
      <td>0.689645</td>
      <td>0.688936</td>
      <td>0.000723</td>
      <td>541</td>
    </tr>
    <tr>
      <th>325</th>
      <td>1.310333</td>
      <td>0.067617</td>
      <td>0.342999</td>
      <td>0.041206</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.681566</td>
      <td>0.683207</td>
      <td>0.684077</td>
      <td>0.682950</td>
      <td>0.001041</td>
      <td>529</td>
      <td>0.689220</td>
      <td>0.687943</td>
      <td>0.689645</td>
      <td>0.688936</td>
      <td>0.000723</td>
      <td>541</td>
    </tr>
    <tr>
      <th>264</th>
      <td>0.524636</td>
      <td>0.014173</td>
      <td>0.205757</td>
      <td>0.018724</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.657140</td>
      <td>0.694941</td>
      <td>0.694108</td>
      <td>0.682063</td>
      <td>0.017627</td>
      <td>533</td>
      <td>0.662979</td>
      <td>0.703972</td>
      <td>0.703404</td>
      <td>0.690118</td>
      <td>0.019192</td>
      <td>538</td>
    </tr>
    <tr>
      <th>480</th>
      <td>0.538403</td>
      <td>0.047234</td>
      <td>0.186648</td>
      <td>0.001134</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.657374</td>
      <td>0.694548</td>
      <td>0.693878</td>
      <td>0.681934</td>
      <td>0.017368</td>
      <td>534</td>
      <td>0.663121</td>
      <td>0.703546</td>
      <td>0.703121</td>
      <td>0.689929</td>
      <td>0.018957</td>
      <td>539</td>
    </tr>
    <tr>
      <th>48</th>
      <td>0.815337</td>
      <td>0.134917</td>
      <td>0.269842</td>
      <td>0.035532</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.656980</td>
      <td>0.694679</td>
      <td>0.694009</td>
      <td>0.681889</td>
      <td>0.017616</td>
      <td>535</td>
      <td>0.662695</td>
      <td>0.703688</td>
      <td>0.703262</td>
      <td>0.689882</td>
      <td>0.019225</td>
      <td>540</td>
    </tr>
    <tr>
      <th>387</th>
      <td>0.517269</td>
      <td>0.034257</td>
      <td>0.196252</td>
      <td>0.005410</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.706601</td>
      <td>0.724362</td>
      <td>0.614035</td>
      <td>0.681666</td>
      <td>0.048369</td>
      <td>536</td>
      <td>0.727376</td>
      <td>0.743404</td>
      <td>0.735319</td>
      <td>0.735366</td>
      <td>0.006544</td>
      <td>383</td>
    </tr>
    <tr>
      <th>102</th>
      <td>0.537702</td>
      <td>0.021073</td>
      <td>0.201335</td>
      <td>0.017986</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.650817</td>
      <td>0.694147</td>
      <td>0.691256</td>
      <td>0.678740</td>
      <td>0.019780</td>
      <td>537</td>
      <td>0.655461</td>
      <td>0.702979</td>
      <td>0.700142</td>
      <td>0.686194</td>
      <td>0.021762</td>
      <td>545</td>
    </tr>
    <tr>
      <th>534</th>
      <td>0.468361</td>
      <td>0.024562</td>
      <td>0.240473</td>
      <td>0.067015</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.650817</td>
      <td>0.694147</td>
      <td>0.691256</td>
      <td>0.678740</td>
      <td>0.019780</td>
      <td>537</td>
      <td>0.655461</td>
      <td>0.702979</td>
      <td>0.700142</td>
      <td>0.686194</td>
      <td>0.021762</td>
      <td>545</td>
    </tr>
    <tr>
      <th>318</th>
      <td>0.516945</td>
      <td>0.040174</td>
      <td>0.203748</td>
      <td>0.028224</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.650794</td>
      <td>0.694147</td>
      <td>0.691256</td>
      <td>0.678732</td>
      <td>0.019791</td>
      <td>539</td>
      <td>0.655461</td>
      <td>0.702979</td>
      <td>0.700142</td>
      <td>0.686194</td>
      <td>0.021762</td>
      <td>545</td>
    </tr>
    <tr>
      <th>375</th>
      <td>0.483332</td>
      <td>0.019867</td>
      <td>0.200339</td>
      <td>0.005556</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.650817</td>
      <td>0.694016</td>
      <td>0.691256</td>
      <td>0.678697</td>
      <td>0.019746</td>
      <td>540</td>
      <td>0.655461</td>
      <td>0.702837</td>
      <td>0.700142</td>
      <td>0.686147</td>
      <td>0.021726</td>
      <td>548</td>
    </tr>
    <tr>
      <th>159</th>
      <td>0.495023</td>
      <td>0.026634</td>
      <td>0.192542</td>
      <td>0.008978</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.650817</td>
      <td>0.694016</td>
      <td>0.691256</td>
      <td>0.678697</td>
      <td>0.019746</td>
      <td>540</td>
      <td>0.655461</td>
      <td>0.702837</td>
      <td>0.700142</td>
      <td>0.686147</td>
      <td>0.021726</td>
      <td>548</td>
    </tr>
    <tr>
      <th>591</th>
      <td>0.515976</td>
      <td>0.016678</td>
      <td>0.192059</td>
      <td>0.007574</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.650817</td>
      <td>0.694016</td>
      <td>0.691256</td>
      <td>0.678697</td>
      <td>0.019746</td>
      <td>540</td>
      <td>0.655461</td>
      <td>0.702837</td>
      <td>0.700142</td>
      <td>0.686147</td>
      <td>0.021726</td>
      <td>548</td>
    </tr>
    <tr>
      <th>156</th>
      <td>0.465664</td>
      <td>0.019567</td>
      <td>0.228335</td>
      <td>0.037386</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.650289</td>
      <td>0.693946</td>
      <td>0.690864</td>
      <td>0.678366</td>
      <td>0.019894</td>
      <td>543</td>
      <td>0.654894</td>
      <td>0.702695</td>
      <td>0.699716</td>
      <td>0.685768</td>
      <td>0.021866</td>
      <td>551</td>
    </tr>
    <tr>
      <th>372</th>
      <td>0.503665</td>
      <td>0.015630</td>
      <td>0.189667</td>
      <td>0.008498</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.650289</td>
      <td>0.693946</td>
      <td>0.690864</td>
      <td>0.678366</td>
      <td>0.019894</td>
      <td>543</td>
      <td>0.654894</td>
      <td>0.702695</td>
      <td>0.699716</td>
      <td>0.685768</td>
      <td>0.021866</td>
      <td>551</td>
    </tr>
    <tr>
      <th>588</th>
      <td>0.518738</td>
      <td>0.047471</td>
      <td>0.197692</td>
      <td>0.006351</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.650289</td>
      <td>0.693946</td>
      <td>0.690864</td>
      <td>0.678366</td>
      <td>0.019894</td>
      <td>543</td>
      <td>0.654894</td>
      <td>0.702695</td>
      <td>0.699716</td>
      <td>0.685768</td>
      <td>0.021866</td>
      <td>551</td>
    </tr>
    <tr>
      <th>315</th>
      <td>0.508220</td>
      <td>0.041296</td>
      <td>0.216804</td>
      <td>0.041100</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.650289</td>
      <td>0.693815</td>
      <td>0.690995</td>
      <td>0.678366</td>
      <td>0.019887</td>
      <td>546</td>
      <td>0.654894</td>
      <td>0.702553</td>
      <td>0.699858</td>
      <td>0.685768</td>
      <td>0.021859</td>
      <td>551</td>
    </tr>
    <tr>
      <th>99</th>
      <td>0.489664</td>
      <td>0.044115</td>
      <td>0.223840</td>
      <td>0.020849</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.650289</td>
      <td>0.693815</td>
      <td>0.690864</td>
      <td>0.678323</td>
      <td>0.019860</td>
      <td>547</td>
      <td>0.654894</td>
      <td>0.702553</td>
      <td>0.699716</td>
      <td>0.685721</td>
      <td>0.021829</td>
      <td>555</td>
    </tr>
    <tr>
      <th>153</th>
      <td>0.535331</td>
      <td>0.069358</td>
      <td>0.211335</td>
      <td>0.022483</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.650289</td>
      <td>0.693815</td>
      <td>0.690864</td>
      <td>0.678323</td>
      <td>0.019860</td>
      <td>547</td>
      <td>0.654894</td>
      <td>0.702553</td>
      <td>0.699716</td>
      <td>0.685721</td>
      <td>0.021829</td>
      <td>555</td>
    </tr>
    <tr>
      <th>585</th>
      <td>0.476999</td>
      <td>0.024536</td>
      <td>0.238997</td>
      <td>0.032259</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.650289</td>
      <td>0.693815</td>
      <td>0.690864</td>
      <td>0.678323</td>
      <td>0.019860</td>
      <td>547</td>
      <td>0.654894</td>
      <td>0.702553</td>
      <td>0.699716</td>
      <td>0.685721</td>
      <td>0.021829</td>
      <td>555</td>
    </tr>
    <tr>
      <th>531</th>
      <td>0.587954</td>
      <td>0.015951</td>
      <td>0.208062</td>
      <td>0.008968</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.650289</td>
      <td>0.693815</td>
      <td>0.690864</td>
      <td>0.678323</td>
      <td>0.019860</td>
      <td>547</td>
      <td>0.654894</td>
      <td>0.702553</td>
      <td>0.699716</td>
      <td>0.685721</td>
      <td>0.021829</td>
      <td>555</td>
    </tr>
    <tr>
      <th>369</th>
      <td>0.504003</td>
      <td>0.027801</td>
      <td>0.215329</td>
      <td>0.010780</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>False</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': False, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.650289</td>
      <td>0.693815</td>
      <td>0.690864</td>
      <td>0.678323</td>
      <td>0.019860</td>
      <td>547</td>
      <td>0.654894</td>
      <td>0.702553</td>
      <td>0.699716</td>
      <td>0.685721</td>
      <td>0.021829</td>
      <td>555</td>
    </tr>
    <tr>
      <th>613</th>
      <td>1.513665</td>
      <td>0.020484</td>
      <td>0.334029</td>
      <td>0.006094</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.626575</td>
      <td>0.698697</td>
      <td>0.709046</td>
      <td>0.678106</td>
      <td>0.036682</td>
      <td>552</td>
      <td>0.627801</td>
      <td>0.706383</td>
      <td>0.719433</td>
      <td>0.684539</td>
      <td>0.040472</td>
      <td>561</td>
    </tr>
    <tr>
      <th>181</th>
      <td>1.563001</td>
      <td>0.016868</td>
      <td>0.327663</td>
      <td>0.011673</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.625782</td>
      <td>0.698565</td>
      <td>0.708752</td>
      <td>0.677700</td>
      <td>0.036947</td>
      <td>553</td>
      <td>0.626950</td>
      <td>0.706241</td>
      <td>0.719149</td>
      <td>0.684113</td>
      <td>0.040762</td>
      <td>563</td>
    </tr>
    <tr>
      <th>616</th>
      <td>1.926313</td>
      <td>0.232410</td>
      <td>0.358666</td>
      <td>0.025300</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.617445</td>
      <td>0.708545</td>
      <td>0.706984</td>
      <td>0.677658</td>
      <td>0.042582</td>
      <td>554</td>
      <td>0.618156</td>
      <td>0.718440</td>
      <td>0.717163</td>
      <td>0.684586</td>
      <td>0.046976</td>
      <td>560</td>
    </tr>
    <tr>
      <th>184</th>
      <td>1.334664</td>
      <td>0.033638</td>
      <td>0.413004</td>
      <td>0.140712</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.616904</td>
      <td>0.708283</td>
      <td>0.706853</td>
      <td>0.677347</td>
      <td>0.042743</td>
      <td>555</td>
      <td>0.617589</td>
      <td>0.718156</td>
      <td>0.717021</td>
      <td>0.684255</td>
      <td>0.047143</td>
      <td>562</td>
    </tr>
    <tr>
      <th>614</th>
      <td>2.717300</td>
      <td>0.447973</td>
      <td>0.525196</td>
      <td>0.095554</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.608624</td>
      <td>0.705144</td>
      <td>0.711829</td>
      <td>0.675199</td>
      <td>0.047155</td>
      <td>556</td>
      <td>0.608936</td>
      <td>0.712908</td>
      <td>0.722553</td>
      <td>0.681466</td>
      <td>0.051437</td>
      <td>564</td>
    </tr>
    <tr>
      <th>182</th>
      <td>2.234000</td>
      <td>0.012195</td>
      <td>0.400664</td>
      <td>0.015150</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.608353</td>
      <td>0.704880</td>
      <td>0.711698</td>
      <td>0.674977</td>
      <td>0.047193</td>
      <td>557</td>
      <td>0.608652</td>
      <td>0.712624</td>
      <td>0.722411</td>
      <td>0.681229</td>
      <td>0.051475</td>
      <td>565</td>
    </tr>
    <tr>
      <th>388</th>
      <td>2.036870</td>
      <td>0.105482</td>
      <td>0.455334</td>
      <td>0.086333</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.706574</td>
      <td>0.727621</td>
      <td>0.589794</td>
      <td>0.674663</td>
      <td>0.060623</td>
      <td>558</td>
      <td>0.746667</td>
      <td>0.754752</td>
      <td>0.727518</td>
      <td>0.742979</td>
      <td>0.011420</td>
      <td>358</td>
    </tr>
    <tr>
      <th>396</th>
      <td>0.717000</td>
      <td>0.051269</td>
      <td>0.218999</td>
      <td>0.022759</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.638124</td>
      <td>0.692087</td>
      <td>0.691718</td>
      <td>0.673976</td>
      <td>0.025352</td>
      <td>559</td>
      <td>0.641560</td>
      <td>0.699858</td>
      <td>0.700709</td>
      <td>0.680709</td>
      <td>0.027685</td>
      <td>566</td>
    </tr>
    <tr>
      <th>400</th>
      <td>2.123119</td>
      <td>0.215236</td>
      <td>0.620333</td>
      <td>0.205240</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.604443</td>
      <td>0.707590</td>
      <td>0.705803</td>
      <td>0.672612</td>
      <td>0.048209</td>
      <td>560</td>
      <td>0.604681</td>
      <td>0.717305</td>
      <td>0.715745</td>
      <td>0.679243</td>
      <td>0.052728</td>
      <td>567</td>
    </tr>
    <tr>
      <th>397</th>
      <td>1.753001</td>
      <td>0.030734</td>
      <td>0.370176</td>
      <td>0.011836</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.601396</td>
      <td>0.700773</td>
      <td>0.707314</td>
      <td>0.669828</td>
      <td>0.048462</td>
      <td>561</td>
      <td>0.601560</td>
      <td>0.708652</td>
      <td>0.717730</td>
      <td>0.675981</td>
      <td>0.052754</td>
      <td>568</td>
    </tr>
    <tr>
      <th>617</th>
      <td>2.802701</td>
      <td>0.105329</td>
      <td>0.515897</td>
      <td>0.042102</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.592480</td>
      <td>0.707190</td>
      <td>0.703651</td>
      <td>0.667774</td>
      <td>0.053260</td>
      <td>562</td>
      <td>0.592482</td>
      <td>0.715603</td>
      <td>0.712482</td>
      <td>0.673522</td>
      <td>0.057318</td>
      <td>569</td>
    </tr>
    <tr>
      <th>185</th>
      <td>2.905703</td>
      <td>0.146464</td>
      <td>0.489998</td>
      <td>0.030432</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.592056</td>
      <td>0.707029</td>
      <td>0.703974</td>
      <td>0.667686</td>
      <td>0.053493</td>
      <td>563</td>
      <td>0.592057</td>
      <td>0.715461</td>
      <td>0.712766</td>
      <td>0.673428</td>
      <td>0.057549</td>
      <td>570</td>
    </tr>
    <tr>
      <th>390</th>
      <td>0.504012</td>
      <td>0.017965</td>
      <td>0.201342</td>
      <td>0.013063</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.713386</td>
      <td>0.727433</td>
      <td>0.555014</td>
      <td>0.665278</td>
      <td>0.078179</td>
      <td>564</td>
      <td>0.741986</td>
      <td>0.755319</td>
      <td>0.716879</td>
      <td>0.738061</td>
      <td>0.015936</td>
      <td>376</td>
    </tr>
    <tr>
      <th>450</th>
      <td>0.569999</td>
      <td>0.015123</td>
      <td>0.224335</td>
      <td>0.031052</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.616551</td>
      <td>0.690249</td>
      <td>0.685493</td>
      <td>0.664098</td>
      <td>0.033677</td>
      <td>565</td>
      <td>0.617730</td>
      <td>0.697872</td>
      <td>0.693191</td>
      <td>0.669598</td>
      <td>0.036726</td>
      <td>571</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.623334</td>
      <td>0.020435</td>
      <td>0.193001</td>
      <td>0.003742</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.615597</td>
      <td>0.689986</td>
      <td>0.685493</td>
      <td>0.663692</td>
      <td>0.034058</td>
      <td>566</td>
      <td>0.616738</td>
      <td>0.697589</td>
      <td>0.693191</td>
      <td>0.669173</td>
      <td>0.037121</td>
      <td>572</td>
    </tr>
    <tr>
      <th>398</th>
      <td>2.332530</td>
      <td>0.046848</td>
      <td>0.638334</td>
      <td>0.064149</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.574270</td>
      <td>0.702119</td>
      <td>0.708946</td>
      <td>0.661778</td>
      <td>0.061940</td>
      <td>567</td>
      <td>0.574468</td>
      <td>0.709504</td>
      <td>0.719149</td>
      <td>0.667707</td>
      <td>0.066047</td>
      <td>573</td>
    </tr>
    <tr>
      <th>401</th>
      <td>2.535622</td>
      <td>0.385079</td>
      <td>0.405590</td>
      <td>0.043726</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.575719</td>
      <td>0.706424</td>
      <td>0.702619</td>
      <td>0.661587</td>
      <td>0.060738</td>
      <td>568</td>
      <td>0.575887</td>
      <td>0.714468</td>
      <td>0.711206</td>
      <td>0.667187</td>
      <td>0.064573</td>
      <td>574</td>
    </tr>
    <tr>
      <th>389</th>
      <td>2.254223</td>
      <td>0.259051</td>
      <td>0.431484</td>
      <td>0.023697</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.678176</td>
      <td>0.720742</td>
      <td>0.585805</td>
      <td>0.661574</td>
      <td>0.056325</td>
      <td>569</td>
      <td>0.744397</td>
      <td>0.755887</td>
      <td>0.724255</td>
      <td>0.741513</td>
      <td>0.013073</td>
      <td>363</td>
    </tr>
    <tr>
      <th>234</th>
      <td>0.618683</td>
      <td>0.017479</td>
      <td>0.199002</td>
      <td>0.008605</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.609154</td>
      <td>0.689649</td>
      <td>0.684877</td>
      <td>0.661226</td>
      <td>0.036872</td>
      <td>570</td>
      <td>0.609929</td>
      <td>0.697163</td>
      <td>0.692340</td>
      <td>0.666478</td>
      <td>0.040034</td>
      <td>575</td>
    </tr>
    <tr>
      <th>78</th>
      <td>0.579346</td>
      <td>0.033403</td>
      <td>0.232989</td>
      <td>0.044082</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.598524</td>
      <td>0.692673</td>
      <td>0.688828</td>
      <td>0.660008</td>
      <td>0.043504</td>
      <td>571</td>
      <td>0.598723</td>
      <td>0.700709</td>
      <td>0.697021</td>
      <td>0.665485</td>
      <td>0.047231</td>
      <td>576</td>
    </tr>
    <tr>
      <th>510</th>
      <td>0.532338</td>
      <td>0.043372</td>
      <td>0.231723</td>
      <td>0.041517</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.598524</td>
      <td>0.692673</td>
      <td>0.688828</td>
      <td>0.660008</td>
      <td>0.043504</td>
      <td>571</td>
      <td>0.598723</td>
      <td>0.700709</td>
      <td>0.697021</td>
      <td>0.665485</td>
      <td>0.047231</td>
      <td>576</td>
    </tr>
    <tr>
      <th>294</th>
      <td>0.497998</td>
      <td>0.036367</td>
      <td>0.191335</td>
      <td>0.011671</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.598385</td>
      <td>0.692805</td>
      <td>0.688828</td>
      <td>0.660006</td>
      <td>0.043603</td>
      <td>573</td>
      <td>0.598582</td>
      <td>0.700851</td>
      <td>0.697021</td>
      <td>0.665485</td>
      <td>0.047333</td>
      <td>576</td>
    </tr>
    <tr>
      <th>394</th>
      <td>1.320332</td>
      <td>0.070542</td>
      <td>0.342333</td>
      <td>0.035799</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.741481</td>
      <td>0.754813</td>
      <td>0.482499</td>
      <td>0.659597</td>
      <td>0.125346</td>
      <td>574</td>
      <td>0.764397</td>
      <td>0.776879</td>
      <td>0.704255</td>
      <td>0.748511</td>
      <td>0.031705</td>
      <td>337</td>
    </tr>
    <tr>
      <th>395</th>
      <td>2.018000</td>
      <td>0.010984</td>
      <td>0.430662</td>
      <td>0.036607</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.739551</td>
      <td>0.756812</td>
      <td>0.474187</td>
      <td>0.656850</td>
      <td>0.129355</td>
      <td>575</td>
      <td>0.761702</td>
      <td>0.778865</td>
      <td>0.701560</td>
      <td>0.747376</td>
      <td>0.033146</td>
      <td>339</td>
    </tr>
    <tr>
      <th>393</th>
      <td>0.596030</td>
      <td>0.087821</td>
      <td>0.278308</td>
      <td>0.018408</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.733081</td>
      <td>0.744115</td>
      <td>0.493003</td>
      <td>0.656733</td>
      <td>0.115862</td>
      <td>576</td>
      <td>0.758440</td>
      <td>0.769078</td>
      <td>0.705390</td>
      <td>0.744303</td>
      <td>0.027856</td>
      <td>352</td>
    </tr>
    <tr>
      <th>453</th>
      <td>0.477996</td>
      <td>0.007072</td>
      <td>0.224333</td>
      <td>0.062783</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.579994</td>
      <td>0.692309</td>
      <td>0.688290</td>
      <td>0.653531</td>
      <td>0.052024</td>
      <td>577</td>
      <td>0.580000</td>
      <td>0.700284</td>
      <td>0.696312</td>
      <td>0.658865</td>
      <td>0.055790</td>
      <td>579</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.496999</td>
      <td>0.016673</td>
      <td>0.215001</td>
      <td>0.028082</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.579567</td>
      <td>0.692309</td>
      <td>0.688159</td>
      <td>0.653345</td>
      <td>0.052196</td>
      <td>578</td>
      <td>0.579574</td>
      <td>0.700284</td>
      <td>0.696170</td>
      <td>0.658676</td>
      <td>0.055959</td>
      <td>580</td>
    </tr>
    <tr>
      <th>237</th>
      <td>0.511336</td>
      <td>0.021749</td>
      <td>0.229666</td>
      <td>0.015430</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.578991</td>
      <td>0.691242</td>
      <td>0.688028</td>
      <td>0.652754</td>
      <td>0.052175</td>
      <td>579</td>
      <td>0.579007</td>
      <td>0.699007</td>
      <td>0.696028</td>
      <td>0.658014</td>
      <td>0.055880</td>
      <td>581</td>
    </tr>
    <tr>
      <th>391</th>
      <td>1.283255</td>
      <td>0.016213</td>
      <td>0.381609</td>
      <td>0.024124</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.715761</td>
      <td>0.728439</td>
      <td>0.510041</td>
      <td>0.651414</td>
      <td>0.100099</td>
      <td>580</td>
      <td>0.746383</td>
      <td>0.757872</td>
      <td>0.708511</td>
      <td>0.737589</td>
      <td>0.021089</td>
      <td>377</td>
    </tr>
    <tr>
      <th>451</th>
      <td>1.349664</td>
      <td>0.034702</td>
      <td>0.326333</td>
      <td>0.021853</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.565841</td>
      <td>0.694078</td>
      <td>0.690650</td>
      <td>0.650190</td>
      <td>0.059660</td>
      <td>581</td>
      <td>0.566241</td>
      <td>0.700851</td>
      <td>0.697447</td>
      <td>0.654846</td>
      <td>0.062669</td>
      <td>582</td>
    </tr>
    <tr>
      <th>19</th>
      <td>1.353668</td>
      <td>0.031353</td>
      <td>0.309998</td>
      <td>0.013731</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.563165</td>
      <td>0.693761</td>
      <td>0.690413</td>
      <td>0.649113</td>
      <td>0.060790</td>
      <td>582</td>
      <td>0.563688</td>
      <td>0.700426</td>
      <td>0.697163</td>
      <td>0.653759</td>
      <td>0.063704</td>
      <td>583</td>
    </tr>
    <tr>
      <th>235</th>
      <td>1.286003</td>
      <td>0.024164</td>
      <td>0.295002</td>
      <td>0.002159</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.553460</td>
      <td>0.692970</td>
      <td>0.688541</td>
      <td>0.644990</td>
      <td>0.064747</td>
      <td>583</td>
      <td>0.554468</td>
      <td>0.699574</td>
      <td>0.695035</td>
      <td>0.649693</td>
      <td>0.067359</td>
      <td>584</td>
    </tr>
    <tr>
      <th>392</th>
      <td>2.190104</td>
      <td>0.108753</td>
      <td>0.552322</td>
      <td>0.037949</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>constant</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'constant', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.716268</td>
      <td>0.725713</td>
      <td>0.481140</td>
      <td>0.641040</td>
      <td>0.113132</td>
      <td>584</td>
      <td>0.748794</td>
      <td>0.757447</td>
      <td>0.701844</td>
      <td>0.736028</td>
      <td>0.024429</td>
      <td>381</td>
    </tr>
    <tr>
      <th>511</th>
      <td>1.257000</td>
      <td>0.022904</td>
      <td>0.307999</td>
      <td>0.012571</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.534319</td>
      <td>0.693286</td>
      <td>0.689807</td>
      <td>0.639137</td>
      <td>0.074132</td>
      <td>585</td>
      <td>0.536596</td>
      <td>0.699858</td>
      <td>0.696454</td>
      <td>0.644303</td>
      <td>0.076173</td>
      <td>585</td>
    </tr>
    <tr>
      <th>79</th>
      <td>1.668665</td>
      <td>0.268958</td>
      <td>0.801668</td>
      <td>0.224682</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.534319</td>
      <td>0.693286</td>
      <td>0.689807</td>
      <td>0.639137</td>
      <td>0.074132</td>
      <td>585</td>
      <td>0.536596</td>
      <td>0.699858</td>
      <td>0.696454</td>
      <td>0.644303</td>
      <td>0.076173</td>
      <td>585</td>
    </tr>
    <tr>
      <th>295</th>
      <td>1.250670</td>
      <td>0.043984</td>
      <td>0.343663</td>
      <td>0.034379</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.533996</td>
      <td>0.693286</td>
      <td>0.689675</td>
      <td>0.638986</td>
      <td>0.074254</td>
      <td>587</td>
      <td>0.536312</td>
      <td>0.699858</td>
      <td>0.696312</td>
      <td>0.644161</td>
      <td>0.076274</td>
      <td>587</td>
    </tr>
    <tr>
      <th>452</th>
      <td>1.977334</td>
      <td>0.043051</td>
      <td>0.417665</td>
      <td>0.016131</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.523541</td>
      <td>0.694160</td>
      <td>0.686951</td>
      <td>0.634884</td>
      <td>0.078786</td>
      <td>588</td>
      <td>0.526667</td>
      <td>0.700142</td>
      <td>0.693050</td>
      <td>0.639953</td>
      <td>0.080158</td>
      <td>588</td>
    </tr>
    <tr>
      <th>20</th>
      <td>1.971000</td>
      <td>0.043204</td>
      <td>0.449670</td>
      <td>0.028860</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.523519</td>
      <td>0.694160</td>
      <td>0.686951</td>
      <td>0.634877</td>
      <td>0.078797</td>
      <td>589</td>
      <td>0.526667</td>
      <td>0.700142</td>
      <td>0.693050</td>
      <td>0.639953</td>
      <td>0.080158</td>
      <td>588</td>
    </tr>
    <tr>
      <th>454</th>
      <td>1.247335</td>
      <td>0.017744</td>
      <td>0.369331</td>
      <td>0.049270</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.517557</td>
      <td>0.693260</td>
      <td>0.690281</td>
      <td>0.633700</td>
      <td>0.082134</td>
      <td>590</td>
      <td>0.521277</td>
      <td>0.699858</td>
      <td>0.696879</td>
      <td>0.639338</td>
      <td>0.083491</td>
      <td>590</td>
    </tr>
    <tr>
      <th>22</th>
      <td>1.292668</td>
      <td>0.026588</td>
      <td>0.399331</td>
      <td>0.023921</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.517092</td>
      <td>0.693260</td>
      <td>0.690281</td>
      <td>0.633544</td>
      <td>0.082353</td>
      <td>591</td>
      <td>0.520851</td>
      <td>0.699858</td>
      <td>0.696879</td>
      <td>0.639196</td>
      <td>0.083691</td>
      <td>591</td>
    </tr>
    <tr>
      <th>238</th>
      <td>1.302661</td>
      <td>0.068224</td>
      <td>0.369667</td>
      <td>0.019222</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.514270</td>
      <td>0.693312</td>
      <td>0.689886</td>
      <td>0.632489</td>
      <td>0.083605</td>
      <td>592</td>
      <td>0.518298</td>
      <td>0.699858</td>
      <td>0.696454</td>
      <td>0.638203</td>
      <td>0.084797</td>
      <td>592</td>
    </tr>
    <tr>
      <th>236</th>
      <td>1.930001</td>
      <td>0.075182</td>
      <td>0.411665</td>
      <td>0.025848</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.513649</td>
      <td>0.693910</td>
      <td>0.683989</td>
      <td>0.630516</td>
      <td>0.082737</td>
      <td>593</td>
      <td>0.517872</td>
      <td>0.699716</td>
      <td>0.689787</td>
      <td>0.635792</td>
      <td>0.083480</td>
      <td>593</td>
    </tr>
    <tr>
      <th>75</th>
      <td>0.520665</td>
      <td>0.057759</td>
      <td>0.198666</td>
      <td>0.004500</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.530802</td>
      <td>0.682299</td>
      <td>0.673976</td>
      <td>0.629025</td>
      <td>0.069538</td>
      <td>594</td>
      <td>0.533050</td>
      <td>0.688652</td>
      <td>0.679858</td>
      <td>0.633853</td>
      <td>0.071369</td>
      <td>594</td>
    </tr>
    <tr>
      <th>507</th>
      <td>0.501084</td>
      <td>0.044220</td>
      <td>0.252061</td>
      <td>0.041654</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.530802</td>
      <td>0.682299</td>
      <td>0.673976</td>
      <td>0.629025</td>
      <td>0.069538</td>
      <td>594</td>
      <td>0.533050</td>
      <td>0.688652</td>
      <td>0.679858</td>
      <td>0.633853</td>
      <td>0.071369</td>
      <td>594</td>
    </tr>
    <tr>
      <th>291</th>
      <td>0.473334</td>
      <td>0.016356</td>
      <td>0.207000</td>
      <td>0.007788</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.530498</td>
      <td>0.682299</td>
      <td>0.673844</td>
      <td>0.628880</td>
      <td>0.069652</td>
      <td>596</td>
      <td>0.532766</td>
      <td>0.688652</td>
      <td>0.679716</td>
      <td>0.633712</td>
      <td>0.071473</td>
      <td>596</td>
    </tr>
    <tr>
      <th>132</th>
      <td>0.542111</td>
      <td>0.048348</td>
      <td>0.195337</td>
      <td>0.004987</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.529416</td>
      <td>0.682456</td>
      <td>0.674315</td>
      <td>0.628729</td>
      <td>0.070304</td>
      <td>597</td>
      <td>0.531773</td>
      <td>0.688794</td>
      <td>0.680142</td>
      <td>0.633570</td>
      <td>0.072068</td>
      <td>597</td>
    </tr>
    <tr>
      <th>564</th>
      <td>0.577374</td>
      <td>0.116304</td>
      <td>0.232669</td>
      <td>0.015108</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.529416</td>
      <td>0.682456</td>
      <td>0.674315</td>
      <td>0.628729</td>
      <td>0.070304</td>
      <td>597</td>
      <td>0.531773</td>
      <td>0.688794</td>
      <td>0.680142</td>
      <td>0.633570</td>
      <td>0.072068</td>
      <td>597</td>
    </tr>
    <tr>
      <th>348</th>
      <td>0.478664</td>
      <td>0.050738</td>
      <td>0.226003</td>
      <td>0.032568</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.529416</td>
      <td>0.682325</td>
      <td>0.674315</td>
      <td>0.628685</td>
      <td>0.070270</td>
      <td>599</td>
      <td>0.531773</td>
      <td>0.688652</td>
      <td>0.680142</td>
      <td>0.633522</td>
      <td>0.072032</td>
      <td>599</td>
    </tr>
    <tr>
      <th>129</th>
      <td>0.553010</td>
      <td>0.049092</td>
      <td>0.202991</td>
      <td>0.015567</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.526064</td>
      <td>0.682271</td>
      <td>0.674572</td>
      <td>0.627636</td>
      <td>0.071891</td>
      <td>600</td>
      <td>0.528652</td>
      <td>0.688511</td>
      <td>0.680284</td>
      <td>0.632482</td>
      <td>0.073496</td>
      <td>600</td>
    </tr>
    <tr>
      <th>561</th>
      <td>0.525203</td>
      <td>0.014993</td>
      <td>0.226040</td>
      <td>0.029271</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.526064</td>
      <td>0.682271</td>
      <td>0.674572</td>
      <td>0.627636</td>
      <td>0.071891</td>
      <td>600</td>
      <td>0.528652</td>
      <td>0.688511</td>
      <td>0.680284</td>
      <td>0.632482</td>
      <td>0.073496</td>
      <td>600</td>
    </tr>
    <tr>
      <th>345</th>
      <td>0.533332</td>
      <td>0.070244</td>
      <td>0.193671</td>
      <td>0.004029</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.525912</td>
      <td>0.682271</td>
      <td>0.674572</td>
      <td>0.627585</td>
      <td>0.071962</td>
      <td>602</td>
      <td>0.528511</td>
      <td>0.688511</td>
      <td>0.680284</td>
      <td>0.632435</td>
      <td>0.073562</td>
      <td>602</td>
    </tr>
    <tr>
      <th>558</th>
      <td>0.627334</td>
      <td>0.023328</td>
      <td>0.254848</td>
      <td>0.052257</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.525606</td>
      <td>0.682033</td>
      <td>0.674440</td>
      <td>0.627360</td>
      <td>0.072017</td>
      <td>603</td>
      <td>0.528227</td>
      <td>0.688227</td>
      <td>0.680142</td>
      <td>0.632199</td>
      <td>0.073593</td>
      <td>603</td>
    </tr>
    <tr>
      <th>126</th>
      <td>0.563335</td>
      <td>0.040038</td>
      <td>0.225000</td>
      <td>0.042765</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.525606</td>
      <td>0.682033</td>
      <td>0.674440</td>
      <td>0.627360</td>
      <td>0.072017</td>
      <td>603</td>
      <td>0.528227</td>
      <td>0.688227</td>
      <td>0.680142</td>
      <td>0.632199</td>
      <td>0.073593</td>
      <td>603</td>
    </tr>
    <tr>
      <th>504</th>
      <td>0.507997</td>
      <td>0.029471</td>
      <td>0.230668</td>
      <td>0.054321</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.525606</td>
      <td>0.682033</td>
      <td>0.674440</td>
      <td>0.627360</td>
      <td>0.072017</td>
      <td>603</td>
      <td>0.528227</td>
      <td>0.688227</td>
      <td>0.680142</td>
      <td>0.632199</td>
      <td>0.073593</td>
      <td>603</td>
    </tr>
    <tr>
      <th>342</th>
      <td>0.458332</td>
      <td>0.012036</td>
      <td>0.208333</td>
      <td>0.036593</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.525606</td>
      <td>0.682033</td>
      <td>0.674440</td>
      <td>0.627360</td>
      <td>0.072017</td>
      <td>603</td>
      <td>0.528227</td>
      <td>0.688227</td>
      <td>0.680142</td>
      <td>0.632199</td>
      <td>0.073593</td>
      <td>603</td>
    </tr>
    <tr>
      <th>72</th>
      <td>0.493333</td>
      <td>0.029952</td>
      <td>0.219665</td>
      <td>0.011671</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.525606</td>
      <td>0.682033</td>
      <td>0.674440</td>
      <td>0.627360</td>
      <td>0.072017</td>
      <td>603</td>
      <td>0.528227</td>
      <td>0.688227</td>
      <td>0.680142</td>
      <td>0.632199</td>
      <td>0.073593</td>
      <td>603</td>
    </tr>
    <tr>
      <th>288</th>
      <td>0.581505</td>
      <td>0.011376</td>
      <td>0.205336</td>
      <td>0.014843</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 1)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 1), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.525606</td>
      <td>0.682033</td>
      <td>0.674308</td>
      <td>0.627316</td>
      <td>0.071989</td>
      <td>608</td>
      <td>0.528227</td>
      <td>0.688227</td>
      <td>0.680000</td>
      <td>0.632151</td>
      <td>0.073562</td>
      <td>608</td>
    </tr>
    <tr>
      <th>80</th>
      <td>3.291187</td>
      <td>0.206872</td>
      <td>0.564667</td>
      <td>0.043656</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.490401</td>
      <td>0.693729</td>
      <td>0.686441</td>
      <td>0.623523</td>
      <td>0.094179</td>
      <td>609</td>
      <td>0.497447</td>
      <td>0.699574</td>
      <td>0.692340</td>
      <td>0.629787</td>
      <td>0.093625</td>
      <td>609</td>
    </tr>
    <tr>
      <th>512</th>
      <td>1.997413</td>
      <td>0.068696</td>
      <td>0.395996</td>
      <td>0.010702</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.490401</td>
      <td>0.693729</td>
      <td>0.686441</td>
      <td>0.623523</td>
      <td>0.094179</td>
      <td>609</td>
      <td>0.497447</td>
      <td>0.699574</td>
      <td>0.692340</td>
      <td>0.629787</td>
      <td>0.093625</td>
      <td>609</td>
    </tr>
    <tr>
      <th>296</th>
      <td>1.885668</td>
      <td>0.047256</td>
      <td>0.444998</td>
      <td>0.029814</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.490401</td>
      <td>0.693464</td>
      <td>0.686309</td>
      <td>0.623391</td>
      <td>0.094084</td>
      <td>611</td>
      <td>0.497447</td>
      <td>0.699291</td>
      <td>0.692199</td>
      <td>0.629645</td>
      <td>0.093523</td>
      <td>611</td>
    </tr>
    <tr>
      <th>455</th>
      <td>1.880998</td>
      <td>0.053234</td>
      <td>0.405666</td>
      <td>0.031930</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.485462</td>
      <td>0.694209</td>
      <td>0.686334</td>
      <td>0.622001</td>
      <td>0.096602</td>
      <td>612</td>
      <td>0.493333</td>
      <td>0.700142</td>
      <td>0.692199</td>
      <td>0.628558</td>
      <td>0.095673</td>
      <td>612</td>
    </tr>
    <tr>
      <th>23</th>
      <td>2.026334</td>
      <td>0.041696</td>
      <td>0.430999</td>
      <td>0.029014</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.485299</td>
      <td>0.694209</td>
      <td>0.686334</td>
      <td>0.621947</td>
      <td>0.096678</td>
      <td>613</td>
      <td>0.493191</td>
      <td>0.700142</td>
      <td>0.692199</td>
      <td>0.628511</td>
      <td>0.095740</td>
      <td>613</td>
    </tr>
    <tr>
      <th>239</th>
      <td>1.949000</td>
      <td>0.046927</td>
      <td>0.379666</td>
      <td>0.010079</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.481315</td>
      <td>0.694366</td>
      <td>0.685937</td>
      <td>0.620540</td>
      <td>0.098506</td>
      <td>614</td>
      <td>0.489787</td>
      <td>0.700284</td>
      <td>0.691773</td>
      <td>0.627281</td>
      <td>0.097285</td>
      <td>614</td>
    </tr>
    <tr>
      <th>218</th>
      <td>1.952002</td>
      <td>0.068996</td>
      <td>0.421337</td>
      <td>0.025313</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.1</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.622870</td>
      <td>0.600268</td>
      <td>0.609911</td>
      <td>0.611017</td>
      <td>0.009260</td>
      <td>615</td>
      <td>0.623972</td>
      <td>0.600284</td>
      <td>0.610213</td>
      <td>0.611489</td>
      <td>0.009713</td>
      <td>630</td>
    </tr>
    <tr>
      <th>326</th>
      <td>1.941001</td>
      <td>0.015296</td>
      <td>0.447000</td>
      <td>0.038292</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.622870</td>
      <td>0.600268</td>
      <td>0.609911</td>
      <td>0.611017</td>
      <td>0.009260</td>
      <td>615</td>
      <td>0.623972</td>
      <td>0.600284</td>
      <td>0.610213</td>
      <td>0.611489</td>
      <td>0.009713</td>
      <td>630</td>
    </tr>
    <tr>
      <th>380</th>
      <td>1.979671</td>
      <td>0.031668</td>
      <td>0.389999</td>
      <td>0.009903</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.25</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.25, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.622870</td>
      <td>0.600268</td>
      <td>0.609911</td>
      <td>0.611017</td>
      <td>0.009260</td>
      <td>615</td>
      <td>0.623972</td>
      <td>0.600284</td>
      <td>0.610213</td>
      <td>0.611489</td>
      <td>0.009713</td>
      <td>630</td>
    </tr>
    <tr>
      <th>272</th>
      <td>1.870668</td>
      <td>0.036352</td>
      <td>0.428665</td>
      <td>0.049492</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>optimal</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.622870</td>
      <td>0.600268</td>
      <td>0.609911</td>
      <td>0.611017</td>
      <td>0.009260</td>
      <td>615</td>
      <td>0.623972</td>
      <td>0.600284</td>
      <td>0.610213</td>
      <td>0.611489</td>
      <td>0.009713</td>
      <td>630</td>
    </tr>
    <tr>
      <th>508</th>
      <td>1.240468</td>
      <td>0.014244</td>
      <td>0.327612</td>
      <td>0.015076</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.465515</td>
      <td>0.685749</td>
      <td>0.679516</td>
      <td>0.610260</td>
      <td>0.102382</td>
      <td>619</td>
      <td>0.476312</td>
      <td>0.691206</td>
      <td>0.684681</td>
      <td>0.617400</td>
      <td>0.099799</td>
      <td>615</td>
    </tr>
    <tr>
      <th>76</th>
      <td>1.225026</td>
      <td>0.004228</td>
      <td>0.327373</td>
      <td>0.040436</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.465515</td>
      <td>0.685749</td>
      <td>0.679516</td>
      <td>0.610260</td>
      <td>0.102382</td>
      <td>619</td>
      <td>0.476312</td>
      <td>0.691206</td>
      <td>0.684681</td>
      <td>0.617400</td>
      <td>0.099799</td>
      <td>615</td>
    </tr>
    <tr>
      <th>292</th>
      <td>1.237999</td>
      <td>0.007788</td>
      <td>0.356334</td>
      <td>0.028534</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.465182</td>
      <td>0.685749</td>
      <td>0.679383</td>
      <td>0.610105</td>
      <td>0.102509</td>
      <td>621</td>
      <td>0.476028</td>
      <td>0.691206</td>
      <td>0.684539</td>
      <td>0.617258</td>
      <td>0.099901</td>
      <td>617</td>
    </tr>
    <tr>
      <th>349</th>
      <td>1.246999</td>
      <td>0.008980</td>
      <td>0.303003</td>
      <td>0.015637</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.465015</td>
      <td>0.685749</td>
      <td>0.679118</td>
      <td>0.609961</td>
      <td>0.102528</td>
      <td>622</td>
      <td>0.475887</td>
      <td>0.691206</td>
      <td>0.684255</td>
      <td>0.617116</td>
      <td>0.099905</td>
      <td>618</td>
    </tr>
    <tr>
      <th>133</th>
      <td>1.294873</td>
      <td>0.013421</td>
      <td>0.356334</td>
      <td>0.029823</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.465015</td>
      <td>0.685749</td>
      <td>0.679118</td>
      <td>0.609961</td>
      <td>0.102528</td>
      <td>622</td>
      <td>0.475887</td>
      <td>0.691206</td>
      <td>0.684255</td>
      <td>0.617116</td>
      <td>0.099905</td>
      <td>618</td>
    </tr>
    <tr>
      <th>565</th>
      <td>1.865402</td>
      <td>0.192524</td>
      <td>0.348788</td>
      <td>0.031793</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.465015</td>
      <td>0.685749</td>
      <td>0.679118</td>
      <td>0.609961</td>
      <td>0.102528</td>
      <td>622</td>
      <td>0.475887</td>
      <td>0.691206</td>
      <td>0.684255</td>
      <td>0.617116</td>
      <td>0.099905</td>
      <td>618</td>
    </tr>
    <tr>
      <th>562</th>
      <td>1.235231</td>
      <td>0.001906</td>
      <td>0.332320</td>
      <td>0.049865</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.460664</td>
      <td>0.685111</td>
      <td>0.678479</td>
      <td>0.608085</td>
      <td>0.104277</td>
      <td>625</td>
      <td>0.472199</td>
      <td>0.690496</td>
      <td>0.683546</td>
      <td>0.615414</td>
      <td>0.101308</td>
      <td>621</td>
    </tr>
    <tr>
      <th>130</th>
      <td>1.746349</td>
      <td>0.054450</td>
      <td>0.599655</td>
      <td>0.148755</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.460664</td>
      <td>0.685111</td>
      <td>0.678479</td>
      <td>0.608085</td>
      <td>0.104277</td>
      <td>625</td>
      <td>0.472199</td>
      <td>0.690496</td>
      <td>0.683546</td>
      <td>0.615414</td>
      <td>0.101308</td>
      <td>621</td>
    </tr>
    <tr>
      <th>346</th>
      <td>1.225002</td>
      <td>0.013141</td>
      <td>0.312333</td>
      <td>0.015158</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.460496</td>
      <td>0.685111</td>
      <td>0.678479</td>
      <td>0.608029</td>
      <td>0.104356</td>
      <td>627</td>
      <td>0.472057</td>
      <td>0.690496</td>
      <td>0.683546</td>
      <td>0.615366</td>
      <td>0.101375</td>
      <td>623</td>
    </tr>
    <tr>
      <th>559</th>
      <td>1.236136</td>
      <td>0.013955</td>
      <td>0.320783</td>
      <td>0.013080</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.460496</td>
      <td>0.685135</td>
      <td>0.678105</td>
      <td>0.607912</td>
      <td>0.104278</td>
      <td>628</td>
      <td>0.472057</td>
      <td>0.690496</td>
      <td>0.683121</td>
      <td>0.615225</td>
      <td>0.101280</td>
      <td>624</td>
    </tr>
    <tr>
      <th>343</th>
      <td>1.297333</td>
      <td>0.017306</td>
      <td>0.381333</td>
      <td>0.011896</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.460496</td>
      <td>0.685135</td>
      <td>0.678105</td>
      <td>0.607912</td>
      <td>0.104278</td>
      <td>628</td>
      <td>0.472057</td>
      <td>0.690496</td>
      <td>0.683121</td>
      <td>0.615225</td>
      <td>0.101280</td>
      <td>624</td>
    </tr>
    <tr>
      <th>505</th>
      <td>1.279123</td>
      <td>0.092486</td>
      <td>0.315459</td>
      <td>0.015139</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.460496</td>
      <td>0.685135</td>
      <td>0.678105</td>
      <td>0.607912</td>
      <td>0.104278</td>
      <td>628</td>
      <td>0.472057</td>
      <td>0.690496</td>
      <td>0.683121</td>
      <td>0.615225</td>
      <td>0.101280</td>
      <td>624</td>
    </tr>
    <tr>
      <th>127</th>
      <td>1.230002</td>
      <td>0.012833</td>
      <td>0.322663</td>
      <td>0.018699</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.460496</td>
      <td>0.685135</td>
      <td>0.678105</td>
      <td>0.607912</td>
      <td>0.104278</td>
      <td>628</td>
      <td>0.472057</td>
      <td>0.690496</td>
      <td>0.683121</td>
      <td>0.615225</td>
      <td>0.101280</td>
      <td>624</td>
    </tr>
    <tr>
      <th>73</th>
      <td>1.441022</td>
      <td>0.125880</td>
      <td>0.358330</td>
      <td>0.011809</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.460496</td>
      <td>0.685135</td>
      <td>0.678105</td>
      <td>0.607912</td>
      <td>0.104278</td>
      <td>628</td>
      <td>0.472057</td>
      <td>0.690496</td>
      <td>0.683121</td>
      <td>0.615225</td>
      <td>0.101280</td>
      <td>624</td>
    </tr>
    <tr>
      <th>289</th>
      <td>1.235665</td>
      <td>0.023303</td>
      <td>0.327666</td>
      <td>0.018518</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 2)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 2), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.460450</td>
      <td>0.685135</td>
      <td>0.677817</td>
      <td>0.607801</td>
      <td>0.104235</td>
      <td>633</td>
      <td>0.472057</td>
      <td>0.690496</td>
      <td>0.682837</td>
      <td>0.615130</td>
      <td>0.101216</td>
      <td>629</td>
    </tr>
    <tr>
      <th>509</th>
      <td>1.943385</td>
      <td>0.025105</td>
      <td>0.406521</td>
      <td>0.005087</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.427270</td>
      <td>0.687415</td>
      <td>0.676587</td>
      <td>0.597090</td>
      <td>0.120163</td>
      <td>634</td>
      <td>0.445390</td>
      <td>0.692340</td>
      <td>0.681135</td>
      <td>0.606288</td>
      <td>0.113864</td>
      <td>634</td>
    </tr>
    <tr>
      <th>77</th>
      <td>2.018026</td>
      <td>0.077830</td>
      <td>0.564328</td>
      <td>0.112959</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.427093</td>
      <td>0.687282</td>
      <td>0.676587</td>
      <td>0.596987</td>
      <td>0.120213</td>
      <td>635</td>
      <td>0.445248</td>
      <td>0.692199</td>
      <td>0.681135</td>
      <td>0.606194</td>
      <td>0.113895</td>
      <td>635</td>
    </tr>
    <tr>
      <th>293</th>
      <td>1.891670</td>
      <td>0.032763</td>
      <td>0.456663</td>
      <td>0.034585</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.426741</td>
      <td>0.687282</td>
      <td>0.676587</td>
      <td>0.596870</td>
      <td>0.120379</td>
      <td>636</td>
      <td>0.444965</td>
      <td>0.692199</td>
      <td>0.681135</td>
      <td>0.606099</td>
      <td>0.114029</td>
      <td>636</td>
    </tr>
    <tr>
      <th>134</th>
      <td>2.513548</td>
      <td>0.368016</td>
      <td>0.756970</td>
      <td>0.368097</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.426388</td>
      <td>0.687304</td>
      <td>0.676454</td>
      <td>0.596715</td>
      <td>0.120521</td>
      <td>637</td>
      <td>0.444681</td>
      <td>0.692199</td>
      <td>0.680993</td>
      <td>0.605957</td>
      <td>0.114131</td>
      <td>637</td>
    </tr>
    <tr>
      <th>566</th>
      <td>1.911751</td>
      <td>0.121908</td>
      <td>0.475332</td>
      <td>0.018210</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.426388</td>
      <td>0.687304</td>
      <td>0.676454</td>
      <td>0.596715</td>
      <td>0.120521</td>
      <td>637</td>
      <td>0.444681</td>
      <td>0.692199</td>
      <td>0.680993</td>
      <td>0.605957</td>
      <td>0.114131</td>
      <td>637</td>
    </tr>
    <tr>
      <th>350</th>
      <td>1.917662</td>
      <td>0.019190</td>
      <td>0.402331</td>
      <td>0.004713</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>modified_huber</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.426211</td>
      <td>0.687304</td>
      <td>0.676454</td>
      <td>0.596657</td>
      <td>0.120605</td>
      <td>639</td>
      <td>0.444539</td>
      <td>0.692199</td>
      <td>0.680993</td>
      <td>0.605910</td>
      <td>0.114198</td>
      <td>639</td>
    </tr>
    <tr>
      <th>347</th>
      <td>1.928002</td>
      <td>0.005888</td>
      <td>0.429001</td>
      <td>0.039654</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.422494</td>
      <td>0.686663</td>
      <td>0.675546</td>
      <td>0.594901</td>
      <td>0.121995</td>
      <td>640</td>
      <td>0.441560</td>
      <td>0.691489</td>
      <td>0.680000</td>
      <td>0.604350</td>
      <td>0.115205</td>
      <td>640</td>
    </tr>
    <tr>
      <th>131</th>
      <td>2.402221</td>
      <td>0.335427</td>
      <td>0.478779</td>
      <td>0.043111</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.422494</td>
      <td>0.686663</td>
      <td>0.675546</td>
      <td>0.594901</td>
      <td>0.121995</td>
      <td>640</td>
      <td>0.441560</td>
      <td>0.691489</td>
      <td>0.680000</td>
      <td>0.604350</td>
      <td>0.115205</td>
      <td>640</td>
    </tr>
    <tr>
      <th>563</th>
      <td>2.065447</td>
      <td>0.140759</td>
      <td>0.780234</td>
      <td>0.209726</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>log</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'log', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.422494</td>
      <td>0.686663</td>
      <td>0.675546</td>
      <td>0.594901</td>
      <td>0.121995</td>
      <td>640</td>
      <td>0.441560</td>
      <td>0.691489</td>
      <td>0.680000</td>
      <td>0.604350</td>
      <td>0.115205</td>
      <td>640</td>
    </tr>
    <tr>
      <th>344</th>
      <td>1.836667</td>
      <td>0.055403</td>
      <td>0.436997</td>
      <td>0.048195</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.422316</td>
      <td>0.686818</td>
      <td>0.675546</td>
      <td>0.594893</td>
      <td>0.122117</td>
      <td>643</td>
      <td>0.441418</td>
      <td>0.691631</td>
      <td>0.680000</td>
      <td>0.604350</td>
      <td>0.115308</td>
      <td>640</td>
    </tr>
    <tr>
      <th>74</th>
      <td>1.855327</td>
      <td>0.059903</td>
      <td>0.433332</td>
      <td>0.019872</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.422316</td>
      <td>0.686818</td>
      <td>0.675546</td>
      <td>0.594893</td>
      <td>0.122117</td>
      <td>643</td>
      <td>0.441418</td>
      <td>0.691631</td>
      <td>0.680000</td>
      <td>0.604350</td>
      <td>0.115308</td>
      <td>640</td>
    </tr>
    <tr>
      <th>506</th>
      <td>1.900729</td>
      <td>0.067752</td>
      <td>0.438113</td>
      <td>0.044099</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.422316</td>
      <td>0.686663</td>
      <td>0.675546</td>
      <td>0.594842</td>
      <td>0.122078</td>
      <td>645</td>
      <td>0.441418</td>
      <td>0.691489</td>
      <td>0.680000</td>
      <td>0.604303</td>
      <td>0.115272</td>
      <td>645</td>
    </tr>
    <tr>
      <th>128</th>
      <td>1.884672</td>
      <td>0.022174</td>
      <td>0.423330</td>
      <td>0.017557</td>
      <td>0.0001</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.0001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.422316</td>
      <td>0.686663</td>
      <td>0.675546</td>
      <td>0.594842</td>
      <td>0.122078</td>
      <td>645</td>
      <td>0.441418</td>
      <td>0.691489</td>
      <td>0.680000</td>
      <td>0.604303</td>
      <td>0.115272</td>
      <td>645</td>
    </tr>
    <tr>
      <th>560</th>
      <td>1.908902</td>
      <td>0.049481</td>
      <td>0.388748</td>
      <td>0.007513</td>
      <td>1e-05</td>
      <td>balanced</td>
      <td>0.001</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 1e-05, 'clf__class_weight': 'balanced', 'clf__eta0': 0.001, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.422316</td>
      <td>0.686663</td>
      <td>0.675546</td>
      <td>0.594842</td>
      <td>0.122078</td>
      <td>645</td>
      <td>0.441418</td>
      <td>0.691489</td>
      <td>0.680000</td>
      <td>0.604303</td>
      <td>0.115272</td>
      <td>645</td>
    </tr>
    <tr>
      <th>290</th>
      <td>1.896336</td>
      <td>0.006945</td>
      <td>0.420999</td>
      <td>0.038942</td>
      <td>0.001</td>
      <td>balanced</td>
      <td>0.01</td>
      <td>True</td>
      <td>invscaling</td>
      <td>hinge</td>
      <td>l2</td>
      <td>False</td>
      <td>word</td>
      <td>False</td>
      <td>(1, 3)</td>
      <td>l2</td>
      <td>None</td>
      <td>{'clf__alpha': 0.001, 'clf__class_weight': 'balanced', 'clf__eta0': 0.01, 'clf__fit_intercept': True, 'clf__learning_rate': 'invscaling', 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'clf__shuffle': False, 'vec__analyzer': 'word', 'vec__lowercase': False, 'vec__ngram_range': (1, 3), 'vec__norm': 'l2', 'vec__strip_accents': None}</td>
      <td>0.421783</td>
      <td>0.686818</td>
      <td>0.675546</td>
      <td>0.594716</td>
      <td>0.122368</td>
      <td>648</td>
      <td>0.440993</td>
      <td>0.691631</td>
      <td>0.680000</td>
      <td>0.604208</td>
      <td>0.115508</td>
      <td>648</td>
    </tr>
  </tbody>
</table>